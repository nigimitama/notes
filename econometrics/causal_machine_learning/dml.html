

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Double/Debiased Machine Learning &#8212; データサイエンス関連+αのメモ</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-KCTWFQM00B"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KCTWFQM00B');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'econometrics/causal_machine_learning/dml';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="モデルの評価" href="model_evaluation.html" />
    <link rel="prev" title="Casual Tree/Forest" href="causal_forest.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">データサイエンス関連+αのメモ</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    データサイエンス関連+αのメモ
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">数学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../mathematics/introduction.html">数学の初歩</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mathematics/set_theory.html">集合論</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematics/calculus/index.html">微分積分学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/calculus/numerical_sequence.html">数列</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/function/index.html">関数</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/function.html">関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/trigonometric_function.html">三角関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/exp_and_log.html">指数関数と対数関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/limit.html">極限</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/differential/index.html">微分法</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/differential.html">微分法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/extreme_value.html">極値</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/basic_theorem.html">微分学の基礎的な定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/taylor_approximation.html">テイラー近似</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/partial_derivative.html">偏微分</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/directional_derivative.html">方向微分</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/total_differential.html">全微分</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/integral/index.html">積分法</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/integral/indefinite_integral.html">不定積分</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/integral/definite_integral.html">定積分</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/exercise/index.html">練習問題メモ</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/exercise/01.html">練習問題メモ 01</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/exercise/02.html">練習問題メモ 02</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/exercise/03.html">練習問題メモ 03</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/index.html">線形代数学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/vector/index.html">ベクトル</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/vector.html">ベクトルとベクトル空間</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/dot_product.html">内積</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/cross_product.html">クロス積（ベクトル積）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/direct_product.html">直積</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/vector_space.html">ベクトル空間</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/matrix.html">行列</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/index.html">行列式</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/definition.html">行列式の定義</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/nature.html">行列式の性質</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/geometry.html">行列式の幾何的な解釈：体積拡大率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/minor_determinant.html">余因子</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/permutation.html">置換</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/inverse_matrix.html">逆行列</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/linear_mapping.html">線形写像</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/rank.html">行列の階数（rank）</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/index.html">連立1次方程式</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/introduction.html">概要</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/gauss_elimination.html">Gauss-Jordanの消去法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/lu_decomposition.html">LU分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/conjugate_gradient.html">共役勾配法</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/eigenvalue/index.html">固有値</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/eigenvalue/eigenvalue.html">固有値と固有ベクトル</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/eigenvalue/eigenvalue_and_covariance.html">固有値と共分散</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/geometry.html">2次元と3次元の簡単な幾何学</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/complexity/index.html">計算量や数値計算について</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/complexity/inverse_matrix.html">逆行列の計算量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/complexity/implementation.html">numpyやscipyの逆行列の実装について</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/index.html">練習問題</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_01.html">練習問題 メモ 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_02.html">練習問題 メモ 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_03.html">練習問題 メモ 3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_04.html">練習問題 メモ 4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_05.html">練習問題メモ 5（連立1次方程式）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_06.html">練習問題メモ 6（正則行列）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_07.html">練習問題メモ 7（置換）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_08.html">練習問題メモ 8（行列式）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_09.html">練習問題メモ 9（余因子展開）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_10.html">練習問題メモ 10（特別な形をした行列式）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_11.html">練習問題メモ 11（行列式の幾何学的意味）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_12.html">練習問題メモ 12（行列の指数関数）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_13.html">練習問題メモ 13（ベクトル空間）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_14.html">練習問題メモ 14（1次独立と1次従属）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_15.html">練習問題メモ 15（基底と次元）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_16.html">練習問題メモ 16（基底変換）</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematics/mathematical_optimization/index.html">数理最適化</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/optimality_conditions.html">最適性条件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/gradient_descent.html">勾配法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/lagrange.html">ラグランジュの未定乗数法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/knapsack_problem.html">ナップサック問題</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/optimal_transport.html">最適輸送</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/shortest_path_problem.html">最短経路問題</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">統計学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/probability/index.html">確率</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/01_probability.html">確率</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/02_expectation.html">確率変数と期待値・分散</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/03_discrete_probability_distribution.html">離散確率分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/04_continuous_probability_distribution.html">連続確率分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/05_nature_of_distribution.html">確率分布の性質</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/statistical_inference/index.html">統計的推測</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/01_sample_distribution.html">標本分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/02_generating_functions.html">母関数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/03_central_limit_theorem.html">中心極限定理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/04_point_estimation.html">点推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/05_interval_inference.html">区間推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/06_test.html">検定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/ci_and_test.html">信頼区間と検定の関係性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/likelihood_and_probability.html">尤度関数と確率関数の違いは何なのか？</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/divergence.html">ダイバージェンス</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/optimal_transport.html">最適輸送</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/bootstrap.html">Bootstrap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/nonparametric_density_estimation.html">ノンパラメトリック密度推定</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/correlation.html">順序尺度の相関係数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/sandwich_estimator.html">Sandwich Estimator</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/asymptotic_theory/index.html">漸近理論</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/introduction.html">漸近理論</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/landau_symbol.html">漸近オーダーの表記法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/law_of_large_numbers.html">大数の法則</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/consistency_simulation.html">一致性のシミュレーション</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/empirical_processes.html">経験過程</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/bayes_statistics/index.html">ベイズ統計学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/bayes_statistics/bayes_estimation.html">ベイズ推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/bayes_statistics/mcmc.html">マルコフ連鎖モンテカルロ（MCMC）法</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/done_wrong.html">統計学の誤用や望ましい作法</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">統計モデリング</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/factor_analysis.html">因子分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/gaussian_process.html">ガウス過程回帰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/quantile_regression.html">分位点回帰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/survival_analysis.html">生存分析</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/sem/index.html">構造方程式モデリング</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/introduction.html">Structural Equation Modeling（SEM）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/statistic.html">統計量</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/regression_analysis.html">回帰分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/path_analysis.html">パス解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/mimic_pls.html">MIMICモデル &amp; PLSモデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/factor_analysis.html">因子分析モデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/evaluation.html">モデルの評価</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/independence_model.html">Lavaanの独立モデル</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/index.html">ベイズ統計モデリング</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/introduction.html">概要</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/aic.html">AIC / BIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/waic.html">WAIC / WBIC / 渡辺ベイズ理論</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/mcmc.html">MCMC法</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/index.html">時系列分析</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/time_series_data.html">時系列データの特徴</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/data_transformation.html">時系列データの変換</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/arima_model.html">ARIMAモデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/state_space_model.html">状態空間モデル</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/symbolic_data_analysis.html">Symbolic Data Analysis</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/semiparametric/index.html">セミ・ノンパラメトリックモデル</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/semiparametric/introduction.html">概要</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">計量経済学・因果推論</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../rubin_causal_model.html">ルービンの因果モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../selection_bias.html">Selection Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental_design.html">実験デザイン</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pearl_causal_model.html">Pearl流の因果推論</a></li>
<li class="toctree-l1"><a class="reference internal" href="../causal_diagram.html">因果ダイアグラム</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ols/index.html">回帰分析</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ols/ols.html">概要</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/assumptions.html">OLSの仮定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/type_of_regression_model.html">線形回帰モデルの種類</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/mle_and_ols.html">最尤推定法に基づく正規方程式の導出</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/error_and_residual.html">誤差項と残差の違い</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/cef.html">条件付き期待値関数（CEF）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/ols_estimator.html">OLS推定量の性質</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/test_of_ols.html">OLSの検定・区間推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/ols_robust_standard_error.html">OLSのロバスト標準誤差</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/log_transformation.html">対数変換</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/omitted_variable_bias.html">欠落変数バイアス</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/fwl.html">FWL定理</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../propensity_score.html">傾向スコア</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../iv/index.html">操作変数法</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../iv/instrumental_variables.html">操作変数法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/gmm_and_iv.html">一般化モーメント法と操作変数法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/history.html">操作変数法の歴史</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/simulatenous_equasion_model.html">同時方程式モデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/bayesian_iv.html">Bayesian IV</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../regression_discontinuity.html">RDD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fixed_effect_model.html">固定効果モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../difference_in_differences.html">Difference In Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="../synthetic_control.html">Synthetic Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../causalimpact.html">Causal Impact</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gmm.html">一般化モーメント法</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Causal Machine Learning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="meta_learner.html">Meta Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="causal_forest.html">Casual Tree/Forest</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Double/Debiased Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">モデルの評価</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../causal_discovery.html">統計的因果探索</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uplift_modeling.html">Uplift Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../literatures.html">よさそうな文献・サイト</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">機械学習</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/linear_models/index.html">線形モデル</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/regression/linear_regression.html">線形回帰</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/regression/ridge_regression.html">Ridge回帰</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/regression/lasso.html">LASSO</a></li>


<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/classification/linear_discriminant_analysis.html">線形判別モデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/classification/logistic_regression.html">ロジスティック回帰</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/svm.html">Support Vector Machine</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/trees/index.html">Tree-based Algorithms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/decision_tree.html">決定木</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/gbdt.html">勾配ブースティング決定木</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/lightgbm.html">LightGBM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/lightgbm_quantize.html">Quantized Training of LightGBM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/ngboost.html">NGBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/catboost.html">CatBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/mondrian_forest.html">Mondrian Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/generalized_random_forest.html">Generalized Random Forest (GRF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/distributional_random_forest.html">Distributional Random Forest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/tabular_data_and_trees.html">なぜTree-based modelはDeep Learningよりテーブルデータに強いのか</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/naive_bayes.html">ナイーブベイズ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/bayesian_network.html">ベイジアンネットワーク</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/dimension_reduction.html">次元削減</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/imbalanced_data.html">不均衡データ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/probability_prediction.html">確率予測</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/evaluation/evaluation.html">予測モデルの評価</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/cross_validation.html">交差検証</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/generalization_error.html">汎化誤差</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/aic.html">AICとCross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/metrics.html">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/uncertainty_of_prediction.html">予測の不確実性の評価</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/ml_ops/index.html">MLOps</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/ml_ops/ml_design_patterns.html">ML Design Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/ml_ops/ml_system_design_patterns.html">ML System Design Pattern</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/overfitting.html">過学習と良性の過学習（Double Descent, Grokking）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/feature_engineering.html">Feature Engineering</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/explainability/introduction.html">説明可能性</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/explainability/influence_function.html">影響関数（influence function）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/explainability/influence_function_with_linear_regression.html">Influence Function 線形回帰での例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/explainability/shap.html">SHAP</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">深層学習</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../deep_learning/history.html">深層学習の歴史</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_learning/dl_and_tabular_data.html">Deep Learning and Tabular data</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/dnn/index.html">Deep Neural Network</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/dnn/mlp.html">多層パーセプトロン</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/cnn/index.html">CNN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/cnn/cnn.html">CNN</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/rnn/index.html">RNN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/rnn/rnn.html">RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/rnn/lstm.html">LSTM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/rnn/gru.html">GRU</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/transformer/index.html">Transformer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/transformer/algorithm.html">Transformerのアルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/transformer/analysis.html">Transformerの理論的解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/transformer/implementation.html">numpyでGPTを再現する</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">生成モデル</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/generative_models.html">生成モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/autoencoder.html">Autoencoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/gan.html">GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/diffusion_models.html">Diffusion Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">自然言語処理</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/normalization.html">テキストデータの前処理：表記揺れ、正規化</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/tokenization.html">トークン化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/language_model.html">言語モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/embedding.html">単語の埋め込み</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/rnn.html">言語モデルとRNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/document_understanding.html">Document Understanding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">画像処理</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/introduction.html">画像認識</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/rotation_correction.html">傾き補正</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/distortion_correction.html">歪み補正・台形補正</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/similarity_and_hashing.html">類似度・hash化</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">推薦システム</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/introduction.html">概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/collaborative_filtering.html">協調フィルタリング</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/matrix_factorization.html">行列分解に基づく推薦システム</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/factorization_machines.html">Factorization Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/bayesian_personalized_ranking.html">Bayesian Personalized Ranking (BPR)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ビジネス関連知識</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../business/revenue_structure.html">売上構造やKPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../business/accounting.html">会計</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../business/product_management/index.html">プロダクトマネジメント</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../business/product_management/prd.html">PRD（Product Requirements Document）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/product_management/ml_pdm.html">Machine Learning Product Management（MLPdM）</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../business/project_management/index.html">プロジェクトマネジメント</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../business/project_management/development_methods.html">システム開発手法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/project_management/roadmap.html">ロードマップ</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../business/business_administration/index.html">経営学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../business/business_administration/introduction.html">概要</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/business_administration/history.html">経営学史</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/business_administration/causal_process_tracing.html">因果過程追跡</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">データマネジメント</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../data_management/introduction.html">データマネジメント</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ソフトウェア工学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/foundations/index.html">ソフトウェア開発の基礎</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/programming.html">プログラミング</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/data_structure.html">データ構造</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/search_algorithms.html">探索アルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/sort_algorithms.html">ソートのアルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/mathematic_algorithms.html">数学的なアルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/other_algorithms.html">その他のアルゴリズム</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/development/index.html">ソフトウェア開発</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/frontend.html">フロントエンド開発</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/backend.html">バックエンド開発</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/networking.html">ネットワーク・通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/domain_driven_design.html">ドメイン駆動設計</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/serverless.html">Serverless</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/security/index.html">サイバーセキュリティ</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/security/security.html">個人としてのセキュリティ対策</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/security/website.html">ウェブアプリ開発のセキュリティ</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">経済学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../economics/microeconomics/index.html">ミクロ経済学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../economics/microeconomics/demand_elasticity.html">需要の弾力性</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../economics/macroeconomics/index.html">マクロ経済学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../economics/macroeconomics/national_income_accounts.html">国民経済計算</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../economics/macroeconomics/economic_growth.html">経済成長</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../economics/macroeconomics/microfoundations.html">ミクロ的基礎付け</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../economics/quantitative_economics.html">Quantitative Economics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">金融経済学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/introduction.html">概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/optimal_portfolio.html">最適ポートフォリオ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/capm.html">CAPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/metrics.html">ファイナンスの指標たち</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/feature_neutralization.html">Feature Neutralization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/statistical_arbitrage.html">統計的裁定</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/asset_pricing.html">Asset Pricing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../financial_economics/papers/index.html">論文メモ</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/papers/abcd_forcast.html">ABCD Forcast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/papers/deep_portfolio.html">Deep Portfolio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/papers/llm.html">計量ファイナンスにおけるLLMの活用</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../financial_economics/financial_time_series/index.html">金融時系列解析</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/financial_time_series/evaluation.html">時系列予測の性能検証</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/financial_time_series/augmentation.html">Data Augmentation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../financial_economics/investment_strategies/index.html">投資戦略</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/investment_strategies/dogs_of_dow.html">「ダウの犬」戦略</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/libraries.html">金融系ライブラリ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/random_walk.html">ランダムウォークによる株価のシミュレーション</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../financial_economics/factors/index.html">Multiple Factor Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/factors/multiple_factor_models.html">Multiple Factor Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/factors/factor_zoo.html">Factor Zoo</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/nigimitama/notes" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/econometrics/causal_machine_learning/dml.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Double/Debiased Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">概要</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">先行研究</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#donsker">Donsker条件</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">課題</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">前提知識</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">ナイーブな推定量と正則化バイアス</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">サンプル分割</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">ナイーブな推定量</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">直交化による正則化バイアスの打破</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#check-theta-0"><span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>の性質</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-fitting">Cross Fittingによる過学習のバイアスの除去</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Cross Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neyman-orthogonality">Neyman Orthogonality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">Donsker条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">プラグイン推定量</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">プラグイン推定量の漸近正規性</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#g-0-x"><span class="math notranslate nohighlight">\(g_0(X)\)</span>の推定</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">部分線形モデル</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-1988">Robinson (1988)の推定量</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">参考</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dmldid">DMLによるDID</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#youtube">講義動画（Youtube）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">応用研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">関連研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">部分線形モデルに対するモーメント条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dml-score-function">DML score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-style-partialling-out-score-function">Robinson-style “partialling-out” score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">cross fitting</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="double-debiased-machine-learning">
<h1>Double/Debiased Machine Learning<a class="headerlink" href="#double-debiased-machine-learning" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Paper: <a class="reference external" href="https://academic.oup.com/ectj/article/21/1/C1/5056401?login=false">Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., &amp; Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters.</a></p></li>
<li><p>Python Package: <a class="reference external" href="https://docs.doubleml.org/stable/index.html">DoubleML</a></p></li>
</ul>
<section id="id1">
<h2>概要<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>世の中の多くの現象は非線形な関係性が想定される。回帰分析は線形モデルであるため、モデルの定式化の誤りに起因するバイアスが生じかねない。</p>
<p>実際に関心のあるパラメータは少なく、交絡のコントロールのために入れている局外母数（nuisance parameters）は高次元になりがち。</p>
<p>局外母数を非線形の関数<span class="math notranslate nohighlight">\(g_0(X)\)</span>で表し、関心のあるパラメータ<span class="math notranslate nohighlight">\(\theta_0\)</span>は線形モデルで表現する <strong>部分線形モデル</strong>（partially linear regression: PLR）</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y = D\theta_0 + g_0(X) + U, \hspace{1em} E[U|X,D] = 0\\
D = m_0(X) + V, \hspace{1em} E[V|X] = 0
\end{split}\]</div>
<p>を作り、局外関数<span class="math notranslate nohighlight">\(g_0(X)\)</span>を機械学習で構築したい。</p>
<p>もしこれが実現できれば、非線形部分を機械学習による優れた関数近似性能で捉えて交絡をコントロールしつつ、パラメータは線形回帰モデルのように推定できる。</p>
<p>これを実現するのがDMLのフレームワークである（<span class="math notranslate nohighlight">\(g_0\)</span>は任意の機械学習アルゴリズムでよいので、DMLは具体的なアルゴリズムに踏み込まず、フレームワーク）。</p>
</section>
<section id="id2">
<h2>先行研究<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>Robinson (1988)は部分線形モデルを提案し、一致推定量も導出した</p>
<div class="admonition-robinson-1988 admonition">
<p class="admonition-title">Robinson (1988)の推定量</p>
<p>部分線形モデル</p>
<div class="math notranslate nohighlight">
\[
Y = D \theta_0 + g(X) + U, \quad E[U|D,X]=0
\]</div>
<p>の両辺を<span class="math notranslate nohighlight">\(X\)</span>で条件づけて期待値をとると</p>
<div class="math notranslate nohighlight">
\[
E[Y|X] = E[D|X] \theta_0 + g(X)
\]</div>
<p>これをモデルから差し引くと</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|X]
= \theta_0 (D - E[D|X]) + U
\]</div>
<p>という線形回帰の形になる（FWL定理の残差回帰の形）</p>
<p><span class="math notranslate nohighlight">\(\tilde{Y}_i = Y_i - E[Y_i|X_i]\)</span>、<span class="math notranslate nohighlight">\(\tilde{D}_i = D_i - E[D_i|X_i]\)</span>とおけば、OLS推定量の形になる</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{\mathrm{inf}}=\left(\sum_{i=1}^n \tilde{D}_i \tilde{D}_i^T \right)^{-1} \sum_{i=1}^n \tilde{D}_i \tilde{Y}_i
\]</div>
<p>ただし、<span class="math notranslate nohighlight">\(E[Y|X], E[D|X]\)</span>は未知なのでそれぞれノンパラメトリック推定量<span class="math notranslate nohighlight">\(\hat{\ell}(X), \hat{m}(X)\)</span>で置き換える（このようにノンパラ推定量で置換する推定量はプラグイン推定量という）。</p>
<p>その推定量はroot-N consistentで漸近正規性を持つ</p>
</div>
<section id="donsker">
<h3>Donsker条件<a class="headerlink" href="#donsker" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://www.jstor.org/stable/2951475">Andrew (1994)</a> はプラグイン推定量が漸近正規性・<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>-consistent 一致性をもつ条件を明らかにした</p>
<p>その条件を満たすために使われるのが、Donsker条件（Donsker condition）という条件を満たすクラスの関数（複雑性の低い関数）をノンパラメトリック推定量に使うというもの。</p>
<p>機械学習アルゴリズムによる推定量は複雑度が高く、一般にDonsker条件を満たさない。よってRobinson（1988）の推定量に機械学習をそのまま組み込むと漸近正規・<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>-consistentにならない</p>
</section>
</section>
<section id="id3">
<h2>課題<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<p><span class="math notranslate nohighlight">\(g(X)\)</span>を機械学習で作って線形回帰するだけだと推定量は<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>の収束レートにならない</p>
<p>2つのバイアスがある</p>
<ol class="arabic simple">
<li><p>正則化バイアス（Reguralization bias）</p></li>
<li><p>過学習によるバイアス（Bias induced by overfifting）</p></li>
</ol>
<p>それぞれの対策として、</p>
<ol class="arabic simple">
<li><p>正則化バイアス → 残差回帰（直交化）で対応</p></li>
<li><p>過学習 → Cross-Fittingで対応</p></li>
</ol>
<p>を行う</p>
</section>
<section id="id4">
<h2>前提知識<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>知ってると理解を深めやすくなる前提知識まとめ</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
（参考）残差回帰<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">DMLでは、FWL定理を利用した残差回帰を一般化する。</p>
<p class="sd-card-text">残差回帰は線形回帰モデル</p>
<div class="math notranslate nohighlight">
\[
Y = X_1 \beta_1 + X_2 \beta_2 + e
\]</div>
<p class="sd-card-text">を用いて</p>
<div class="math notranslate nohighlight">
\[
Y - X_2 \hat{\gamma} = (X_1 - X_2 \hat{\delta}) \beta_1
\]</div>
<p class="sd-card-text">のようにして関心のあるパラメータ<span class="math notranslate nohighlight">\(\beta_1\)</span>を推定する。</p>
<p class="sd-card-text">線形回帰モデルは回帰関数<span class="math notranslate nohighlight">\(E[Y|X]\)</span>を近似するため、上記の残差回帰は期待値を用いて</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|X_2] = (X_1 - E[X_1|X_2]) \beta_1
\]</div>
<p class="sd-card-text">と表すことができる。</p>
<div class="admonition-fwl admonition">
<p class="admonition-title">FWL定理</p>
<p class="sd-card-text">目的変数のベクトル<span class="math notranslate nohighlight">\(Y \in \mathbb{R}^{n\times 1}\)</span>、説明変数の行列<span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n\times d}\)</span>と誤差項<span class="math notranslate nohighlight">\(e \in \mathbb{R}^{n\times 1}\)</span>による線形回帰モデル</p>
<div class="math notranslate nohighlight">
\[
Y = X \beta + e
\]</div>
<p class="sd-card-text">があるとする。</p>
<p class="sd-card-text">説明変数を<span class="math notranslate nohighlight">\(X = (X_1 | X_2)\)</span>と2つのグループに分割し、回帰係数ベクトル<span class="math notranslate nohighlight">\(\beta\)</span>も合わせて<span class="math notranslate nohighlight">\(\beta = (\beta_1 | \beta_2)^T\)</span>と2つに分割して</p>
<div class="math notranslate nohighlight">
\[
Y = X_1 \beta_1 + X_2 \beta_2 + e
\]</div>
<p class="sd-card-text">と表す。</p>
<p class="sd-card-text">この回帰モデルの<span class="math notranslate nohighlight">\(\beta_1\)</span>は、<strong>残差回帰</strong>（residual regression）と呼ばれる以下の手順に従うことでも得ることができる。</p>
<ol class="arabic simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(X_1\)</span>を<span class="math notranslate nohighlight">\(X_2\)</span>に回帰して残差<span class="math notranslate nohighlight">\(\tilde{X}_1\)</span>を得る：<span class="math notranslate nohighlight">\(\tilde{X}_1 = X_1 - X_2 \hat{\delta}\)</span></p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(Y\)</span>を<span class="math notranslate nohighlight">\(X_2\)</span>に回帰して残差<span class="math notranslate nohighlight">\(\tilde{Y}\)</span>を得る：<span class="math notranslate nohighlight">\(\tilde{Y} = Y - X_2 \hat{\gamma}\)</span></p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(\tilde{Y}\)</span>を<span class="math notranslate nohighlight">\(\tilde{X}_1\)</span>に回帰させる：<span class="math notranslate nohighlight">\(\tilde{Y} = \tilde{X}_1 \beta_1\)</span></p></li>
</ol>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
（参考）モーメント法<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">確率変数<span class="math notranslate nohighlight">\(X\)</span>が<span class="math notranslate nohighlight">\(\theta\)</span>というパラメータをもつ分布に従うとする。</p>
<div class="math notranslate nohighlight">
\[
E[\psi(X; \theta)] = 0
\]</div>
<p class="sd-card-text">という条件（直交条件）を満たすスコア関数<span class="math notranslate nohighlight">\(\psi(X; \theta)\)</span>があるとき、標本<span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span>を使った直交条件</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum^n_{i=1} \psi(X_i; \theta) = 0
\]</div>
<p class="sd-card-text">を解いて<span class="math notranslate nohighlight">\(\theta\)</span>を推定する方法を <strong>モーメント法</strong> （method of moments） という。</p>
<div class="admonition- admonition">
<p class="admonition-title">例：線形回帰モデル</p>
<p class="sd-card-text">線形回帰モデル</p>
<div class="math notranslate nohighlight">
\[
Y_i = X_i^T \beta + u_i
\]</div>
<p class="sd-card-text">のパラメータ<span class="math notranslate nohighlight">\(\beta\)</span>の推定を考える。ここで<span class="math notranslate nohighlight">\(X\)</span>と<span class="math notranslate nohighlight">\(\beta\)</span>は<span class="math notranslate nohighlight">\((k \times 1)\)</span>ベクトルとする。<span class="math notranslate nohighlight">\(X\)</span>は誤差項と無相関<span class="math notranslate nohighlight">\(E[X_i u_i] = 0\)</span>であるとする。</p>
<p class="sd-card-text">このモデルから<span class="math notranslate nohighlight">\(k\)</span>本のモーメント条件が得られる</p>
<div class="math notranslate nohighlight">
\[
E[X_i u_i] = E[X_i (Y_i - X_i^T \beta)] = 0
\]</div>
<p class="sd-card-text">標本対応は</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum^n_{i=1} X_i u_i
= \frac{1}{n} \sum^n_{i=1} X_i (Y_i - X_i^T \beta)
\]</div>
<p class="sd-card-text">行列表記では</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} X^T u
= \frac{1}{n} X^T (Y - X\beta) = 0
\]</div>
<p class="sd-card-text">となる。これを解くと</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{1}{n} X^T Y = \frac{1}{n} X^T X\beta\\
\to \beta = (X^T X)^{-1}X^T Y
\end{split}\]</div>
<p class="sd-card-text">と、最小二乗法の解と一致する</p>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
（参考）漸近理論<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">確率変数列<span class="math notranslate nohighlight">\(X_n\)</span>の分布関数がある確率変数<span class="math notranslate nohighlight">\(X\)</span>の分布関数に収束するとき</p>
<div class="math notranslate nohighlight">
\[
\mathrm{P}\left(X_n \leq x\right) \rightarrow \mathrm{P}(X \leq x)
\]</div>
<p class="sd-card-text"><strong>分布収束</strong> （converge in distribution）や <strong>法則収束</strong>（convergence in law） や <strong>弱収束</strong> （weak convergence） と呼び、</p>
<div class="math notranslate nohighlight">
\[
X_n \overset{d}{\to} X,\quad
X_n \rightsquigarrow X
\]</div>
<p class="sd-card-text">などと表す。<span class="math notranslate nohighlight">\(X\)</span>がある分布<span class="math notranslate nohighlight">\(L\)</span>に従う場合は</p>
<div class="math notranslate nohighlight">
\[
X_n \overset{d}{\to} L,\quad
X_n \rightsquigarrow L
\]</div>
<p class="sd-card-text">などと表す。</p>
</div>
</details></section>
<section id="id5">
<h2>ナイーブな推定量と正則化バイアス<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h2>
<section id="id6">
<h3>サンプル分割<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>のちのCross Fittingでサンプル分割の話になるので、数式の記法もあらかじめ分割に対応させておく。</p>
<p>main sampleは<span class="math notranslate nohighlight">\(n\)</span>個のサンプルからなり、<span class="math notranslate nohighlight">\(i\in I\)</span>のインデックスで表す。補助サンプルは<span class="math notranslate nohighlight">\(N-n\)</span>として<span class="math notranslate nohighlight">\(i \in I^c\)</span>とする。単純のため2つに分割するだけにし、<span class="math notranslate nohighlight">\(n=N/2\)</span>とする。</p>
<p>補助パートのサンプルで<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>を獲得し、<span class="math notranslate nohighlight">\(\theta_0\)</span>の推定にメインパートのサンプルを使うことにする。</p>
<img style="width: 400px;" src="data:image/png;base64,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"></section>
<section id="id7">
<h3>ナイーブな推定量<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>線形回帰モデル<span class="math notranslate nohighlight">\(Y = X\beta + U\)</span>のモーメント条件は</p>
<div class="math notranslate nohighlight">
\[
E[U X] = E[(Y - X^T \beta) X] = 0
\]</div>
<p>であった。これと同様に部分線形モデルにおいて</p>
<div class="math notranslate nohighlight">
\[
E[UD] = E[(Y - \theta D - g(X))D] = 0
\]</div>
<p>というモーメント条件を考えると、その推定量は</p>
<div class="math notranslate nohighlight">
\[
\hat{\theta}_0 = \left( \frac{1}{n} \sum_{i\in I} D_i^2 \right)^{-1}
\frac{1}{n} \sum_{i\in I} D_i (Y_i - \hat{g}_0(X_i))
\]</div>
<p>となる。この推定量<span class="math notranslate nohighlight">\(\hat{\theta}_0\)</span>は一般に<span class="math notranslate nohighlight">\(1/\sqrt{n}\)</span>より遅い収束レート、つまり</p>
<div class="math notranslate nohighlight">
\[
|\sqrt{n} (\hat{\theta}_0 - \theta_0)| \overset{p}{\to} \infty
\]</div>
<p>となる。</p>
<p>この「劣った」振る舞いの背後には<span class="math notranslate nohighlight">\(g_0\)</span>の学習におけるバイアスがある。</p>
<p>ヒューリスティックにこの<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>の学習のバイアスのインパクトを説明すると、スケールされた<span class="math notranslate nohighlight">\(\hat{\theta}_0\)</span>の推定誤差は</p>
<div class="math notranslate nohighlight">
\[
\sqrt{n} (\hat{\theta}_0 - \theta_0) =
\underbrace{
    \left( \frac{1}{n} \sum_{i\in I} D_i^2 \right)^{-1}
    \frac{1}{\sqrt{n}} \sum_{i\in I} D_i U_i
}_{:=a}
+
\underbrace{
    \left( \frac{1}{n} \sum_{i\in I} D_i^2 \right)^{-1}
    \frac{1}{\sqrt{n}} \sum_{i\in I} D_i (g_0(X_i) - \hat{g}_0(X_i))
}_{:=b}
\]</div>
<p>である。</p>
<p>第1項<span class="math notranslate nohighlight">\(a\)</span>は<span class="math notranslate nohighlight">\(a \rightsquigarrow N(0, \bar{\Sigma})\)</span>となるので問題ない。第2項の<span class="math notranslate nohighlight">\(b\)</span>の項は正則化バイアス項で、一般に中心にならず発散する。first orderで以下を得る</p>
<div class="math notranslate nohighlight">
\[
b = (E[D_i^2])^{-1}
\frac{1}{\sqrt{n}} \sum_{i\in I}
m_0(X_i)(g_0(X_i) - \hat{g}_0(X_i)) + o_P(1)
\]</div>
<p>ヒューリスティックには、<span class="math notranslate nohighlight">\(b\)</span>は平均がゼロにならない<span class="math notranslate nohighlight">\(m_0(X_i)(g_0(X_i) - \hat{g}_0(X_i))\)</span>の<span class="math notranslate nohighlight">\(n\)</span>個の総和で、<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>で割られる。これらの項は非ゼロの平均になる。なぜなら一般に機械学習手法は正則化推定量を採用するためである。正則化は推定量の分散が爆発しないようにするものの相当なバイアスを引き起こす。とりわけ、<span class="math notranslate nohighlight">\(g_0\)</span>への<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>のバイアスの収束レートは、RMSEにおいて<span class="math notranslate nohighlight">\(n^{-\phi_g}\)</span>（<span class="math notranslate nohighlight">\(\phi_g &lt; 1/2\)</span>）である。ゆえに<span class="math notranslate nohighlight">\(b\)</span>は<span class="math notranslate nohighlight">\(D_i\)</span>が<span class="math notranslate nohighlight">\(m_0(X_i)\neq 0\)</span>で中心化されるとき<span class="math notranslate nohighlight">\(\sqrt{n} n^{-\phi_g} \to \infty\)</span>の確率的オーダーになることが期待され、よって<span class="math notranslate nohighlight">\(|\sqrt{n} (\hat{\theta}_0 - \theta_0)| \overset{p}{\to} \infty\)</span>となる</p>
<p><a class="reference external" href="https://docs.doubleml.org/stable/guide/basics.html">1. The basics of double/debiased machine learning — DoubleML documentation</a></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">n_rep</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
    <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">non_orth_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">l_hat</span><span class="p">,</span> <span class="n">m_hat</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">,</span> <span class="n">smpls</span><span class="p">):</span>
    <span class="n">u_hat</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">g_hat</span>
    <span class="n">psi_a</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
    <span class="n">psi_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">u_hat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_a</span><span class="p">,</span> <span class="n">psi_b</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span>
<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLPLR</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">face_colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s1">&#39;pastel&#39;</span><span class="p">)</span>
<span class="n">edge_colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s1">&#39;dark&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1111</span><span class="p">)</span>
<span class="n">ml_l</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">132</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">378</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">ml_g</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">ml_l</span><span class="p">)</span>

<span class="c1"># シミュレーションに時間がかかるので結果を保存する</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">result_json_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./dml_simulation_results.json&#39;</span><span class="p">)</span>
<span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># 実験1: ネイマン直交条件を満たさない場合</span>
<span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">result_json_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">theta_nonorth</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_nonorth&quot;</span><span class="p">]</span>
    <span class="n">se_nonorth</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_nonorth&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">theta_nonorth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="n">se_nonorth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
        <span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">obj_dml_plr_nonorth</span> <span class="o">=</span> <span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                                          <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span>
                                          <span class="n">n_folds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                          <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">score</span><span class="o">=</span><span class="n">non_orth_score</span><span class="p">)</span>
        <span class="n">obj_dml_plr_nonorth</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">this_theta</span> <span class="o">=</span> <span class="n">obj_dml_plr_nonorth</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">this_se</span> <span class="o">=</span> <span class="n">obj_dml_plr_nonorth</span><span class="o">.</span><span class="n">se</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">theta_nonorth</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>
        <span class="n">se_nonorth</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_se</span>

    <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_nonorth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_nonorth</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_nonorth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">se_nonorth</span>
<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">((</span><span class="n">theta_nonorth</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">se_nonorth</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">face_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                  <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Non-orthogonal ML&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$(\hat{</span><span class="se">\\</span><span class="s1">theta}_0 - </span><span class="se">\\</span><span class="s1">theta_0)/\hat{\sigma}$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/f5317d42dfcc15a8a02f9c07c8e4f42a4de3e976f0e85f5da96c10f123593cbf.png" src="../../_images/f5317d42dfcc15a8a02f9c07c8e4f42a4de3e976f0e85f5da96c10f123593cbf.png" />
</div>
</div>
</section>
</section>
<section id="id8">
<h2>直交化による正則化バイアスの打破<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<p>DからXの効果をpartialling outして直交化された</p>
<div class="math notranslate nohighlight">
\[
\hat{V} = D - \hat{m}_0(X)
\]</div>
<p>を使用する方法を考える。ここで<span class="math notranslate nohighlight">\(\hat{m}_0\)</span>は補助的サンプル（auxiliary sample）を用いたML推定量である。</p>
<p>DからXの効果をpartialling out したあとは、main sampleを使って<span class="math notranslate nohighlight">\(\theta_0\)</span>のdebiased ML (DML)を構築する</p>
<div class="math notranslate nohighlight">
\[
\check{\theta}_0 = \left( \frac{1}{n} \sum_{i\in I} \hat{V}_i D_i \right)^{-1}
\frac{1}{n} \sum_{i\in I} \hat{V}_i (Y_i - \hat{g}_0(X_i))
\]</div>
<p>近似的にDをXについて直交化し、<span class="math notranslate nohighlight">\(g_0\)</span>の推定値を引くことで近似的に交絡の直接効果を除去することで、<span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>は(1.3)の正則化バイアスを除去している。</p>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<p class="sd-card-text"><span class="math notranslate nohighlight">\(\hat{V}\)</span>も入れて書くと</p>
<div class="math notranslate nohighlight">
\[
\check{\theta}_0 = \left( \frac{1}{n} \sum_{i\in I} \left(D_i - \hat{m}_0(X_i)\right) D_i \right)^{-1}
\frac{1}{n} \sum_{i\in I} \left(D_i - \hat{m}_0(X_i)\right) \left(Y_i - \hat{g}_0(X_i) \right)
\]</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 実験2: 直交化した場合</span>
<span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">result_json_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">theta_orth_nosplit</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_orth_nosplit&quot;</span><span class="p">]</span>
    <span class="n">se_orth_nosplit</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_orth_nosplit&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">theta_orth_nosplit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="n">se_orth_nosplit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
        <span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">obj_dml_plr_orth_nosplit</span> <span class="o">=</span> <span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                                               <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span>
                                               <span class="n">n_folds</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                               <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                                               <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">obj_dml_plr_orth_nosplit</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">this_theta</span> <span class="o">=</span> <span class="n">obj_dml_plr_orth_nosplit</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">this_se</span> <span class="o">=</span> <span class="n">obj_dml_plr_orth_nosplit</span><span class="o">.</span><span class="n">se</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">theta_orth_nosplit</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>
        <span class="n">se_orth_nosplit</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_se</span>

    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_orth_nosplit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_orth_nosplit</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_orth_nosplit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">se_orth_nosplit</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">((</span><span class="n">theta_orth_nosplit</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">se_orth_nosplit</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">face_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Double ML (no sample splitting)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$(\hat{</span><span class="se">\\</span><span class="s1">theta}_0 - </span><span class="se">\\</span><span class="s1">theta_0)/\hat{\sigma}$&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;$(\\hat{\\theta}_0 - \\theta_0)/\\hat{\\sigma}$&#39;)
</pre></div>
</div>
<img alt="../../_images/31b87226d444808ce8922958d58a590fe6f423d6c4452fc41e8b0c8efdce4c3a.png" src="../../_images/31b87226d444808ce8922958d58a590fe6f423d6c4452fc41e8b0c8efdce4c3a.png" />
</div>
</div>
<section id="check-theta-0">
<h3><span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>の性質<a class="headerlink" href="#check-theta-0" title="Permalink to this heading">#</a></h3>
<p>スケールされた推定誤差は３つの要素に分解できる</p>
<div class="math notranslate nohighlight">
\[
\sqrt{n}(\check{\theta}_0 - \theta_0)
= a^* + b^* + c^*
\]</div>
<p><span class="math notranslate nohighlight">\(a^*\)</span>はmild conditionsのもとで以下を満たす</p>
<div class="math notranslate nohighlight">
\[
a^* = (E[V^2])^{-1}
\frac{1}{\sqrt{n}} \sum_{i\in I} V_i U_i \rightsquigarrow N(0, \Sigma)
\]</div>
<p><span class="math notranslate nohighlight">\(b^*\)</span>は<span class="math notranslate nohighlight">\(g_0, m_0\)</span>の推定における正則化バイアスの影響を捉える。具体的には</p>
<div class="math notranslate nohighlight">
\[
b^* = (E[V^2])^{-1}
\frac{1}{\sqrt{n}} \sum_{i\in I} 
(\hat{m}_0(X_i) - m_0(X_i))
(\hat{g}_0(X_i) - g_0(X_i))
\]</div>
<p>で、これは<span class="math notranslate nohighlight">\(\hat{m}_0\)</span>と<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>の推定誤差の積に依存する。そのため、幅広い範囲のデータ生成過程のもとで消失させることが可能である。</p>
<p>実際、この項は<span class="math notranslate nohighlight">\(\sqrt{n}n^{-(\phi_m+\phi_g)}\)</span>で上界になり、ここで<span class="math notranslate nohighlight">\(n^{-\phi_m}, n^{-\phi_g}\)</span>はそれぞれ<span class="math notranslate nohighlight">\(\hat{m}_0, \hat{g}_0\)</span>の<span class="math notranslate nohighlight">\(m_0, g_0\)</span>への収束レートである。これは両者が比較的遅い収束レートで推定されたとしても、消失しうる。</p>
<p><span class="math notranslate nohighlight">\(c^*\)</span>は</p>
<div class="math notranslate nohighlight">
\[
c^* = o_P(1)
\]</div>
<p>となる。これが弱い条件のもとで成り立つことを保証するにあたって、sample splittingが重要な役割を果たす。</p>
</section>
</section>
<section id="cross-fitting">
<h2>Cross Fittingによる過学習のバイアスの除去<a class="headerlink" href="#cross-fitting" title="Permalink to this heading">#</a></h2>
<p>DML推定量の<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>でスケールした推定誤差</p>
<div class="math notranslate nohighlight">
\[
\sqrt{n}(\check{\theta}_0 - \theta_0)
= a^* + b^* + c^*
\]</div>
<p>のうち、<span class="math notranslate nohighlight">\(c^*\)</span>が確率的に消失するためにsample splittingが使われる。</p>
<p><span class="math notranslate nohighlight">\(c^*\)</span>は</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{\sqrt{n}} \sum_{i \in I} V_i (\hat{g}_0(X_i) - g_0(X_i))
\]</div>
<p>などの項を含む。
この項は局外関数の推定誤差と部分線形モデルの構造的未観測要因の積の和を<span class="math notranslate nohighlight">\(1/\sqrt{n}\)</span>-normalizedしたものである。</p>
<p>sample splittingを使うと、このような項をシンプルでタイトにコントロールできる。それを確認するため、観測値が独立と仮定して、<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>が補助的サンプルの観測値のみで推定されることを思い出そう。</p>
<p><span class="math notranslate nohighlight">\(E[V_i|X_i]=0\)</span>であることを思い出すと、この項は平均ゼロで分散は</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum_{i \in I} (\hat{g}_0(X_i) - g_0(X_i))^2
\overset{p}{\to}
0
\]</div>
<p>であることがわかり、チェビシェフの不等式を使って確率的には消失することがわかる。</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
なぜ平均ゼロになるのか<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">条件付き期待値の性質<span class="math notranslate nohighlight">\(E[X]=E_Y[E(X|Y)]\)</span>により</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
E[V_i (\hat{g}_0(X_i) - g_0(X_i))]
&amp;= E_X[E[V_i (\hat{g}_0(X_i) - g_0(X_i)) \mid X ] ]\\
&amp;= E_X[ (\hat{g}_0(X_i) - g_0(X_i)) \underbrace{ E[V_i \mid X ] }_{=0} ]\\
&amp;= E[0] = 0
\end{aligned}
\end{split}\]</div>
<p class="sd-card-text">ということかと思われる</p>
</div>
</details><p>sample splittingの欠点は推定に使用するサンプル数が減ることによる効率性の低下である。しかし、mainとauxiliaryの2つでそれぞれ推定を行い、両者の平均を取ればfull efficiencyを取り戻す。この手続き（mainとauxiliaryの役割を取り替えて複数の推定値を取得しそれらの平均をとる）を「<strong>cross-fitting</strong>」と呼ぶことにする。一般にk-foldにすることもできる。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 実験2: 直交化した場合</span>
<span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">result_json_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">theta_dml</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_dml&quot;</span><span class="p">]</span>
    <span class="n">se_dml</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_dml&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">theta_dml</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="n">se_dml</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
        <span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">obj_dml_plr</span> <span class="o">=</span> <span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                                  <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span>
                                  <span class="n">n_folds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                  <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">)</span>
        <span class="n">obj_dml_plr</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">this_theta</span> <span class="o">=</span> <span class="n">obj_dml_plr</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">this_se</span> <span class="o">=</span> <span class="n">obj_dml_plr</span><span class="o">.</span><span class="n">se</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">theta_dml</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>
        <span class="n">se_dml</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_se</span>

    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_dml&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_dml</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_dml&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">se_dml</span>
    <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">simulation_results</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">((</span><span class="n">theta_dml</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">se_dml</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">face_colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="n">edge_colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                  <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Double ML with cross-fitting&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$(\hat{</span><span class="se">\\</span><span class="s1">theta}_0 - </span><span class="se">\\</span><span class="s1">theta_0)/\hat{\sigma}$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/25e0a6a7587b9df4d27c92413e5970d9f9ea6af84e2a0138caefb4409a8d1127.png" src="../../_images/25e0a6a7587b9df4d27c92413e5970d9f9ea6af84e2a0138caefb4409a8d1127.png" />
</div>
</div>
</section>
<section id="id9">
<h2>Cross Fitting<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<div class="admonition-definition-3-1-dml1 admonition">
<p class="admonition-title">Definition 3.1.DML1</p>
<p>(1) サンプル<span class="math notranslate nohighlight">\((W_i)^N_{i=1}\)</span>のインデックス<span class="math notranslate nohighlight">\([N]=\{1,\dots,N\}\)</span>のK-foldのランダムな分割<span class="math notranslate nohighlight">\(\left(I_k\right)_{k=1}^K\)</span> を作る。</p>
<p><span class="math notranslate nohighlight">\(I_k\)</span>のサイズは<span class="math notranslate nohighlight">\(n=N/K\)</span>である。</p>
<p>それぞれの<span class="math notranslate nohighlight">\(k\in[K]=\{1,\dots,K\}\)</span>について、<span class="math notranslate nohighlight">\(I_k^c := \{1,\dots,N\} \backslash I_k\)</span>を定義する。</p>
<p>(2) 各<span class="math notranslate nohighlight">\(k\in[K]\)</span>について、局外母数<span class="math notranslate nohighlight">\(\eta_0\)</span>のML推定量</p>
<div class="math notranslate nohighlight">
\[
\hat{\eta}_{0, k}=\hat{\eta}_0\left(\left(W_i\right)_{i \in I_k^c}\right)
\]</div>
<p>を構築する。</p>
<p>(3) 各<span class="math notranslate nohighlight">\(k\in[K]\)</span>について、推定量<span class="math notranslate nohighlight">\(\check{\theta}_{0, k}\)</span>を</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{n, k}\left[
\psi \left(W ; \check{\theta}_{0, k}, \hat{\eta}_{0, k} \right)
\right]=0
\]</div>
<p>の解として構築する。<span class="math notranslate nohighlight">\(\psi\)</span>はネイマン直交スコアで、<span class="math notranslate nohighlight">\(\mathbb{E}_{n, k}\)</span>は経験期待値</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}_{n, k}[\psi(W)] = \frac{1}{n} \sum_{i \in I_k} \psi\left(W_i\right)
\]</div>
<p>である。</p>
<p>なお、もし厳密に0にするのが不可能である場合は、推定量<span class="math notranslate nohighlight">\(\check\theta_{0,k}\)</span>は近似解</p>
<div class="math notranslate nohighlight">
\[
\left\|E_{n, k}\left[\psi\left(W ; \check{\theta}_{0, k}, \hat{\eta}_{0, k}\right)\right]\right\| \leq \inf _{\theta \in \Theta}\left\|E_{n, k}\left[\psi\left(W ; \theta, \hat{\eta}_{0, k}\right)\right]\right\|+\varepsilon_N, \quad \varepsilon_N=o\left(\delta_N N^{-1 / 2}\right)
\]</div>
<p>ここで<span class="math notranslate nohighlight">\(\left(\delta_N\right)_{N \geq 1}\)</span>はゼロに収束する正の整数列である。</p>
<p>(4) 推定量を集計する</p>
<div class="math notranslate nohighlight">
\[
\widetilde{\theta}_0=\frac{1}{K} \sum_{k=1}^K \check{\theta}_{0, k}
\]</div>
</div>
</section>
<section id="neyman-orthogonality">
<h2>Neyman Orthogonality<a class="headerlink" href="#neyman-orthogonality" title="Permalink to this heading">#</a></h2>
<p>partialling outしたモーメント条件による推定量とナイーブな推定量は何が違うのか？</p>
<p>→ ネイマン直交性（Neyman orthogonality）がカギになる。</p>
<div class="admonition- admonition">
<p class="admonition-title">ネイマン直交性</p>
<p>サンプル<span class="math notranslate nohighlight">\(W\)</span>、関心のあるパラメータ<span class="math notranslate nohighlight">\(\theta_0\)</span>、局外母数<span class="math notranslate nohighlight">\(\eta_0\)</span>についてのスコア関数<span class="math notranslate nohighlight">\(\psi(W; \theta_0, \eta_0)\)</span>のベクトル<span class="math notranslate nohighlight">\(\psi = (\psi_1, \dots, \psi_d)^T\)</span>があるとする。このスコア関数の直交条件</p>
<div class="math notranslate nohighlight">
\[
E[\psi(W; \theta_0, \eta_0)] = 0
\]</div>
<p>について、ガトー微分が存在し、</p>
<p>ネイマン直交性（Neyman orthogonality）</p>
</div>
<blockquote>
<div><p>We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order.</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1901.09036.pdf">Foster, D. J., &amp; Syrgkanis, V. (2023). Orthogonal statistical learning. The Annals of Statistics, 51(3), 879-908.</a></p>
</div></blockquote>
</section>
<section id="id10">
<h2>Donsker条件<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h2>
<p>Robinson (1988）などのセミパラメトリックモデルでも<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>-consistentで漸近正規性をもつ推定量が作れていた</p>
<p>しかし、Donsker条件（Donsker condition）という条件を満たすクラスの関数（複雑性の低い関数）でなければ、漸近正規性をもたない（<a class="reference external" href="https://www.jstor.org/stable/2951475">Andrew 1994</a>）</p>
<p>機械学習モデルの収束レートが遅い（Donsker条件）→Cross Fitting</p>
<p><a class="reference external" href="https://twitter.com/masakat0/status/1314897112316870657">XユーザーのMasahiro Katoさん: 「Double/debiased machine learningはどういう手法かというと，機械学習はDonsker条件を満たさないので，サンプルを分割することによって，異なる部分集合間で独立だと思えるような局外母数の推定量を構築することで，収束率だけで漸近正規性を出す手法です．」 / X</a></p>
<section id="id11">
<h3>プラグイン推定量<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
<p>モデルのパラメータをモーメント推定する際に、未知の関数をノンパラ推定量で置換してモーメント推定する推定量。
部分線形モデルを含む多くのセミパラメトリック推定量はプラグイン推定量に含まれる。</p>
<p>関心のあるパラメータを<span class="math notranslate nohighlight">\(\theta\)</span>、局外母数を<span class="math notranslate nohighlight">\(\eta\)</span>とし、セミパラメトリックモデルが確率変数を<span class="math notranslate nohighlight">\(W\)</span>として真のパラメータ<span class="math notranslate nohighlight">\((\theta_0, \eta_0)\)</span>のもとでモーメント条件</p>
<div class="math notranslate nohighlight">
\[
E[m(W, \theta_0, \eta_0)]=0
\]</div>
<p>を満たすとする（<span class="math notranslate nohighlight">\(m\)</span>は既知の関数）。
第1段階で局外母数<span class="math notranslate nohighlight">\(\eta_0\)</span>の一致推定量<span class="math notranslate nohighlight">\(\hat\eta\)</span>を得て、第2段階で標本モーメント条件</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n}\sum^n_{i=1} m(W_i, \hat\beta, \hat\eta)=0
\]</div>
<p>を満たすように<span class="math notranslate nohighlight">\(\hat\theta\)</span>を推定する。</p>
</section>
<section id="id12">
<h3>プラグイン推定量の漸近正規性<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h3>
<p>プラグイン推定量が漸近正規性をもつためには、次の2つの条件が鍵となる</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\nu_n(\hat\eta) - \nu(\eta_0) \overset{p}{\to} 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sqrt{n}E[m(X_i, \theta_0, \hat\eta)] = o_p(1)\)</span></p></li>
</ol>
<p>なお<span class="math notranslate nohighlight">\(m(\cdot)\)</span>はモーメント条件を構成する既知の関数で、<span class="math notranslate nohighlight">\(\nu_n\)</span>は経験過程（empirical process）とよばれる関数</p>
<div class="math notranslate nohighlight">
\[
\nu_n(\eta) = \frac{1}{\sqrt{n}} \sum_{i=1}^n ( m(X_i, \eta) - E[m(X_i, \eta)] )
\]</div>
<p>である。</p>
<p>ノンパラメトリック推定量の漸近理論ではDonsker条件を用いて条件1を示すことが多いようだが、高次元ではDonsker条件は満たされない</p>
<p>対処法のひとつは標本分割（sample splitting）だが、標本分割すると効率性が低下する。Chernozkov et al. (2018)ではCross-fittingにより効率性を落とさずに推定できることを示した</p>
</section>
</section>
<section id="g-0-x">
<h2><span class="math notranslate nohighlight">\(g_0(X)\)</span>の推定<a class="headerlink" href="#g-0-x" title="Permalink to this heading">#</a></h2>
<p>Robinson-styleのほうは<span class="math notranslate nohighlight">\(g_0(X)\)</span>ではなく<span class="math notranslate nohighlight">\(\ell_0(X) := E[Y|X]\)</span>を使ったのでシンプルにFWL定理であり、わかりやすかった。</p>
<p>DMLの<span class="math notranslate nohighlight">\(g(X)\)</span>はどう推定するのか?</p>
<p>→ 直接推定できないのでちょっと手順を踏む</p>
<p>ドキュメントの例だと<span class="math notranslate nohighlight">\(y - D \theta\)</span>を目的変数にしてfitしてるっぽい</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">psi_a</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">i_train</span><span class="p">]</span> <span class="o">-</span> <span class="n">ml_m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i_train</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">d</span><span class="p">[</span><span class="n">i_train</span><span class="p">]</span> <span class="o">-</span> <span class="n">ml_m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i_train</span><span class="p">,</span> <span class="p">:]))</span>
<span class="n">psi_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">i_train</span><span class="p">]</span> <span class="o">-</span> <span class="n">ml_m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i_train</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">y</span><span class="p">[</span><span class="n">i_train</span><span class="p">]</span> <span class="o">-</span> <span class="n">ml_l</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i_train</span><span class="p">,</span> <span class="p">:]))</span>
<span class="n">theta_initial</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">psi_b</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">psi_a</span><span class="p">)</span>
<span class="n">ml_g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i_train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">i_train</span><span class="p">]</span> <span class="o">-</span> <span class="n">theta_initial</span> <span class="o">*</span> <span class="n">d</span><span class="p">[</span><span class="n">i_train</span><span class="p">])</span>
</pre></div>
</div>
<blockquote>
<div><p>Remark that the estimator is not able to estimate <span class="math notranslate nohighlight">\(\hat{g}_0(X)\)</span> directly, but has to be based on a preliminary estimate of <span class="math notranslate nohighlight">\(\hat{m}_0(X)\)</span></p>
<p><a class="reference external" href="https://docs.doubleml.org/stable/examples/py_double_ml_basics.html">Python: Basics of Double Machine Learning — DoubleML documentation</a></p>
</div></blockquote>
<section id="id13">
<h3>部分線形モデル<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h3>
<p>結果変数<span class="math notranslate nohighlight">\(Y\)</span>、説明変数<span class="math notranslate nohighlight">\(X, Z\)</span>についての次のようなモデルを**部分線形モデル（Partially Linear Model）**という。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
Y &amp;= X^T \beta + g(Z) + u\\
E[u|X,Z] &amp;= 0\\
E[u^2|X,Z] &amp;= \sigma^2(X, Z)\\
\end{align}
\end{split}\]</div>
<p>ここで、<span class="math notranslate nohighlight">\(g(\cdot)\)</span>は任意の関数（非線形の関数でもよい）である。<span class="math notranslate nohighlight">\(\sigma^2(\cdot, \cdot)\)</span>も未知の関数で、不均一分散を許容する。</p>
<p>関心のあるパラメータ<span class="math notranslate nohighlight">\(\beta\)</span>を解釈性の高い線形モデルで推定（パラメトリック推定）しつつ、影響を統制するためだけにモデルに投じている<span class="math notranslate nohighlight">\(Z\)</span>は関数形を特定せず推定（ノンパラメトリック推定）することができるため、部分線形モデルはセミパラメトリックモデルと呼ばれる。</p>
<section id="robinson-1988">
<h4>Robinson (1988)の推定量<a class="headerlink" href="#robinson-1988" title="Permalink to this heading">#</a></h4>
<p><span class="math notranslate nohighlight">\(Z\)</span>で両辺の条件付き期待値をとった</p>
<div class="math notranslate nohighlight">
\[
E[Y|Z] = E[X|Z]^T \beta + g(Z)
\]</div>
<p>を差し引くと</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|Z] = (X - E[X|Z])^T \beta + u
\]</div>
<p><span class="math notranslate nohighlight">\(\tilde{Y}_i = Y_i - E[Y_i|Z]\)</span>、<span class="math notranslate nohighlight">\(\tilde{X}_i = X_i - E[X_i|Z]\)</span>とおけば、OLS推定量の形になる</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{\mathrm{inf}}=\left(\sum_{i=1}^n \tilde{X}_i \tilde{X}_i^{\prime}\right)^{-1} \sum_{i=1}^n \tilde{X}_i \tilde{Y}_i
\]</div>
<p>が<span class="math notranslate nohighlight">\(E[Y|Z], E[X|Z]\)</span>が未知のため実行不可能である。<span class="math notranslate nohighlight">\(E[Y|Z], E[X|Z]\)</span>をそれぞれのノンパラメトリック推定量で置換して推定を行うことは可能であり、その推定量はroot-N consistentで漸近正規性を持つ</p>
<p><strong>参考</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://sites.google.com/site/naoyasueishij/teaching/nonpara">末石直也 - セミ・ノンパラメトリック計量分析 (京都大学)</a> 第5回 <a class="reference external" href="https://drive.google.com/file/d/0B6W_J4QoAI6wcWdwYkNwUU5DWTA/view?resourcekey=0--WtAUb3PgzgBpsw1XtvhzQ">部分線形モデルとセミパラメトリック推定量の性質</a></p></li>
<li><p>西山・人見（2023）『ノン・セミパラメトリック統計解析』、共立出版</p></li>
</ul>
</section>
</section>
</section>
<section id="id14">
<h2>参考<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>解説記事: <a class="reference external" href="https://www.web-nippyo.jp/13331/">機械学習×計量経済学：Double/Debiased Machine Learning | Web日本評論</a></p></li>
<li><p><a class="reference external" href="https://speakerdeck.com/masa_asa/debiased-ml?slide=32">[勉強会資料メモ] Double/Debiased ML - Speaker Deck</a></p></li>
<li><p><a class="reference external" href="https://matheusfacure.github.io/python-causality-handbook/22-Debiased-Orthogonal-Machine-Learning.html">22 - Debiased/Orthogonal Machine Learning — Causal Inference for the Brave and True</a></p></li>
<li><p><a class="reference external" href="https://causalml-book.org/">CausalML Book</a>の<a class="reference external" href="https://causalml-book.org/assets/chapters/CausalML_chap_13.pdf">Chapter 13</a></p></li>
</ul>
<section id="dmldid">
<h3>DMLによるDID<a class="headerlink" href="#dmldid" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://academic.oup.com/ectj/article/23/2/177/5722119">Double/debiased machine learning for difference-in-differences models | The Econometrics Journal | Oxford Academic</a></p>
<ul class="simple">
<li><p>解説: <a class="reference external" href="https://speakerdeck.com/masakat0/dmlniyoruchai-fen-falsechai-tui-ding">DMLによる差分の差推定 - Speaker Deck</a></p></li>
<li><p>関連: <a class="reference external" href="https://www.researchgate.net/profile/Di-Liu-124/publication/370440876_DoubleDebiased_Machine-learning_estimator_for_Difference-in-Difference_with_Multiple_Periods/links/645015ce5762c95ac3676c6e/Double-Debiased-Machine-learning-estimator-for-Difference-in-Difference-with-Multiple-Periods.pdf">Double-Debiased-Machine-learning-estimator-for-Difference-in-Difference-with-Multiple-Periods.pdf</a></p></li>
</ul>
</section>
<section id="youtube">
<h3>講義動画（Youtube）<a class="headerlink" href="#youtube" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://www.youtube.com/watch?v=eHOjmyoPCFU&amp;list=PLru50RuxzKFAsi9x3La3pidYURmi17ci6&amp;index=4&amp;t=479s">Double Machine Learning for Causal and Treatment Effects - YouTube</a></p>
<ul class="simple">
<li><p>MLでのcausal parametersの推定は良いとは限らない</p></li>
<li><p>double or orthogonalized MLとsample splittingによって、causal parametersの高精度な推定が可能</p></li>
</ul>
<p>Partially Linear Modelを使う</p>
<div class="math notranslate nohighlight">
\[
Y = D \theta_0 + g_0(Z) + U
, \hspace{1em} E[U|Z, D] = 0
\]</div>
<ul class="simple">
<li><p>MLをそのまま使うと一致推定量にならない（例えば<span class="math notranslate nohighlight">\(Y - D\)</span>で<span class="math notranslate nohighlight">\(g_0(Z)\)</span>をRandom Forestで学習しても、予測精度は良いがバイアスがある）</p></li>
<li><p>FWL定理を用いて、残差の回帰にするとよい</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{W} = Y - \hat{E[Y|Z]}\\
\hat{V} = D - \hat{E[D|Z]}
\end{split}\]</div>
<p>モーメント条件</p>
<ol class="arabic simple">
<li><p>Regression adjustment: <span class="math notranslate nohighlight">\(E[(Y - D \theta_0 - g_0(Z) ) D] = 0\)</span></p></li>
<li><p>“propensity score adjustment”: <span class="math notranslate nohighlight">\(E[(Y - D \theta_0) (D - E[D|Z])] = 0\)</span></p></li>
<li><p>Neyman-orthogonal (semi-parametrically efficient under homoscedasticity): <span class="math notranslate nohighlight">\(E[(\hat{W} - \hat{V}\theta_0) \hat{V}] = E[\{(Y - E[Y|Z]) - (D - E[D|Z])\theta_0\} (D - E[D|Z])] = 0\)</span></p></li>
</ol>
<p>3は不偏</p>
<p>Sample Splitting</p>
<p>Splittingによるefficiencyの低下問題</p>
<ul class="simple">
<li><p>2個に分けて2回やって平均とればfull efficiency → k個に分けての分析をk回やって平均とってもfull efficiency</p></li>
</ul>
</section>
</section>
<section id="id15">
<h2>応用研究<a class="headerlink" href="#id15" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/2002.08536">[2002.08536] Debiased Off-Policy Evaluation for Recommendation Systems</a></p>
<ul class="simple">
<li><p>PR: <a class="reference external" href="https://www.cyberagent.co.jp/news/detail/id=26585">AI Lab、推薦システム分野におけるトップカンファレンス「RecSys2021」にて共著論文採択 ー高次元なデータを使った意思決定評価の信頼性を改善ー | 株式会社サイバーエージェント</a></p></li>
</ul>
</section>
<section id="id16">
<h2>関連研究<a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/2305.04174">[2305.04174] Root-n consistent semiparametric learning with high-dimensional nuisance functions under minimal sparsity</a></p>
<ul class="simple">
<li><p>先行研究まとめがある</p></li>
</ul>
<p><a class="reference external" href="https://arxiv.org/abs/2008.06461">[2008.06461] Estimating Structural Target Functions using Machine Learning and Influence Functions</a></p>
<ul class="simple">
<li><p>Influence Function Learningという新しいフレームワークを提案</p></li>
</ul>
<p><a class="reference external" href="https://econml.azurewebsites.net/spec/flowchart.html">Library Flow Chart — econml 0.15.0 documentation</a></p>
<ul class="simple">
<li><p>派生モデルの使い分けについて</p></li>
</ul>
</section>
<section id="id17">
<h2>部分線形モデルに対するモーメント条件<a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h2>
<p>異なる推定量でどれだけバイアスが入るか確認したい</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="c1"># linear</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">D</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">g</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Y&quot;</span><span class="p">:</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="n">D</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>
<span class="n">X_mat</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">D_mat</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>ナイーブな推定量</p>
<div class="math notranslate nohighlight">
\[
E[UD] = E[(Y  - D\theta - g(X)) D] = 0
\]</div>
<div class="math notranslate nohighlight">
\[
\hat{\theta}_0=\left(\frac{1}{n} \sum_{i \in I} D_i^2\right)^{-1} \frac{1}{n} \sum_{i \in I} D_i\left(Y_i-\hat{g}_0\left(X_i\right)\right)
\]</div>
<p>かりに、<span class="math notranslate nohighlight">\(\hat{g}(X_i)\)</span>は<span class="math notranslate nohighlight">\(Y_i\)</span>を<span class="math notranslate nohighlight">\(X\)</span>に回帰する（予測値<span class="math notranslate nohighlight">\(\hat{Y}_i = \hat{g}(X_i)\)</span>を作る）とするなら</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>

<span class="c1"># Y ~ X</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Y_res := Y - g(X)</span>
<span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span> <span class="o">*</span> <span class="n">Y_res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;θ=</span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Y_res ~ D のOLS</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Y_res ~ -1 + D&#39;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>θ=1.981
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<tr>
  <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>D</th> <td>    1.9811</td> <td>    0.049</td> <td>   40.446</td> <td> 0.000</td> <td>    1.885</td> <td>    2.077</td>
</tr>
</table></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># gをDonsker条件を満たしそうな線形モデルにしたらどうなるか</span>
<span class="c1"># これは普通に残渣回帰でもないしだめか</span>
<span class="c1"># Y ~ X</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Y_res := Y - g(X)</span>
<span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span> <span class="o">*</span> <span class="n">Y_res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;θ=</span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>θ=2.177
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">coef_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([4.65807719])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO: モーメント条件の方向微分をplotできないものか？</span>
<span class="c1"># 横軸はthetaとr</span>
</pre></div>
</div>
</div>
</div>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
疑問：<span class="math notranslate nohighlight">\(\hat{g}(X)\)</span>はどう得る？</div>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(Y = g(X)\)</span>で学習させる？でもそうなると<span class="math notranslate nohighlight">\(E[Y|X] = \ell(X)\)</span>を使うRobinsonとの違いは…？</p>
</div>
</div>
<section id="dml-score-function">
<h3>DML score function<a class="headerlink" href="#dml-score-function" title="Permalink to this heading">#</a></h3>
<p>ネイマン直交性を満たす</p>
<div class="math notranslate nohighlight">
\[
E[UV] = E[ \{Y-D \theta-g(X)\}(D-m(X)) ]=0
\]</div>
<p><span class="math notranslate nohighlight">\(\hat{V}= D-\hat{m}_0(X)\)</span></p>
<div class="math notranslate nohighlight">
\[
\check{\theta}_0=\left(\frac{1}{n} \sum_{i \in I} \widehat{V}_i D_i\right)^{-1} \frac{1}{n} \sum_{i \in I} \widehat{V}_i\left(Y_i-\hat{g}_0\left(X_i\right)\right)
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>

<span class="c1"># Y ~ X</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># D ~ X</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

<span class="c1"># y_res := Y - g(X)</span>
<span class="c1"># V_hat := D - m(X)</span>
<span class="n">V_hat</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
<span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>

<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">V_hat</span> <span class="o">*</span> <span class="n">D</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">V_hat</span> <span class="o">*</span> <span class="n">Y_res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;θ=</span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Y_res ~ -1 + V_hat&#39;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y_res</span><span class="p">,</span>
        <span class="n">V_hat</span> <span class="o">=</span> <span class="n">V_hat</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>θ=2.872
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>V_hat</th> <td>    2.9672</td> <td>    0.032</td> <td>   93.561</td> <td> 0.000</td> <td>    2.905</td> <td>    3.029</td>
</tr>
</table></div></div>
</div>
</section>
<section id="robinson-style-partialling-out-score-function">
<h3>Robinson-style “partialling-out” score function<a class="headerlink" href="#robinson-style-partialling-out-score-function" title="Permalink to this heading">#</a></h3>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Robinson (1988)の推定量</div>
<p class="sd-card-text">部分線形モデル</p>
<div class="math notranslate nohighlight">
\[
Y = D \theta_0 + g(X) + U
, \quad E[U|D,X]=0
\]</div>
<p class="sd-card-text">の両辺を<span class="math notranslate nohighlight">\(X\)</span>で条件づけて期待値をとると</p>
<div class="math notranslate nohighlight">
\[
E[Y|X] = E[D|X] \theta_0 + g(X)
\]</div>
<p class="sd-card-text">これをモデルから差し引くと</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|X]
= \theta_0 (D - E[D|X]) + U
\]</div>
<p class="sd-card-text">という線形回帰の形になる。</p>
<p class="sd-card-text">ただし、<span class="math notranslate nohighlight">\(E[Y|X], E[D|X]\)</span>は未知なのでそれぞれノンパラメトリック推定量<span class="math notranslate nohighlight">\(\hat{\ell}(X), \hat{m}(X)\)</span>で置き換える。</p>
</div>
</div>
<p>こちらもネイマン直交性を満たす。</p>
<div class="math notranslate nohighlight">
\[
\mathrm{E}\left[\left\{(Y-E[Y \mid X])-(D-E[D \mid X]) \theta_0\right\}(D-E[D \mid X])\right]=0
\]</div>
<p><span class="math notranslate nohighlight">\(V=D - E[D|X] = D-m_0(X)\)</span>として、<span class="math notranslate nohighlight">\(\ell_0(X) := E[Y|X]\)</span>とすると</p>
<div class="math notranslate nohighlight">
\[
\mathrm{E}\left[\left((Y-\ell_0(X))-V \theta_0\right)V\right]=0
\]</div>
<p><a class="reference external" href="https://academic.oup.com/ectj/article/21/1/C1/5056401#130274171">DMLの論文のSection 4.1</a>でRobinsonのスコア関数もネイマン直交性を満たすことを述べているが、DMLのスコア関数が優れてるなどといった説明はとくに無いようだった。</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>FWL的にしてCrossFittingするという、<a class="reference external" href="https://matheusfacure.github.io/python-causality-handbook/22-Debiased-Orthogonal-Machine-Learning.html">Causal Inference for the Brave and True</a>の方法はRobinson-styleのscore functionと思われる。</p>
<p>Donsker条件を満たさないであろうLightGBMでもバイアスが入らないのはCrossFittingがそれだけバイアスを抑えているということだろうか。</p>
</aside>
</section>
<section id="id18">
<h3>cross fitting<a class="headerlink" href="#id18" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># cross-fittingあり</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;V_hat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;D&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;D&quot;</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Y_res&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Y_res ~ -1 + V_hat&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>V_hat</th> <td>    2.9471</td> <td>    0.032</td> <td>   92.429</td> <td> 0.000</td> <td>    2.885</td> <td>    3.010</td>
</tr>
</table></div></div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./econometrics/causal_machine_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="causal_forest.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Casual Tree/Forest</p>
      </div>
    </a>
    <a class="right-next"
       href="model_evaluation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">モデルの評価</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">概要</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">先行研究</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#donsker">Donsker条件</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">課題</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">前提知識</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">ナイーブな推定量と正則化バイアス</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">サンプル分割</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">ナイーブな推定量</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">直交化による正則化バイアスの打破</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#check-theta-0"><span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>の性質</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-fitting">Cross Fittingによる過学習のバイアスの除去</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Cross Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neyman-orthogonality">Neyman Orthogonality</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">Donsker条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">プラグイン推定量</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">プラグイン推定量の漸近正規性</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#g-0-x"><span class="math notranslate nohighlight">\(g_0(X)\)</span>の推定</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">部分線形モデル</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-1988">Robinson (1988)の推定量</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">参考</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dmldid">DMLによるDID</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#youtube">講義動画（Youtube）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">応用研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">関連研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">部分線形モデルに対するモーメント条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dml-score-function">DML score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-style-partialling-out-score-function">Robinson-style “partialling-out” score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">cross fitting</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By mitama
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>