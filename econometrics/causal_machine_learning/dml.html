

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Double/Debiased Machine Learning &#8212; データサイエンス関連+αのメモ</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-KCTWFQM00B"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KCTWFQM00B');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'econometrics/causal_machine_learning/dml';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="モデルの評価" href="model_evaluation.html" />
    <link rel="prev" title="Casual Tree/Forest" href="causal_forest.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">データサイエンス関連+αのメモ</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    データサイエンス関連+αのメモ
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">数学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../mathematics/introduction.html">数学の初歩</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mathematics/set_theory.html">集合論</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematics/calculus/index.html">微分積分学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/calculus/numerical_sequence.html">数列</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/function/index.html">関数</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/function.html">関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/trigonometric_function.html">三角関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/exp_and_log.html">指数関数と対数関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/function/limit.html">極限</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/differential/index.html">微分法</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/differential.html">微分法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/extreme_value.html">極値</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/basic_theorem.html">微分学の基礎的な定理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/taylor_approximation.html">テイラー近似</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/partial_derivative.html">偏微分</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/directional_derivative.html">方向微分</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/differential/total_differential.html">全微分</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/integral/index.html">積分法</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/integral/indefinite_integral.html">不定積分</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/integral/definite_integral.html">定積分</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/calculus/exercise/index.html">練習問題メモ</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/exercise/01.html">練習問題メモ 01</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/exercise/02.html">練習問題メモ 02</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/calculus/exercise/03.html">練習問題メモ 03</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/index.html">線形代数学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/vector/index.html">ベクトル</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/vector.html">ベクトルとベクトル空間</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/dot_product.html">内積</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/cross_product.html">クロス積（ベクトル積）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/direct_product.html">直積</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/vector/vector_space.html">ベクトル空間</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/matrix.html">行列</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/index.html">行列式</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/definition.html">行列式の定義</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/nature.html">行列式の性質</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/geometry.html">行列式の幾何的な解釈：体積拡大率</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/minor_determinant.html">余因子</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/determinant/permutation.html">置換</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/inverse_matrix.html">逆行列</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/linear_mapping.html">線形写像</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/rank.html">行列の階数（rank）</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/index.html">連立1次方程式</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/introduction.html">概要</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/gauss_elimination.html">Gauss-Jordanの消去法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/lu_decomposition.html">LU分解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/simultaneous_linear_equations/conjugate_gradient.html">共役勾配法</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/eigenvalue/index.html">固有値</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/eigenvalue/eigenvalue.html">固有値と固有ベクトル</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/eigenvalue/eigenvalue_and_covariance.html">固有値と共分散</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/linear_algebra/geometry.html">2次元と3次元の簡単な幾何学</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/complexity/index.html">計算量や数値計算について</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/complexity/inverse_matrix.html">逆行列の計算量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/complexity/implementation.html">numpyやscipyの逆行列の実装について</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/index.html">練習問題</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_01.html">練習問題 メモ 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_02.html">練習問題 メモ 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_03.html">練習問題 メモ 3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_04.html">練習問題 メモ 4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_05.html">練習問題メモ 5（連立1次方程式）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_06.html">練習問題メモ 6（正則行列）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_07.html">練習問題メモ 7（置換）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_08.html">練習問題メモ 8（行列式）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_09.html">練習問題メモ 9（余因子展開）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_10.html">練習問題メモ 10（特別な形をした行列式）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_11.html">練習問題メモ 11（行列式の幾何学的意味）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_12.html">練習問題メモ 12（行列の指数関数）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_13.html">練習問題メモ 13（ベクトル空間）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_14.html">練習問題メモ 14（1次独立と1次従属）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mathematics/linear_algebra/exercise/exercise_15.html">練習問題メモ 15（基底と次元）</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematics/mathematical_optimization/index.html">数理最適化</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/optimality_conditions.html">最適性条件</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/gradient_descent.html">勾配法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/lagrange.html">ラグランジュの未定乗数法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/knapsack_problem.html">ナップサック問題</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematics/mathematical_optimization/optimal_transport.html">最適輸送</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">統計学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/probability/index.html">確率</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/01_probability.html">確率</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/02_expectation.html">確率変数と期待値・分散</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/03_discrete_probability_distribution.html">離散確率分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/04_continuous_probability_distribution.html">連続確率分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/probability/05_nature_of_distribution.html">確率分布の性質</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/statistical_inference/index.html">統計的推測</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/01_sample_distribution.html">標本分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/02_generating_functions.html">母関数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/03_central_limit_theorem.html">中心極限定理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/04_point_estimation.html">点推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/05_interval_inference.html">区間推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/06_test.html">検定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/ci_and_test.html">信頼区間と検定の関係性</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/statistical_inference/likelihood_and_probability.html">尤度関数と確率関数の違いは何なのか？</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/divergence.html">ダイバージェンス</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/optimal_transport.html">最適輸送</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/bootstrap.html">Bootstrap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/nonparametric_density_estimation.html">ノンパラメトリック密度推定</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/correlation.html">順序尺度の相関係数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/sandwich_estimator.html">Sandwich Estimator</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/asymptotic_theory/index.html">漸近理論</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/introduction.html">漸近理論</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/landau_symbol.html">漸近オーダーの表記法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/law_of_large_numbers.html">大数の法則</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/consistency_simulation.html">一致性のシミュレーション</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/asymptotic_theory/empirical_processes.html">経験過程</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistics/bayes_statistics/index.html">ベイズ統計学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/bayes_statistics/bayes_estimation.html">ベイズ推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistics/bayes_statistics/mcmc.html">マルコフ連鎖モンテカルロ（MCMC）法</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistics/done_wrong.html">統計学の誤用や望ましい作法</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">統計モデリング</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/factor_analysis.html">因子分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/gaussian_process.html">ガウス過程回帰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/quantile_regression.html">分位点回帰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/survival_analysis.html">生存分析</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/sem/index.html">構造方程式モデリング</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/introduction.html">Structural Equation Modeling（SEM）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/statistic.html">統計量</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/regression_analysis.html">回帰分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/path_analysis.html">パス解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/mimic_pls.html">MIMICモデル &amp; PLSモデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/factor_analysis.html">因子分析モデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/evaluation.html">モデルの評価</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/sem/independence_model.html">Lavaanの独立モデル</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/index.html">ベイズ統計モデリング</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/introduction.html">概要</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/aic.html">AIC / BIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/waic.html">WAIC / WBIC / 渡辺ベイズ理論</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/bayes_modeling/mcmc.html">MCMC法</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/index.html">時系列分析</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/time_series_data.html">時系列データの特徴</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/data_transformation.html">時系列データの変換</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/arima_model.html">ARIMAモデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/time_series_analysis/state_space_model.html">状態空間モデル</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../statistical_modeling/symbolic_data_analysis.html">Symbolic Data Analysis</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../statistical_modeling/semiparametric/index.html">セミ・ノンパラメトリックモデル</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../statistical_modeling/semiparametric/introduction.html">概要</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">計量経済学・因果推論</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../rubin_causal_model.html">ルービンの因果モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../selection_bias.html">Selection Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experimental_design.html">実験デザイン</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pearl_causal_model.html">Pearl流の因果推論</a></li>
<li class="toctree-l1"><a class="reference internal" href="../causal_diagram.html">因果ダイアグラム</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ols/index.html">回帰分析</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ols/ols.html">概要</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/assumptions.html">OLSの仮定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/type_of_regression_model.html">線形回帰モデルの種類</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/mle_and_ols.html">最尤推定法に基づく正規方程式の導出</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/error_and_residual.html">誤差項と残差の違い</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/cef.html">条件付き期待値関数（CEF）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/ols_estimator.html">OLS推定量の性質</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/test_of_ols.html">OLSの検定・区間推定</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/ols_robust_standard_error.html">OLSのロバスト標準誤差</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/log_transformation.html">対数変換</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/omitted_variable_bias.html">欠落変数バイアス</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ols/fwl.html">FWL定理</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../propensity_score.html">傾向スコア</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../iv/index.html">操作変数法</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../iv/instrumental_variables.html">操作変数法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/gmm_and_iv.html">一般化モーメント法と操作変数法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/history.html">操作変数法の歴史</a></li>
<li class="toctree-l2"><a class="reference internal" href="../iv/simulatenous_equasion_model.html">同時方程式モデル</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../regression_discontinuity.html">RDD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fixed_effect_model.html">固定効果モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../difference_in_differences.html">Difference In Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="../synthetic_control.html">Synthetic Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../causalimpact.html">Causal Impact</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gmm.html">一般化モーメント法</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Causal Machine Learning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="meta_learner.html">Meta Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="causal_forest.html">Casual Tree/Forest</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Double/Debiased Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">モデルの評価</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../causal_discovery.html">統計的因果探索</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uplift_modeling.html">Uplift Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../literatures.html">よさそうな文献・サイト</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">機械学習</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/linear_models/index.html">線形モデル</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/regression/linear_regression.html">線形回帰</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/regression/ridge_regression.html">Ridge回帰</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/regression/lasso.html">LASSO</a></li>


<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/classification/linear_discriminant_analysis.html">線形判別モデル</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/linear_models/classification/logistic_regression.html">ロジスティック回帰</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/svm.html">Support Vector Machine</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/trees/index.html">Tree-based Algorithms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/decision_tree.html">決定木</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/gbdt.html">勾配ブースティング決定木</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/lightgbm.html">LightGBM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/lightgbm_quantize.html">Quantized Training of LightGBM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/ngboost.html">NGBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/catboost.html">CatBoost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/mondrian_forest.html">Mondrian Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/generalized_random_forest.html">Generalized Random Forest (GRF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/distributional_random_forest.html">Distributional Random Forest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/trees/tabular_data_and_trees.html">なぜTree-based modelはDeep Learningよりテーブルデータに強いのか</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/naive_bayes.html">ナイーブベイズ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/bayesian_network.html">ベイジアンネットワーク</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/dimension_reduction.html">次元削減</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/imbalanced_data.html">不均衡データ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/probability_prediction.html">確率予測</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/evaluation/evaluation.html">予測モデルの評価</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/cross_validation.html">交差検証</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/generalization_error.html">汎化誤差</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/aic.html">AICとCross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/metrics.html">Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/evaluation/uncertainty_of_prediction.html">予測の不確実性の評価</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/ml_ops/index.html">MLOps</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/ml_ops/ml_design_patterns.html">ML Design Patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/ml_ops/ml_system_design_patterns.html">ML System Design Pattern</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/overfitting.html">過学習と良性の過学習（Double Descent, Grokking）</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../machine_learning/feature_engineering.html">Feature Engineering</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../machine_learning/explainability/introduction.html">説明可能性</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/explainability/influence_function.html">影響関数（influence function）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/explainability/influence_function_with_linear_regression.html">Influence Function 線形回帰での例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../machine_learning/explainability/shap.html">SHAP</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">深層学習</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../deep_learning/history.html">深層学習の歴史</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep_learning/dl_and_tabular_data.html">Deep Learning and Tabular data</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/dnn/index.html">Deep Neural Network</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/dnn/mlp.html">多層パーセプトロン</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/cnn/index.html">CNN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/cnn/cnn.html">CNN</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/rnn/index.html">RNN</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/rnn/rnn.html">RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/rnn/lstm.html">LSTM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/rnn/gru.html">GRU</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/transformer/index.html">Transformer</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/transformer/algorithm.html">Transformerのアルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/transformer/analysis.html">Transformerの理論的解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/transformer/implementation.html">numpyでGPTを再現する</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">生成モデル</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/generative_models.html">生成モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/autoencoder.html">Autoencoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/gan.html">GAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative_models/diffusion_models.html">Diffusion Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">自然言語処理</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/normalization.html">テキストデータの前処理：表記揺れ、正規化</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/tokenization.html">トークン化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/language_model.html">言語モデル</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/embedding.html">単語の埋め込み</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/rnn.html">言語モデルとRNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../natural_language_processing/document_understanding.html">Document Understanding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">画像処理</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/introduction.html">画像認識</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/rotation_correction.html">傾き補正</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/distortion_correction.html">歪み補正・台形補正</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../image_processing/similarity_and_hashing.html">類似度・hash化</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">推薦システム</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/introduction.html">概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/collaborative_filtering.html">協調フィルタリング</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/matrix_factorization.html">行列分解に基づく推薦システム</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/factorization_machines.html">Factorization Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommender_system/bayesian_personalized_ranking.html">Bayesian Personalized Ranking (BPR)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ビジネス関連知識</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../business/revenue_structure.html">売上構造やKPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../business/accounting.html">会計</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../business/product_management/index.html">プロダクトマネジメント</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../business/product_management/prd.html">PRD（Product Requirements Document）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/product_management/ml_pdm.html">Machine Learning Product Management（MLPdM）</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../business/project_management/index.html">プロジェクトマネジメント</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../business/project_management/development_methods.html">システム開発手法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/project_management/roadmap.html">ロードマップ</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../business/business_administration/index.html">経営学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../business/business_administration/introduction.html">概要</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/business_administration/history.html">経営学史</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../business/business_administration/causal_process_tracing.html">因果過程追跡</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">データマネジメント</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../data_management/introduction.html">データマネジメント</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ソフトウェア工学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/foundations/index.html">ソフトウェア開発の基礎</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/programming.html">プログラミング</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/data_structure.html">データ構造</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/search_algorithms.html">探索アルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/sort_algorithms.html">ソートのアルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/mathematic_algorithms.html">数学的なアルゴリズム</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/foundations/other_algorithms.html">その他のアルゴリズム</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/development/index.html">ソフトウェア開発</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/frontend.html">フロントエンド開発</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/backend.html">バックエンド開発</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/networking.html">ネットワーク・通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/domain_driven_design.html">ドメイン駆動設計</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/development/serverless.html">Serverless</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">経済学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../economics/microeconomics/index.html">ミクロ経済学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../economics/microeconomics/demand_elasticity.html">需要の弾力性</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../economics/macroeconomics/index.html">マクロ経済学</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../economics/macroeconomics/national_income_accounts.html">国民経済計算</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../economics/macroeconomics/economic_growth.html">経済成長</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../economics/macroeconomics/microfoundations.html">ミクロ的基礎付け</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../economics/quantitative_economics.html">Quantitative Economics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">金融経済学</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/introduction.html">概要</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/optimal_portfolio.html">最適ポートフォリオ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/capm.html">CAPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/metrics.html">ファイナンスの指標たち</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/feature_neutralization.html">Feature Neutralization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/statistical_arbitrage.html">統計的裁定</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/asset_pricing.html">Asset Pricing</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../financial_economics/papers/index.html">論文メモ</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/papers/abcd_forcast.html">ABCD Forcast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/papers/deep_portfolio.html">Deep Portfolio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/papers/llm.html">計量ファイナンスにおけるLLMの活用</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../financial_economics/financial_time_series/index.html">金融時系列解析</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/financial_time_series/evaluation.html">時系列予測の性能検証</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../financial_economics/financial_time_series/augmentation.html">Data Augmentation</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../financial_economics/libraries.html">金融系ライブラリ</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/nigimitama/notes" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/econometrics/causal_machine_learning/dml.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Double/Debiased Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">概要</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">先行研究</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">課題</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">前提知識</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">（参考）残差回帰</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">残差回帰</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">部分線形モデルへの拡張</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">（参考）モーメント法</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">（参考）漸近理論</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">分布収束</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">部分線形モデル</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-1983">Robinson (1983)の推定量</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">ナイーブな推定量と正則化バイアス</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">直交化による正則化バイアスの打破</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#check-theta-0"><span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>の性質</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-fitting">Cross Fittingによる過学習のバイアスの除去</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">Cross Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neyman-orthogonality">Neyman Orthogonality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robinsondml">（疑問）Robinsonの推定量とDMLの違い、そうなった原因は？</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">Robinsonの推定量とDMLの違い</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">新規性は</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#donsker">Donsker条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">プラグイン推定量</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">プラグイン推定量の漸近正規性</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">Donsker条件</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">考察</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">機械学習を使うと常にバイアスが入る？？</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">参考</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dmldid">DMLによるDID</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#youtube">講義動画（Youtube）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">応用研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id24">関連研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id25">部分線形モデルに対するモーメント条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dml-score-function">DML score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-style-partialling-out-score-function">Robinson-style “partialling-out” score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id26">cross fitting</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="double-debiased-machine-learning">
<h1>Double/Debiased Machine Learning<a class="headerlink" href="#double-debiased-machine-learning" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Paper: <a class="reference external" href="https://academic.oup.com/ectj/article/21/1/C1/5056401?login=false">Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., &amp; Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters.</a></p></li>
<li><p>Python Package: <a class="reference external" href="https://docs.doubleml.org/stable/index.html">DoubleML</a></p></li>
</ul>
<section id="id1">
<h2>概要<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<section id="motivation">
<h3>motivation<a class="headerlink" href="#motivation" title="Permalink to this heading">#</a></h3>
<p>世の中の多くの現象は非線形な関係性が想定される。回帰分析は線形モデルであるため、モデルの定式化の誤りに起因するバイアスが生じかねない。</p>
<p>実際に関心のあるパラメータは少なく、交絡のコントロールのために入れている局外母数（nuisance parameters）は高次元になりがち。</p>
<p>局外母数を非線形モデルで表し、関心のあるパラメータは線形モデルで表現する部分線形モデル</p>
<div class="math notranslate nohighlight">
\[
Y = \theta D + g(X) + e
\]</div>
<p>を作り、非線形モデル<span class="math notranslate nohighlight">\(g(X)\)</span>を機械学習で構築したい</p>
</section>
<section id="id2">
<h3>先行研究<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>ノンパラメトリックモデルの文脈で研究があるが、Donsker条件を満たすような、複雑性の低い関数クラスでないとうまくいかないという理論解析がある</p>
<p>機械学習のようなDonsker条件を満たさない複雑な関数でも使えるようにしたい</p>
</section>
<section id="id3">
<h3>課題<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(g(X)\)</span>を機械学習で作って線形回帰するだけだと推定量は<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>の収束レートにならない</p>
<p>2つのバイアスがある</p>
<ol class="arabic simple">
<li><p>正則化バイアス（Reguralization bias）</p></li>
<li><p>過学習によるバイアス（Bias induced by overfifting）</p></li>
</ol>
<p>それぞれの対策として、</p>
<ol class="arabic simple">
<li><p>正則化バイアス → 残差回帰（直交化）で対応</p></li>
<li><p>過学習 → Cross-Fittingで対応</p></li>
</ol>
<p>を行う</p>
</section>
</section>
<section id="id4">
<h2>前提知識<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>知ってると理解を深めやすくなる前提知識まとめ</p>
<section id="id5">
<h3>（参考）残差回帰<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>DMLでは、FWL定理を利用した残差回帰を一般化する。</p>
<section id="id6">
<h4>残差回帰<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<p>通常の残差回帰は線形回帰モデル</p>
<div class="math notranslate nohighlight">
\[
Y = X_1 \beta_1 + X_2 \beta_2 + e
\]</div>
<p>を用いて</p>
<div class="math notranslate nohighlight">
\[
Y - X_2 \hat{\gamma} = (X_1 - X_2 \hat{\delta}) \beta_1
\]</div>
<p>のようにして関心のあるパラメータ<span class="math notranslate nohighlight">\(\beta_1\)</span>を推定する。</p>
<p>線形回帰モデルは回帰関数<span class="math notranslate nohighlight">\(E[Y|X]\)</span>を近似するため、上記の残差回帰は期待値を用いて</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|X_2] = (X_1 - E[X_1|X_2]) \beta_1
\]</div>
<p>と表すことができる。</p>
</section>
<section id="id7">
<h4>部分線形モデルへの拡張<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h4>
<p>部分線形モデル</p>
<div class="math notranslate nohighlight">
\[
Y = \theta D + g(X) + e
\]</div>
<p>においても同様に</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|X] = (D - E[D|X]) \beta_1
\]</div>
<p>とするアプローチをとる</p>
<div class="admonition-fwl admonition">
<p class="admonition-title">FWL定理</p>
<p>目的変数のベクトル<span class="math notranslate nohighlight">\(Y \in \mathbb{R}^{n\times 1}\)</span>、説明変数の行列<span class="math notranslate nohighlight">\(X \in \mathbb{R}^{n\times d}\)</span>と誤差項<span class="math notranslate nohighlight">\(e \in \mathbb{R}^{n\times 1}\)</span>による線形回帰モデル</p>
<div class="math notranslate nohighlight">
\[
Y = X \beta + e
\]</div>
<p>があるとする。</p>
<p>説明変数を<span class="math notranslate nohighlight">\(X = (X_1 | X_2)\)</span>と2つのグループに分割し、回帰係数ベクトル<span class="math notranslate nohighlight">\(\beta\)</span>も合わせて<span class="math notranslate nohighlight">\(\beta = (\beta_1 | \beta_2)^T\)</span>と2つに分割して</p>
<div class="math notranslate nohighlight">
\[
Y = X_1 \beta_1 + X_2 \beta_2 + e
\]</div>
<p>と表す。</p>
<p>この回帰モデルの<span class="math notranslate nohighlight">\(\beta_1\)</span>は、<strong>残差回帰</strong>（residual regression）と呼ばれる以下の手順に従うことでも得ることができる。</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(X_1\)</span>を<span class="math notranslate nohighlight">\(X_2\)</span>に回帰して残差<span class="math notranslate nohighlight">\(\tilde{X}_1\)</span>を得る：<span class="math notranslate nohighlight">\(\tilde{X}_1 = X_1 - X_2 \hat{\delta}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y\)</span>を<span class="math notranslate nohighlight">\(X_2\)</span>に回帰して残差<span class="math notranslate nohighlight">\(\tilde{Y}\)</span>を得る：<span class="math notranslate nohighlight">\(\tilde{Y} = Y - X_2 \hat{\gamma}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\tilde{Y}\)</span>を<span class="math notranslate nohighlight">\(\tilde{X}_1\)</span>に回帰させる：<span class="math notranslate nohighlight">\(\tilde{Y} = \tilde{X}_1 \beta_1\)</span></p></li>
</ol>
</div>
</section>
</section>
<section id="id8">
<h3>（参考）モーメント法<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p>確率変数<span class="math notranslate nohighlight">\(X\)</span>が<span class="math notranslate nohighlight">\(\theta\)</span>というパラメータをもつ分布に従うとする。</p>
<div class="math notranslate nohighlight">
\[
E[\psi(X; \theta)] = 0
\]</div>
<p>という条件（直交条件）を満たすスコア関数<span class="math notranslate nohighlight">\(\psi(X; \theta)\)</span>があるとき、標本<span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span>を使った直交条件</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum^n_{i=1} \psi(X_i; \theta) = 0
\]</div>
<p>を解いて<span class="math notranslate nohighlight">\(\theta\)</span>を推定する方法を <strong>モーメント法</strong> （method of moments） という。</p>
</section>
<section id="id9">
<h3>（参考）漸近理論<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h3>
<section id="id10">
<h4>分布収束<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h4>
<p>確率変数列<span class="math notranslate nohighlight">\(X_n\)</span>の分布関数がある確率変数<span class="math notranslate nohighlight">\(X\)</span>の分布関数に収束するとき</p>
<div class="math notranslate nohighlight">
\[
\mathrm{P}\left(X_n \leq x\right) \rightarrow \mathrm{P}(X \leq x)
\]</div>
<p><strong>分布収束</strong> （converge in distribution）や <strong>法則収束</strong>（convergence in law） や <strong>弱収束</strong> （weak convergence） と呼び、</p>
<div class="math notranslate nohighlight">
\[
X_n \overset{d}{\to} X,\quad
X_n \rightsquigarrow X
\]</div>
<p>などと表す。<span class="math notranslate nohighlight">\(X\)</span>がある分布<span class="math notranslate nohighlight">\(L\)</span>に従う場合は</p>
<div class="math notranslate nohighlight">
\[
X_n \overset{d}{\to} L,\quad
X_n \rightsquigarrow L
\]</div>
<p>などと表す。</p>
</section>
</section>
<section id="id11">
<h3>部分線形モデル<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
<p>結果変数<span class="math notranslate nohighlight">\(Y\)</span>、説明変数<span class="math notranslate nohighlight">\(X, Z\)</span>についての次のようなモデルを**部分線形モデル（Partially Linear Model）**という。</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
Y &amp;= X^T \beta + g(Z) + u\\
E[u|X,Z] &amp;= 0\\
E[u^2|X,Z] &amp;= \sigma^2(X, Z)\\
\end{align}
\end{split}\]</div>
<p>ここで、<span class="math notranslate nohighlight">\(g(\cdot)\)</span>は任意の関数（非線形の関数でもよい）である。<span class="math notranslate nohighlight">\(\sigma^2(\cdot, \cdot)\)</span>も未知の関数で、不均一分散を許容する。</p>
<p>関心のあるパラメータ<span class="math notranslate nohighlight">\(\beta\)</span>を解釈性の高い線形モデルで推定（パラメトリック推定）しつつ、影響を統制するためだけにモデルに投じている<span class="math notranslate nohighlight">\(Z\)</span>は関数形を特定せず推定（ノンパラメトリック推定）することができるため、部分線形モデルはセミパラメトリックモデルと呼ばれる。</p>
<section id="robinson-1983">
<h4>Robinson (1983)の推定量<a class="headerlink" href="#robinson-1983" title="Permalink to this heading">#</a></h4>
<p><span class="math notranslate nohighlight">\(Z\)</span>で両辺の条件付き期待値をとった</p>
<div class="math notranslate nohighlight">
\[
E[Y|Z] = E[X|Z]^T \beta + g(Z)
\]</div>
<p>を差し引くと</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|Z] = (X - E[X|Z])^T \beta + u
\]</div>
<p><span class="math notranslate nohighlight">\(\tilde{Y}_i = Y_i - E[Y_i|Z]\)</span>、<span class="math notranslate nohighlight">\(\tilde{X}_i = X_i - E[X_i|Z]\)</span>とおけば、OLS推定量の形になる</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{\mathrm{inf}}=\left(\sum_{i=1}^n \tilde{X}_i \tilde{X}_i^{\prime}\right)^{-1} \sum_{i=1}^n \tilde{X}_i \tilde{Y}_i
\]</div>
<p>が<span class="math notranslate nohighlight">\(E[Y|Z], E[X|Z]\)</span>が未知のため実行不可能である。<span class="math notranslate nohighlight">\(E[Y|Z], E[X|Z]\)</span>をそれぞれのノンパラメトリック推定量で置換して推定を行うことは可能であり、その推定量はroot-N consistentで漸近正規性を持つ</p>
<p><strong>参考</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://sites.google.com/site/naoyasueishij/teaching/nonpara">末石直也 - セミ・ノンパラメトリック計量分析 (京都大学)</a> 第5回 <a class="reference external" href="https://drive.google.com/file/d/0B6W_J4QoAI6wcWdwYkNwUU5DWTA/view?resourcekey=0--WtAUb3PgzgBpsw1XtvhzQ">部分線形モデルとセミパラメトリック推定量の性質</a></p></li>
<li><p>西山・人見（2023）『ノン・セミパラメトリック統計解析』、共立出版</p></li>
</ul>
</section>
</section>
</section>
<section id="id12">
<h2>ナイーブな推定量と正則化バイアス<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h2>
<p>話を簡潔にするために、サンプルを2つにランダム分割するとしよう：メインパートは<span class="math notranslate nohighlight">\(n\)</span>サンプルで<span class="math notranslate nohighlight">\(i\in I\)</span>のインデックスで表し、補助パートは<span class="math notranslate nohighlight">\(N-n\)</span>として<span class="math notranslate nohighlight">\(i \in I^c\)</span>とする。単純のため<span class="math notranslate nohighlight">\(n=N/2\)</span>とする。補助パートのサンプルで<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>を獲得し、<span class="math notranslate nohighlight">\(\theta_0\)</span>の推定にメインパートのサンプルを使うことにする</p>
<div class="math notranslate nohighlight">
\[
\hat{\theta}_0 = \left( \frac{1}{n} \sum_{i\in I} D_i^2 \right)^{-1}
\frac{1}{n} \sum_{i\in I} D_i (Y_i - \hat{g}_0(X_i))
\tag{1.3}
\]</div>
<p>推定量<span class="math notranslate nohighlight">\(\hat{\theta}_0\)</span>は一般に<span class="math notranslate nohighlight">\(1/\sqrt{n}\)</span>より遅い収束レート、つまり</p>
<div class="math notranslate nohighlight">
\[
|\sqrt{n} (\hat{\theta}_0 - \theta_0)| \overset{p}{\to} \infty
\]</div>
<p>となる。</p>
<p>この「劣った」振る舞いの背後には<span class="math notranslate nohighlight">\(g_0\)</span>の学習におけるバイアスがある。</p>
<p>ヒューリスティックにこの<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>の学習のバイアスのインパクトを説明すると、スケールされた<span class="math notranslate nohighlight">\(\hat{\theta}_0\)</span>の推定誤差は</p>
<div class="math notranslate nohighlight">
\[
\sqrt{n} (\hat{\theta}_0 - \theta_0) =
\underbrace{
    \left( \frac{1}{n} \sum_{i\in I} D_i^2 \right)^{-1}
    \frac{1}{\sqrt{n}} \sum_{i\in I} D_i U_i
}_{:=a}
+
\underbrace{
    \left( \frac{1}{n} \sum_{i\in I} D_i^2 \right)^{-1}
    \frac{1}{\sqrt{n}} \sum_{i\in I} D_i (g_0(X_i) - \hat{g}_0(X_i))
}_{:=b}
\]</div>
<p>である。</p>
<p>第1項<span class="math notranslate nohighlight">\(a\)</span>は<span class="math notranslate nohighlight">\(a \rightsquigarrow N(0, \bar{\Sigma})\)</span>となるので問題ない。第2項の<span class="math notranslate nohighlight">\(b\)</span>の項は正則化バイアス項で、一般に中心にならず発散する。first orderで以下を得る</p>
<div class="math notranslate nohighlight">
\[
b = (E[D_i^2])^{-1}
\frac{1}{\sqrt{n}} \sum_{i\in I}
m_0(X_i)(g_0(X_i) - \hat{g}_0(X_i)) + o_P(1)
\]</div>
<p>ヒューリスティックには、<span class="math notranslate nohighlight">\(b\)</span>は平均がゼロにならない<span class="math notranslate nohighlight">\(m_0(X_i)(g_0(X_i) - \hat{g}_0(X_i))\)</span>の<span class="math notranslate nohighlight">\(n\)</span>個の総和で、<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>で割られる。これらの項は非ゼロの平均になる。なぜなら高次元あるいは複雑な問題設定のために我々はlasso, ridge, boostingあるいはpenalized neural netsなどの正則化推定量を採用するためである。</p>
<p>それらの推定量において正則化は推定量の分散が爆発しないようにするものの相当なバイアスを引き起こす。とりわけ、<span class="math notranslate nohighlight">\(g_0\)</span>への<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>のバイアスの収束レートは、RMSEにおいて<span class="math notranslate nohighlight">\(n^{-\phi_g}\)</span>（<span class="math notranslate nohighlight">\(\phi_g &lt; 1/2\)</span>）である。ゆえに<span class="math notranslate nohighlight">\(b\)</span>は<span class="math notranslate nohighlight">\(D_i\)</span>が<span class="math notranslate nohighlight">\(m_0(X_i)\neq 0\)</span>で中心化されるとき<span class="math notranslate nohighlight">\(\sqrt{n} n^{-\phi_g} \to \infty\)</span>の確率的オーダーになることが期待され、よって<span class="math notranslate nohighlight">\(|\sqrt{n} (\hat{\theta}_0 - \theta_0)| \overset{p}{\to} \infty\)</span>となる</p>
<p><a class="reference external" href="https://docs.doubleml.org/stable/guide/basics.html">1. The basics of double/debiased machine learning — DoubleML documentation</a></p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">doubleml.datasets</span> <span class="kn">import</span> <span class="n">make_plr_CCDDHNR2018</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">n_rep</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_obs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
    <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">make_plr_CCDDHNR2018</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">dim_x</span><span class="o">=</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">non_orth_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">l_hat</span><span class="p">,</span> <span class="n">m_hat</span><span class="p">,</span> <span class="n">g_hat</span><span class="p">,</span> <span class="n">smpls</span><span class="p">):</span>
    <span class="n">u_hat</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">g_hat</span>
    <span class="n">psi_a</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
    <span class="n">psi_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">u_hat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_a</span><span class="p">,</span> <span class="n">psi_b</span>

<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLData</span>
<span class="kn">from</span> <span class="nn">doubleml</span> <span class="kn">import</span> <span class="n">DoubleMLPLR</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">face_colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s1">&#39;pastel&#39;</span><span class="p">)</span>
<span class="n">edge_colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s1">&#39;dark&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1111</span><span class="p">)</span>
<span class="n">ml_l</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">132</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ml_m</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">378</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">ml_g</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">ml_l</span><span class="p">)</span>

<span class="c1"># シミュレーションに時間がかかるので結果を保存する</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">result_json_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./dml_simulation_results.json&#39;</span><span class="p">)</span>
<span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># 実験1: ネイマン直交条件を満たさない場合</span>
<span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">result_json_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">theta_nonorth</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_nonorth&quot;</span><span class="p">]</span>
    <span class="n">se_nonorth</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_nonorth&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">theta_nonorth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="n">se_nonorth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
        <span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">obj_dml_plr_nonorth</span> <span class="o">=</span> <span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                                          <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span>
                                          <span class="n">n_folds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                          <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">score</span><span class="o">=</span><span class="n">non_orth_score</span><span class="p">)</span>
        <span class="n">obj_dml_plr_nonorth</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">this_theta</span> <span class="o">=</span> <span class="n">obj_dml_plr_nonorth</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">this_se</span> <span class="o">=</span> <span class="n">obj_dml_plr_nonorth</span><span class="o">.</span><span class="n">se</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">theta_nonorth</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>
        <span class="n">se_nonorth</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_se</span>

    <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_nonorth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_nonorth</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_nonorth&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">se_nonorth</span>
<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">((</span><span class="n">theta_nonorth</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">se_nonorth</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">face_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                  <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Non-orthogonal ML&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$(\hat{</span><span class="se">\\</span><span class="s1">theta}_0 - </span><span class="se">\\</span><span class="s1">theta_0)/\hat{\sigma}$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/f5317d42dfcc15a8a02f9c07c8e4f42a4de3e976f0e85f5da96c10f123593cbf.png" src="../../_images/f5317d42dfcc15a8a02f9c07c8e4f42a4de3e976f0e85f5da96c10f123593cbf.png" />
</div>
</div>
<section id="id13">
<h3>直交化による正則化バイアスの打破<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h3>
<p>直交化されたregressor <span class="math notranslate nohighlight">\(V=D-m_0(X)\)</span>を得るためにDからXの効果をpartialling outすることにより得られる直交化された式（orthogonalized formulation）を使う。具体的には</p>
<div class="math notranslate nohighlight">
\[
\hat{V} = D - \hat{m}_0(X)
\]</div>
<p>ここで<span class="math notranslate nohighlight">\(\hat{m}_0\)</span>は補助的サンプル（auxiliary sample）からを用いたML推定量。</p>
<p>DからXの効果をpartialling out したあとは、main sampleを使って<span class="math notranslate nohighlight">\(\theta_0\)</span>のdebiased ML (DML)を構築する</p>
<div class="math notranslate nohighlight">
\[
\check{\theta}_0 = \left( \frac{1}{n} \sum_{i\in I} \hat{V}_i D_i \right)^{-1}
\frac{1}{n} \sum_{i\in I} \hat{V}_i (Y_i - \hat{g}_0(X_i))
\]</div>
<p>近似的にDをXについて直交化し、<span class="math notranslate nohighlight">\(g_0\)</span>の推定値を引くことで近似的に交絡の直接効果を除去することで、<span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>は(1.3)の正則化バイアスを除去している。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 実験2: 直交化した場合</span>
<span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">result_json_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">theta_orth_nosplit</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_orth_nosplit&quot;</span><span class="p">]</span>
    <span class="n">se_orth_nosplit</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_orth_nosplit&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">theta_orth_nosplit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="n">se_orth_nosplit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
        <span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">obj_dml_plr_orth_nosplit</span> <span class="o">=</span> <span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                                               <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span>
                                               <span class="n">n_folds</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                               <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">,</span>
                                               <span class="n">apply_cross_fitting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">obj_dml_plr_orth_nosplit</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">this_theta</span> <span class="o">=</span> <span class="n">obj_dml_plr_orth_nosplit</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">this_se</span> <span class="o">=</span> <span class="n">obj_dml_plr_orth_nosplit</span><span class="o">.</span><span class="n">se</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">theta_orth_nosplit</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>
        <span class="n">se_orth_nosplit</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_se</span>

    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_orth_nosplit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_orth_nosplit</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_orth_nosplit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">se_orth_nosplit</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">((</span><span class="n">theta_orth_nosplit</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">se_orth_nosplit</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">face_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">edge_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Double ML (no sample splitting)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$(\hat{</span><span class="se">\\</span><span class="s1">theta}_0 - </span><span class="se">\\</span><span class="s1">theta_0)/\hat{\sigma}$&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;$(\\hat{\\theta}_0 - \\theta_0)/\\hat{\\sigma}$&#39;)
</pre></div>
</div>
<img alt="../../_images/31b87226d444808ce8922958d58a590fe6f423d6c4452fc41e8b0c8efdce4c3a.png" src="../../_images/31b87226d444808ce8922958d58a590fe6f423d6c4452fc41e8b0c8efdce4c3a.png" />
</div>
</div>
<section id="check-theta-0">
<h4><span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>の性質<a class="headerlink" href="#check-theta-0" title="Permalink to this heading">#</a></h4>
<p>スケールされた推定誤差は３つの要素に分解できる</p>
<div class="math notranslate nohighlight">
\[
\sqrt{n}(\check{\theta}_0 - \theta_0)
= a^* + b^* + c^*
\]</div>
<p><span class="math notranslate nohighlight">\(a^*\)</span>はmild conditionsのもとで以下を満たす</p>
<div class="math notranslate nohighlight">
\[
a^* = (E[V^2])^{-1}
\frac{1}{\sqrt{n}} \sum_{i\in I} V_i U_i \rightsquigarrow N(0, \Sigma)
\]</div>
<p><span class="math notranslate nohighlight">\(b^*\)</span>は<span class="math notranslate nohighlight">\(g_0, m_0\)</span>の推定における正則化バイアスの影響を捉える。具体的には</p>
<div class="math notranslate nohighlight">
\[
b^* = (E[V^2])^{-1}
\frac{1}{\sqrt{n}} \sum_{i\in I} 
(\hat{m}_0(X_i) - m_0(X_i))
(\hat{g}_0(X_i) - g_0(X_i))
\]</div>
<p>で、これは<span class="math notranslate nohighlight">\(\hat{m}_0\)</span>と<span class="math notranslate nohighlight">\(\hat{g}_0\)</span>の推定誤差の積に依存する。そのため、幅広い範囲のデータ生成過程のもとで消失させることが可能である。</p>
<p>実際、この項は<span class="math notranslate nohighlight">\(\sqrt{n}n^{-(\phi_m+\phi_g)}\)</span>で上界になり、ここで<span class="math notranslate nohighlight">\(n^{-\phi_m}, n^{-\phi_g}\)</span>はそれぞれ<span class="math notranslate nohighlight">\(\hat{m}_0, \hat{g}_0\)</span>の<span class="math notranslate nohighlight">\(m_0, g_0\)</span>への収束レートである。これは両者が比較的遅い収束レートで推定されたとしても、消失しうる。</p>
<p><span class="math notranslate nohighlight">\(c^*\)</span>は</p>
<div class="math notranslate nohighlight">
\[
c^* = o_P(1)
\]</div>
<p>となる。これが弱い条件のもとで成り立つことを保証するにあたって、sample splittingが重要な役割を果たす。</p>
</section>
</section>
<section id="cross-fitting">
<h3>Cross Fittingによる過学習のバイアスの除去<a class="headerlink" href="#cross-fitting" title="Permalink to this heading">#</a></h3>
<p>sample splittingは<span class="math notranslate nohighlight">\(c^*\)</span>が確率的に消失するために使われる。</p>
<p><span class="math notranslate nohighlight">\(c^*\)</span>は
$<span class="math notranslate nohighlight">\(
\frac{1}{\sqrt{n}} \sum_{i \in I} V_i (\hat{g}_0(X_i) - g_0(X_i))
\)</span><span class="math notranslate nohighlight">\(
などの項を含む。この項は推定誤差と構造的未観測要因の積の和を\)</span>1/\sqrt{n}$-normalizedしたものである。</p>
<p><span class="math notranslate nohighlight">\(E[V_i|X_i]=0\)</span>であることを思い出すと、この項は平均ゼロで分散は
$<span class="math notranslate nohighlight">\(
\frac{1}{n} \sum_{i \in I} (\hat{g}_0(X_i) - g_0(X_i))^2
\overset{p}{\to}
0
\)</span>$
であることがわかり、チェビシェフの不等式を使って確率的には消失することがわかる。</p>
<p>sample splittingの欠点は推定に使用するサンプル数が減ることによる効率性の低下である。しかし、mainとauxiliaryの2つでそれぞれ推定を行い、両者の平均を取ればfull efficiencyを取り戻す。この手続き（mainとauxiliaryの役割を取り替えて複数の推定値を取得しそれらの平均をとる）を「<strong>cross-fitting</strong>」と呼ぶことにする。一般にk-foldにすることもできる。Section 3で詳細を述べる。</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 実験2: 直交化した場合</span>
<span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">result_json_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">theta_dml</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_dml&quot;</span><span class="p">]</span>
    <span class="n">se_dml</span> <span class="o">=</span> <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_dml&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">theta_dml</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>
    <span class="n">se_dml</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_rep</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i_rep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_rep</span><span class="p">):</span>
        <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span>
        <span class="n">obj_dml_data</span> <span class="o">=</span> <span class="n">DoubleMLData</span><span class="o">.</span><span class="n">from_arrays</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
        <span class="n">obj_dml_plr</span> <span class="o">=</span> <span class="n">DoubleMLPLR</span><span class="p">(</span><span class="n">obj_dml_data</span><span class="p">,</span>
                                  <span class="n">ml_l</span><span class="p">,</span> <span class="n">ml_m</span><span class="p">,</span> <span class="n">ml_g</span><span class="p">,</span>
                                  <span class="n">n_folds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                  <span class="n">score</span><span class="o">=</span><span class="s1">&#39;partialling out&#39;</span><span class="p">)</span>
        <span class="n">obj_dml_plr</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">this_theta</span> <span class="o">=</span> <span class="n">obj_dml_plr</span><span class="o">.</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">this_se</span> <span class="o">=</span> <span class="n">obj_dml_plr</span><span class="o">.</span><span class="n">se</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">theta_dml</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>
        <span class="n">se_dml</span><span class="p">[</span><span class="n">i_rep</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_se</span>

    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;theta_dml&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta_dml</span>
    <span class="n">simulation_results</span><span class="p">[</span><span class="s2">&quot;se_dml&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">se_dml</span>
    <span class="n">simulation_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">simulation_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_json_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">simulation_results</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">((</span><span class="n">theta_dml</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">se_dml</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">face_colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="n">edge_colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                  <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Double ML with cross-fitting&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">mathcal</span><span class="si">{N}</span><span class="s1">(0, 1)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$(\hat{</span><span class="se">\\</span><span class="s1">theta}_0 - </span><span class="se">\\</span><span class="s1">theta_0)/\hat{\sigma}$&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;$(\\hat{\\theta}_0 - \\theta_0)/\\hat{\\sigma}$&#39;)
</pre></div>
</div>
<img alt="../../_images/25e0a6a7587b9df4d27c92413e5970d9f9ea6af84e2a0138caefb4409a8d1127.png" src="../../_images/25e0a6a7587b9df4d27c92413e5970d9f9ea6af84e2a0138caefb4409a8d1127.png" />
</div>
</div>
</section>
</section>
<section id="id14">
<h2>Cross Fitting<a class="headerlink" href="#id14" title="Permalink to this heading">#</a></h2>
</section>
<section id="neyman-orthogonality">
<h2>Neyman Orthogonality<a class="headerlink" href="#neyman-orthogonality" title="Permalink to this heading">#</a></h2>
<p>partialling outしたモーメント条件による推定量とナイーブな推定量は何が違うのか？</p>
<p>→ ネイマン直交性（Neyman orthogonality）がカギになる。</p>
<div class="admonition- admonition">
<p class="admonition-title">ネイマン直交性</p>
<p>サンプル<span class="math notranslate nohighlight">\(W\)</span>、関心のあるパラメータ<span class="math notranslate nohighlight">\(\theta_0\)</span>、局外母数<span class="math notranslate nohighlight">\(\eta_0\)</span>についてのスコア関数<span class="math notranslate nohighlight">\(\psi(W; \theta_0, \eta_0)\)</span>のベクトル<span class="math notranslate nohighlight">\(\psi = (\psi_1, \dots, \psi_d)^T\)</span>があるとする。このスコア関数の直交条件</p>
<div class="math notranslate nohighlight">
\[
E[\psi(W; \theta_0, \eta_0)] = 0
\]</div>
<p>について、ガトー微分が存在し、</p>
<p>ネイマン直交性（Neyman orthogonality）</p>
</div>
<blockquote>
<div><p>We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order.</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1901.09036.pdf">Foster, D. J., &amp; Syrgkanis, V. (2023). Orthogonal statistical learning. The Annals of Statistics, 51(3), 879-908.</a></p>
</div></blockquote>
<section id="robinsondml">
<h3>（疑問）Robinsonの推定量とDMLの違い、そうなった原因は？<a class="headerlink" href="#robinsondml" title="Permalink to this heading">#</a></h3>
<section id="id15">
<h4>Robinsonの推定量とDMLの違い<a class="headerlink" href="#id15" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>期待値を差し引くというFWL-style or Neiman-orthogonalityを使うのは一緒</p></li>
<li><p>モーメント条件が議論の根幹なのでOLS推定量の形には限らない？？</p></li>
<li><p>差し引く期待値の推定をMLにしたのがDML</p></li>
</ul>
</section>
<section id="id16">
<h4>新規性は<a class="headerlink" href="#id16" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>ML推定ゆえoverfitting biasが入る → Cross Fitting</p>
<ul>
<li><p>なんでMLだとbiasがはいる？高次元や複雑なモデルはDonsker conditionを満たさないから？</p></li>
</ul>
</li>
</ul>
<p><a class="reference external" href="https://academic.oup.com/ectj/article/21/1/C1/5056401#130274171">4. Inference in Partially Linear Models</a></p>
<p>PLR model</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
Y&amp;=D \theta_0+g_0(X)+U, &amp; E_P[U \mid X, D]=0 \\
D&amp;=m_0(X)+V, &amp; E_P[V \mid X]=0
\end{aligned}
\end{split}\]</div>
<p>の<span class="math notranslate nohighlight">\(\theta_0\)</span>の推定方法は2つある</p>
<p>1つめは</p>
<div class="math notranslate nohighlight">
\[
\psi(W ; \theta, \eta):=\{Y-D \theta-g(X)\}(D-m(X)), \quad \eta=(g, m)
\]</div>
<p>というスコア関数のもとでのDML</p>
<p>2つ目はRobinsonの”partialling-out”のスコア関数</p>
<div class="math notranslate nohighlight">
\[
\psi(W ; \theta, \eta):=\{Y-\ell(X)-\theta(D-m(X))\}(D-m(X)), \quad \eta=(\ell, m)
\]</div>
<p>を使うもの</p>
</section>
</section>
</section>
<section id="donsker">
<h2>Donsker条件<a class="headerlink" href="#donsker" title="Permalink to this heading">#</a></h2>
<p>Robinson (1988）などのセミパラメトリックモデルでも<span class="math notranslate nohighlight">\(\sqrt{n}\)</span>-consistentで漸近正規性をもつ推定量が作れていた</p>
<p>しかし、Donsker条件（Donsker condition）という条件を満たすクラスの関数（複雑性の低い関数）でなければ、漸近正規性をもたない（<a class="reference external" href="https://www.jstor.org/stable/2951475">Andrew 1994</a>）</p>
<p>機械学習モデルの収束レートが遅い（Donsker条件）→Cross Fitting</p>
<p><a class="reference external" href="https://twitter.com/masakat0/status/1314897112316870657">XユーザーのMasahiro Katoさん: 「Double/debiased machine learningはどういう手法かというと，機械学習はDonsker条件を満たさないので，サンプルを分割することによって，異なる部分集合間で独立だと思えるような局外母数の推定量を構築することで，収束率だけで漸近正規性を出す手法です．」 / X</a></p>
<section id="id17">
<h3>プラグイン推定量<a class="headerlink" href="#id17" title="Permalink to this heading">#</a></h3>
<p>モデルのパラメータをモーメント推定する際に、未知の関数をノンパラ推定量で置換してモーメント推定する推定量。
部分線形モデルを含む多くのセミパラメトリック推定量はプラグイン推定量に含まれる。</p>
<p>関心のあるパラメータを<span class="math notranslate nohighlight">\(\theta\)</span>、局外母数を<span class="math notranslate nohighlight">\(\eta\)</span>とし、セミパラメトリックモデルが確率変数を<span class="math notranslate nohighlight">\(W\)</span>として真のパラメータ<span class="math notranslate nohighlight">\((\theta_0, \eta_0)\)</span>のもとでモーメント条件</p>
<div class="math notranslate nohighlight">
\[
E[m(W, \theta_0, \eta_0)]=0
\]</div>
<p>を満たすとする（<span class="math notranslate nohighlight">\(m\)</span>は既知の関数）。
第1段階で局外母数<span class="math notranslate nohighlight">\(\eta_0\)</span>の一致推定量<span class="math notranslate nohighlight">\(\hat\eta\)</span>を得て、第2段階で標本モーメント条件</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n}\sum^n_{i=1} m(W_i, \hat\beta, \hat\eta)=0
\]</div>
<p>を満たすように<span class="math notranslate nohighlight">\(\hat\theta\)</span>を推定する。</p>
</section>
<section id="id18">
<h3>プラグイン推定量の漸近正規性<a class="headerlink" href="#id18" title="Permalink to this heading">#</a></h3>
<p>プラグイン推定量が漸近正規性をもつためには、次の2つの条件が鍵となる</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\nu_n(\hat\eta) - \nu(\eta_0) \overset{p}{\to} 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sqrt{n}E[m(X_i, \theta_0, \hat\eta)] = o_p(1)\)</span></p></li>
</ol>
<p>なお<span class="math notranslate nohighlight">\(m(\cdot)\)</span>はモーメント条件を構成する既知の関数で、<span class="math notranslate nohighlight">\(\nu_n\)</span>は経験過程（empirical process）とよばれる関数</p>
<div class="math notranslate nohighlight">
\[
\nu_n(\eta) = \frac{1}{\sqrt{n}} \sum_{i=1}^n ( m(X_i, \eta) - E[m(X_i, \eta)] )
\]</div>
<p>である。</p>
<p>ノンパラメトリック推定量の漸近理論ではDonsker条件を用いて条件1を示すことが多いようだが、高次元ではDonsker条件は満たされない</p>
<p>対処法のひとつは標本分割（sample splitting）だが、標本分割すると効率性が低下する。Chernozkov et al. (2018)ではCross-fittingにより効率性を落とさずに推定できることを示した</p>
</section>
<section id="id19">
<h3>Donsker条件<a class="headerlink" href="#id19" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="id20">
<h2>考察<a class="headerlink" href="#id20" title="Permalink to this heading">#</a></h2>
<section id="id21">
<h3>機械学習を使うと常にバイアスが入る？？<a class="headerlink" href="#id21" title="Permalink to this heading">#</a></h3>
<p>X-learnerとかどうなる？</p>
</section>
</section>
<section id="id22">
<h2>参考<a class="headerlink" href="#id22" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>解説記事: <a class="reference external" href="https://www.web-nippyo.jp/13331/">機械学習×計量経済学：Double/Debiased Machine Learning | Web日本評論</a></p></li>
<li><p><a class="reference external" href="https://speakerdeck.com/masa_asa/debiased-ml?slide=32">[勉強会資料メモ] Double/Debiased ML - Speaker Deck</a></p></li>
<li><p><a class="reference external" href="https://matheusfacure.github.io/python-causality-handbook/22-Debiased-Orthogonal-Machine-Learning.html">22 - Debiased/Orthogonal Machine Learning — Causal Inference for the Brave and True</a></p></li>
<li><p><a class="reference external" href="https://causalml-book.org/">CausalML Book</a>の<a class="reference external" href="https://causalml-book.org/assets/chapters/CausalML_chap_13.pdf">Chapter 13</a></p></li>
</ul>
<section id="dmldid">
<h3>DMLによるDID<a class="headerlink" href="#dmldid" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://academic.oup.com/ectj/article/23/2/177/5722119">Double/debiased machine learning for difference-in-differences models | The Econometrics Journal | Oxford Academic</a></p>
<ul class="simple">
<li><p>解説: <a class="reference external" href="https://speakerdeck.com/masakat0/dmlniyoruchai-fen-falsechai-tui-ding">DMLによる差分の差推定 - Speaker Deck</a></p></li>
<li><p>関連: <a class="reference external" href="https://www.researchgate.net/profile/Di-Liu-124/publication/370440876_DoubleDebiased_Machine-learning_estimator_for_Difference-in-Difference_with_Multiple_Periods/links/645015ce5762c95ac3676c6e/Double-Debiased-Machine-learning-estimator-for-Difference-in-Difference-with-Multiple-Periods.pdf">Double-Debiased-Machine-learning-estimator-for-Difference-in-Difference-with-Multiple-Periods.pdf</a></p></li>
</ul>
</section>
<section id="youtube">
<h3>講義動画（Youtube）<a class="headerlink" href="#youtube" title="Permalink to this heading">#</a></h3>
<p><a class="reference external" href="https://www.youtube.com/watch?v=eHOjmyoPCFU&amp;list=PLru50RuxzKFAsi9x3La3pidYURmi17ci6&amp;index=4&amp;t=479s">Double Machine Learning for Causal and Treatment Effects - YouTube</a></p>
<ul class="simple">
<li><p>MLでのcausal parametersの推定は良いとは限らない</p></li>
<li><p>double or orthogonalized MLとsample splittingによって、causal parametersの高精度な推定が可能</p></li>
</ul>
<p>Partially Linear Modelを使う</p>
<div class="math notranslate nohighlight">
\[
Y = D \theta_0 + g_0(Z) + U
, \hspace{1em} E[U|Z, D] = 0
\]</div>
<ul class="simple">
<li><p>MLをそのまま使うと一致推定量にならない（例えば<span class="math notranslate nohighlight">\(Y - D\)</span>で<span class="math notranslate nohighlight">\(g_0(Z)\)</span>をRandom Forestで学習しても、予測精度は良いがバイアスがある）</p></li>
<li><p>FWL定理を用いて、残差の回帰にするとよい</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{W} = Y - \hat{E[Y|Z]}\\
\hat{V} = D - \hat{E[D|Z]}
\end{split}\]</div>
<p>モーメント条件</p>
<ol class="arabic simple">
<li><p>Regression adjustment: <span class="math notranslate nohighlight">\(E[(Y - D \theta_0 - g_0(Z) ) D] = 0\)</span></p></li>
<li><p>“propensity score adjustment”: <span class="math notranslate nohighlight">\(E[(Y - D \theta_0) (D - E[D|Z])] = 0\)</span></p></li>
<li><p>Neyman-orthogonal (semi-parametrically efficient under homoscedasticity): <span class="math notranslate nohighlight">\(E[(\hat{W} - \hat{V}\theta_0) \hat{V}] = E[\{(Y - E[Y|Z]) - (D - E[D|Z])\theta_0\} (D - E[D|Z])] = 0\)</span></p></li>
</ol>
<p>3は不偏</p>
<p>Sample Splitting</p>
<p>Splittingによるefficiencyの低下問題</p>
<ul class="simple">
<li><p>2個に分けて2回やって平均とればfull efficiency → k個に分けての分析をk回やって平均とってもfull efficiency</p></li>
</ul>
</section>
</section>
<section id="id23">
<h2>応用研究<a class="headerlink" href="#id23" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/2002.08536">[2002.08536] Debiased Off-Policy Evaluation for Recommendation Systems</a></p>
<ul class="simple">
<li><p>PR: <a class="reference external" href="https://www.cyberagent.co.jp/news/detail/id=26585">AI Lab、推薦システム分野におけるトップカンファレンス「RecSys2021」にて共著論文採択 ー高次元なデータを使った意思決定評価の信頼性を改善ー | 株式会社サイバーエージェント</a></p></li>
</ul>
</section>
<section id="id24">
<h2>関連研究<a class="headerlink" href="#id24" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/2305.04174">[2305.04174] Root-n consistent semiparametric learning with high-dimensional nuisance functions under minimal sparsity</a></p>
<ul class="simple">
<li><p>先行研究まとめがある</p></li>
</ul>
<p><a class="reference external" href="https://arxiv.org/abs/2008.06461">[2008.06461] Estimating Structural Target Functions using Machine Learning and Influence Functions</a></p>
<ul class="simple">
<li><p>Influence Function Learningという新しいフレームワークを提案</p></li>
</ul>
<p><a class="reference external" href="https://econml.azurewebsites.net/spec/flowchart.html">Library Flow Chart — econml 0.15.0 documentation</a></p>
<ul class="simple">
<li><p>派生モデルの使い分けについて</p></li>
</ul>
</section>
<section id="id25">
<h2>部分線形モデルに対するモーメント条件<a class="headerlink" href="#id25" title="Permalink to this heading">#</a></h2>
<p>異なる推定量でどれだけバイアスが入るか確認したい</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="c1"># linear</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">D</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">g</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;Y&quot;</span><span class="p">:</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="n">D</span><span class="p">,</span> <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">X</span><span class="p">})</span>
<span class="n">X_mat</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">D_mat</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>ナイーブな推定量</p>
<div class="math notranslate nohighlight">
\[
E[UD] = E[(Y  - D\theta - g(X)) D] = 0
\]</div>
<div class="math notranslate nohighlight">
\[
\hat{\theta}_0=\left(\frac{1}{n} \sum_{i \in I} D_i^2\right)^{-1} \frac{1}{n} \sum_{i \in I} D_i\left(Y_i-\hat{g}_0\left(X_i\right)\right)
\]</div>
<p>かりに、<span class="math notranslate nohighlight">\(\hat{g}(X_i)\)</span>は<span class="math notranslate nohighlight">\(Y_i\)</span>を<span class="math notranslate nohighlight">\(X\)</span>に回帰する（予測値<span class="math notranslate nohighlight">\(\hat{Y}_i = \hat{g}(X_i)\)</span>を作る）とするなら</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>

<span class="c1"># Y ~ X</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Y_res := Y - g(X)</span>
<span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span> <span class="o">*</span> <span class="n">Y_res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;θ=</span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Y_res ~ D のOLS</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Y_res ~ -1 + D&#39;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>θ=1.981
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<tr>
  <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>D</th> <td>    1.9811</td> <td>    0.049</td> <td>   40.446</td> <td> 0.000</td> <td>    1.885</td> <td>    2.077</td>
</tr>
</table></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># gをDonsker条件を満たしそうな線形モデルにしたらどうなるか</span>
<span class="c1"># これは普通に残渣回帰でもないしだめか</span>
<span class="c1"># Y ~ X</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Y_res := Y - g(X)</span>
<span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D</span> <span class="o">*</span> <span class="n">Y_res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;θ=</span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>θ=2.177
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span><span class="o">.</span><span class="n">coef_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([4.65807719])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO: モーメント条件の方向微分をplotできないものか？</span>
<span class="c1"># 横軸はthetaとr</span>
</pre></div>
</div>
</div>
</div>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
疑問：<span class="math notranslate nohighlight">\(\hat{g}(X)\)</span>はどう得る？</div>
<p class="sd-card-text"><span class="math notranslate nohighlight">\(Y = g(X)\)</span>で学習させる？でもそうなると<span class="math notranslate nohighlight">\(E[Y|X] = \ell(X)\)</span>を使うRobinsonとの違いは…？</p>
</div>
</div>
<section id="dml-score-function">
<h3>DML score function<a class="headerlink" href="#dml-score-function" title="Permalink to this heading">#</a></h3>
<p>ネイマン直交性を満たす</p>
<div class="math notranslate nohighlight">
\[
E[UV] = E[ \{Y-D \theta-g(X)\}(D-m(X)) ]=0
\]</div>
<p><span class="math notranslate nohighlight">\(\hat{V}= D-\hat{m}_0(X)\)</span></p>
<div class="math notranslate nohighlight">
\[
\check{\theta}_0=\left(\frac{1}{n} \sum_{i \in I} \widehat{V}_i D_i\right)^{-1} \frac{1}{n} \sum_{i \in I} \widehat{V}_i\left(Y_i-\hat{g}_0\left(X_i\right)\right)
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>

<span class="c1"># Y ~ X</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># D ~ X</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mat</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

<span class="c1"># y_res := Y - g(X)</span>
<span class="c1"># V_hat := D - m(X)</span>
<span class="n">V_hat</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>
<span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">g</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_mat</span><span class="p">)</span>

<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">V_hat</span> <span class="o">*</span> <span class="n">D</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">V_hat</span> <span class="o">*</span> <span class="n">Y_res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;θ=</span><span class="si">{</span><span class="n">theta_hat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Y_res ~ -1 + V_hat&#39;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
        <span class="n">Y_res</span> <span class="o">=</span> <span class="n">Y_res</span><span class="p">,</span>
        <span class="n">V_hat</span> <span class="o">=</span> <span class="n">V_hat</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>θ=2.872
</pre></div>
</div>
<div class="output text_html"><table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>V_hat</th> <td>    2.9672</td> <td>    0.032</td> <td>   93.561</td> <td> 0.000</td> <td>    2.905</td> <td>    3.029</td>
</tr>
</table></div></div>
</div>
</section>
<section id="robinson-style-partialling-out-score-function">
<h3>Robinson-style “partialling-out” score function<a class="headerlink" href="#robinson-style-partialling-out-score-function" title="Permalink to this heading">#</a></h3>
<div class="sd-card sd-sphinx-override sd-mb-3 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Robinson (1988)の推定量</div>
<p class="sd-card-text">部分線形モデル</p>
<div class="math notranslate nohighlight">
\[
Y = D \theta_0 + g(X) + U
, \quad E[U|D,X]=0
\]</div>
<p class="sd-card-text">の両辺を<span class="math notranslate nohighlight">\(X\)</span>で条件づけて期待値をとると</p>
<div class="math notranslate nohighlight">
\[
E[Y|X] = E[D|X] \theta_0 + g(X)
\]</div>
<p class="sd-card-text">これをモデルから差し引くと</p>
<div class="math notranslate nohighlight">
\[
Y - E[Y|X]
= \theta_0 (D - E[D|X]) + U
\]</div>
<p class="sd-card-text">という線形回帰の形になる。</p>
<p class="sd-card-text">ただし、<span class="math notranslate nohighlight">\(E[Y|X], E[D|X]\)</span>は未知なのでそれぞれノンパラメトリック推定量<span class="math notranslate nohighlight">\(\hat{\ell}(X), \hat{m}(X)\)</span>で置き換える。</p>
</div>
</div>
<p>こちらもネイマン直交性を満たす。</p>
<div class="math notranslate nohighlight">
\[
\mathrm{E}\left[\left\{(Y-E[Y \mid X])-(D-E[D \mid X]) \theta_0\right\}(D-E[D \mid X])\right]=0
\]</div>
<p><span class="math notranslate nohighlight">\(V=D - E[D|X] = D-m_0(X)\)</span>として、<span class="math notranslate nohighlight">\(\ell_0(X) := E[Y|X]\)</span>とすると</p>
<div class="math notranslate nohighlight">
\[
\mathrm{E}\left[\left((Y-\ell_0(X))-V \theta_0\right)V\right]=0
\]</div>
</section>
<section id="id26">
<h3>cross fitting<a class="headerlink" href="#id26" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># cross-fittingあり</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;V_hat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;D&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;D&quot;</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Y_res&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;X&quot;</span><span class="p">]],</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="n">final_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Y_res ~ -1 + V_hat&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>V_hat</th> <td>    2.9471</td> <td>    0.032</td> <td>   92.429</td> <td> 0.000</td> <td>    2.885</td> <td>    3.010</td>
</tr>
</table></div></div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./econometrics/causal_machine_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="causal_forest.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Casual Tree/Forest</p>
      </div>
    </a>
    <a class="right-next"
       href="model_evaluation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">モデルの評価</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">概要</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">先行研究</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">課題</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">前提知識</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">（参考）残差回帰</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">残差回帰</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">部分線形モデルへの拡張</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">（参考）モーメント法</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">（参考）漸近理論</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">分布収束</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">部分線形モデル</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-1983">Robinson (1983)の推定量</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">ナイーブな推定量と正則化バイアス</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">直交化による正則化バイアスの打破</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#check-theta-0"><span class="math notranslate nohighlight">\(\check{\theta}_0\)</span>の性質</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-fitting">Cross Fittingによる過学習のバイアスの除去</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">Cross Fitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neyman-orthogonality">Neyman Orthogonality</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robinsondml">（疑問）Robinsonの推定量とDMLの違い、そうなった原因は？</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">Robinsonの推定量とDMLの違い</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">新規性は</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#donsker">Donsker条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">プラグイン推定量</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">プラグイン推定量の漸近正規性</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">Donsker条件</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">考察</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">機械学習を使うと常にバイアスが入る？？</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">参考</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dmldid">DMLによるDID</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#youtube">講義動画（Youtube）</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">応用研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id24">関連研究</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id25">部分線形モデルに対するモーメント条件</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dml-score-function">DML score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robinson-style-partialling-out-score-function">Robinson-style “partialling-out” score function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id26">cross fitting</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By mitama
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>