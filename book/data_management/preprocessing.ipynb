{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e486869-faf4-497a-b600-56700026071b",
   "metadata": {},
   "source": [
    "# データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212286ec-938c-4680-bcbc-ca0f67add796",
   "metadata": {},
   "source": [
    "## テキストデータの前処理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381297ee-f418-4536-a96a-b59220a8645e",
   "metadata": {},
   "source": [
    "### 表記ゆれと正規化\n",
    "\n",
    "同じものを表す文字列が複数あることを表記ゆれという。\n",
    "\n",
    "同じものを一意な文字列に揃えることを正規化という。\n",
    "\n",
    "自分で正規化のルールを書いてもいいが、便利なパッケージもある。\n",
    "\n",
    "#### unicodedataパッケージ\n",
    "\n",
    "Pythonに標準で入っているunicodedataパッケージを使う方法\n",
    "\n",
    "```python\n",
    "import unicodedata\n",
    "unicodedata.normalize(\"NFKC\", \"金額は￥１６８０です\")\n",
    "# -> '金額は¥1680です'\n",
    "unicodedata.normalize(\"NFKC\", \"㈱\")\n",
    "# -> '(株)'\n",
    "```\n",
    "\n",
    "参考：[Unicode正規化 - Wikipedia](https://ja.wikipedia.org/wiki/Unicode%E6%AD%A3%E8%A6%8F%E5%8C%96)\n",
    "\n",
    "#### neologdnパッケージ\n",
    "\n",
    "MeCabのために作られた正規化パッケージ\n",
    "\n",
    "[ikegami-yukino/neologdn: Japanese text normalizer for mecab-neologd](https://github.com/ikegami-yukino/neologdn)\n",
    "\n",
    "```python\n",
    "import neologdn\n",
    "neologdn.normalize(\"ﾊﾝｶｸｶﾅ\")\n",
    "# => 'ハンカクカナ'\n",
    "neologdn.normalize(\"全角記号！？＠＃\")\n",
    "# => '全角記号!?@#'\n",
    "neologdn.normalize(\"全角記号例外「・」\")\n",
    "# => '全角記号例外「・」'\n",
    "neologdn.normalize(\"いろんなハイフン˗֊‐‑‒–⁃⁻₋−\")\n",
    "# => 'いろんなハイフン-'\n",
    "neologdn.normalize(\"　　　ＰＲＭＬ　　副　読　本　　　\")\n",
    "# => 'PRML副読本'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e45a3-37fe-451e-af5b-506306fe5b12",
   "metadata": {},
   "source": [
    "### 形態素解析\n",
    "\n",
    "MeCabが有名だが、MeCab本体を入れる必要があるし、本体の更新がしばらく止まっている。\n",
    "\n",
    "Sudachiは本体の実装がまだあり、[SudachiPy](https://github.com/WorksApplications/SudachiPy)だけ入れればすぐ使えるので使いやすそう\n",
    "\n",
    "\n",
    "```python\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "\n",
    "tokenizer_obj = dictionary.Dictionary().create()\n",
    "\n",
    "# Multi-granular Tokenization\n",
    "\n",
    "mode = tokenizer.Tokenizer.SplitMode.C\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"国家公務員\", mode)]\n",
    "# => ['国家公務員']\n",
    "\n",
    "mode = tokenizer.Tokenizer.SplitMode.B\n",
    "[m.surface() for m in tokenizer_obj.tokenize(\"国家公務員\", mode)]\n",
    "# => ['国家', '公務員']\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
