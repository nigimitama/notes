{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a4398a-accf-4772-b8de-8cc7e7d2543b",
   "metadata": {},
   "source": [
    "# 表形式データ（Tabular data）の予測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934e414-ffc8-47aa-9df0-a8e4e806c261",
   "metadata": {},
   "source": [
    "## 手法比較\n",
    "\n",
    "### 最新の状況\n",
    "\n",
    "Hugging Faceの TabArena というTabular DataのLeaderboardがおそらく最新の比較結果を表示してくれている\n",
    "\n",
    ":::{admonition} TabArena\n",
    "\n",
    "[TabArena - a Hugging Face Space by TabArena](https://huggingface.co/spaces/TabArena/leaderboard)\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "### 過去の比較研究\n",
    "\n",
    ":::{card} When Do Neural Nets Outperform Boosted Trees on Tabular Data? (NeurIPS 2023)\n",
    "\n",
    "[McElfresh et al. (2023). When Do Neural Nets Outperform Boosted Trees on Tabular Data?](https://arxiv.org/abs/2305.02997)\n",
    "\n",
    "- 19のアルゴリズムを176データセットで比較した\n",
    "- GBDTとNNのどちらを採用するかより、GBDTの少々のパラメータチューニングのほうがよほど重要\n",
    "    - 唯一の例外はTabPFNで、n=3000のデータでもよく機能するし、平均的に他のアルゴリズムより優れた結果を出していた\n",
    "- 特徴量の分布が歪んでいたり不規則性があるときにGBDTはNNよりずっとよいパフォーマンスを出すことがわかった\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{card} Tabular Data: Deep Learning is Not All You Need\n",
    "\n",
    "[Shwartz-Ziv, R., & Armon, A. (2022). Tabular data: Deep learning is not all you need. Information Fusion, 81, 84-90.](https://arxiv.org/abs/2106.03253)\n",
    "\n",
    "TabNetなどの登場で「テーブルデータでもDeepが一番」という見方もあった時期\n",
    "\n",
    "「ハイパーパラメータをちゃんと設定すればXGBoostはTabNetなどのディープラーニングベースのアルゴリズムと同等以上のパフォーマンスになった」という報告\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card} Revisiting Deep Learning Models for Tabular Data (NeurIPS 2021)\n",
    "\n",
    "[Gorishniy, Y., Rubachev, I., Khrulkov, V., & Babenko, A. (2021). Revisiting deep learning models for tabular data. Advances in neural information processing systems, 34, 18932-18943.](https://proceedings.neurips.cc/paper_files/paper/2021/hash/9d86d83f925f2149e9edb0ac3b49229c-Abstract.html)\n",
    "\n",
    "- 表形式データ向けのDLアルゴリズムをレビュー\n",
    "- ResNet系のものとTransformer系を選出して最良のDLアルゴリズムとGBDTと11のデータセットで比較した\n",
    "- その結果、普遍的に（どのデータセットでも）優れたアルゴリズムはないという結論に\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9d8c8-cfe3-4807-b9f0-d507f179e097",
   "metadata": {},
   "source": [
    "## NNベースの手法\n",
    "\n",
    "### TabPFN\n",
    "\n",
    "Transformerベースで、膨大な合成データによる事前学習が行われている。\n",
    "\n",
    "LLMと同様にIn-context Learningの考え方を使用しており、Zero-shot予測も可能\n",
    "\n",
    "- v1: [[2207.01848] TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second](https://arxiv.org/abs/2207.01848)\n",
    "- v2: [Accurate predictions on small data with a tabular foundation model | Nature](https://www.nature.com/articles/s41586-024-08328-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66063127-1554-47f9-9a05-da4d5cc6de31",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "[最新のテーブルデータ向けNNモデルをまとめてみた](https://zenn.dev/mkj/articles/f7939cb221da14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
