{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb66af0a-6461-4552-87ab-aabd4fdbe481",
   "metadata": {},
   "source": [
    "# 01\n",
    "\n",
    "\n",
    "Feed-Forward-Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ca6d91-26cd-4f9b-ac73-74be342db6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.40663229 -0.85494722  1.16443209]\n",
      " [ 1.99868227 -2.67328285  1.12598685]\n",
      " [ 1.48731375 -1.01911847  1.21029006]\n",
      " [ 1.15213398 -1.55998636  0.54425216]\n",
      " [ 2.03657236 -2.36520637  1.31864512]\n",
      " [ 2.23340046 -3.08404013  1.24597028]\n",
      " [ 1.49560536 -1.37479342  1.08182005]\n",
      " [ 1.23958604 -1.19529964  0.81686411]\n",
      " [ 2.38592354 -3.06367859  1.44795461]\n",
      " [ 1.70561659 -2.92434904  0.63195006]]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    \"\"\"全結合層\"\"\"\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        return out\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        # 重みとバイアスの初期化\n",
    "        W1 = np.random.randn(I, H)\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "\n",
    "        # すべての重みをリストにまとめる\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = np.random.randn(10, 2)\n",
    "model = TwoLayerNet(2, 4, 3)\n",
    "s = model.predict(x)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31ce4c-5e74-4e93-a42e-ff857040a02e",
   "metadata": {},
   "source": [
    "## 逆伝播\n",
    "\n",
    "### MatMul（行列積）\n",
    "\n",
    "$xW$の部分について。\n",
    "\n",
    "$x_i$の微分\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_i} \n",
    "= \\sum_j \\frac{\\partial L}{\\partial y_j} \\frac{\\partial y_j}{\\partial x_i}\n",
    "$$\n",
    "\n",
    "は$\\frac{\\partial y_j}{\\partial x_i}=W_{ij}$から\n",
    "\n",
    "$$\n",
    "\\newcommand{\\b}[1]{\\boldsymbol{#1}}\n",
    "\\frac{\\partial L}{\\partial \\b{x}} \n",
    "= \\frac{\\partial L}{\\partial \\b{y}} \\b{W}^T\n",
    "$$\n",
    "\n",
    "となる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf8506-243d-48f0-90e8-1bcbb56132dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb4fe95b-6894-417a-a0d5-ad97b118c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f354cb-253d-42d1-9687-e463f8091498",
   "metadata": {},
   "source": [
    "## NNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4989f6bb-6396-4f19-a165-f9049360238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        return dx\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.y = None  # softmaxの出力\n",
    "        self.t = None  # 教師ラベル\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        # 教師ラベルがone-hotベクトルの場合、正解のインデックスに変換\n",
    "        if self.t.size == self.y.size:\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "\n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = self.y.copy()\n",
    "        dx[np.arange(batch_size), self.t] -= 1\n",
    "        dx *= dout\n",
    "        dx = dx / batch_size\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "761cdbf9-6630-4398-8e08-be260127b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        # 重みとバイアスの初期化\n",
    "        W1 = 0.01 * np.random.randn(I, H)\n",
    "        b1 = np.zeros(H)\n",
    "        W2 = 0.01 * np.random.randn(H, O)\n",
    "        b2 = np.zeros(O)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        score = self.predict(x)\n",
    "        loss = self.loss_layer.forward(score, t)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b2c1a2-719c-4a4d-8244-a90eea17690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-322be43cc967>:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  t = np.zeros((N*CLS_NUM, CLS_NUM), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "def spiral_data(seed=1984):\n",
    "    np.random.seed(seed)\n",
    "    N = 100  # クラスごとのサンプル数\n",
    "    DIM = 2  # データの要素数\n",
    "    CLS_NUM = 3  # クラス数\n",
    "\n",
    "    x = np.zeros((N*CLS_NUM, DIM))\n",
    "    t = np.zeros((N*CLS_NUM, CLS_NUM), dtype=np.int)\n",
    "\n",
    "    for j in range(CLS_NUM):\n",
    "        for i in range(N):#N*j, N*(j+1)):\n",
    "            rate = i / N\n",
    "            radius = 1.0*rate\n",
    "            theta = j*4.0 + 4.0*rate + np.random.randn()*0.2\n",
    "\n",
    "            ix = N*j + i\n",
    "            x[ix] = np.array([radius*np.sin(theta),\n",
    "                              radius*np.cos(theta)]).flatten()\n",
    "            t[ix, j] = 1\n",
    "\n",
    "    return x, t\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0\n",
    "\n",
    "x, t = spiral_data()\n",
    "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007af9a-ee6b-4748-b677-ad3ca70b8a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
