{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733cacd3-1521-4c79-8fb3-5d20629fd626",
   "metadata": {},
   "source": [
    "# OLS推定量の性質"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86755f18-49a4-4180-a44e-bb2bcd1a418d",
   "metadata": {},
   "source": [
    "## 重回帰モデル\n",
    "\n",
    "$N$個のサンプルと$D$個の説明変数からなるデータセットがあるとして、被説明変数を$Y \\in \\mathbb{R}^N$、説明変数を$X\\in \\mathbb{R}^{N\\times D}$、回帰係数ベクトルを$\\beta \\in \\mathbb{R}^D$、誤差項ベクトルを$u\\in\\mathbb{R}^N$とすると、重回帰モデルは\n",
    "\n",
    "$$\n",
    "Y = X \\beta + u\n",
    "$$\n",
    "\n",
    "と表すことができる。\n",
    "\n",
    "### 1行単位の重回帰モデルの表記\n",
    "\n",
    "ここで$i$番目のサンプルについての回帰式を次のように表記する\n",
    "\n",
    "$$\n",
    "Y_i = X_i^T \\beta + u_i, \\hspace{1em} i=1,\\dots, N\n",
    "$$\n",
    "\n",
    "ここで$X_i \\in \\mathbb{R}^D$はデータの行列$X$を1行取り出したもので、$Y_i, u_i \\in \\mathbb{R}$も1つのサンプルの被説明変数と誤差項である。\n",
    "\n",
    "この書き方をした重回帰モデルのOLS推定量は\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = \\beta +\n",
    "\\left(\n",
    "    \\frac{1}{N} X^T X\n",
    "\\right)^{-1}\n",
    "\\frac{1}{N} X^T u\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "単回帰でいうと\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = \\beta + \\frac{Cov(X, u)}{Var(X)}\n",
    "$$\n",
    "\n",
    "である。$X$に内生性がある、すなわち$Cov(X, u) \\neq 0$であると$\\hat{\\beta} \\neq \\beta$となる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9010c73-3d7d-43ab-9a14-fd2c47baa708",
   "metadata": {},
   "source": [
    ":::{admonition} OLSの仮定\n",
    "1. i.i.d.：$(Y, X)$は独立同一分布に従う\n",
    "2. 外生性：$E[u|X] = 0$\n",
    "3. 異常値がない：$X, u$は4次までのモーメントを持つ\n",
    "4. 多重共線性がない：任意の$\\sum_{j=0}^k a_j^2 = 1$となる$a_0,\\dots,a_k$について$E[(a_0 + a_1 X_1 + \\cdots + a_k X_k)^2]>0$が成り立つ\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4badf0a0-6349-4919-86d0-98114ed85a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 一致性\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{N} X^T X\n",
    "    &= \\frac{1}{N} \\sum^N_{i=1} X_i X_i^T\n",
    "    \\overset{p}{\\longrightarrow}\n",
    "    E[X_i X_i^T]\n",
    "\\\\\n",
    "\\frac{1}{N} X^T u\n",
    "    &= \\frac{1}{N} \\sum^N_{i=1} X_i u_i\n",
    "    \\overset{p}{\\longrightarrow}\n",
    "    E[X_i u_i]\n",
    "    = 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "多重共線性がないという仮定により$(E[X_i X_i^T])^{-1}$が存在する\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "    \\frac{1}{N} X^T X\n",
    "\\right)^{-1}\n",
    "\\frac{1}{N} X^T u\n",
    "\\overset{p}{\\longrightarrow}\n",
    "0\n",
    "$$\n",
    "\n",
    "よって\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}\n",
    "\\overset{p}{\\longrightarrow}\n",
    "\\beta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c58162-4089-44f5-9f82-c2103de6531f",
   "metadata": {},
   "source": [
    "## 漸近正規性\n",
    "\n",
    "式を整理して\n",
    "\n",
    "$$\n",
    "\\sqrt{N} \\hat{\\beta} - \\beta\n",
    "=\n",
    "\\left(\n",
    "    \\frac{1}{N} X^T X\n",
    "\\right)^{-1}\n",
    "\\frac{1}{\\sqrt{N}} X^T u\n",
    "$$\n",
    "\n",
    "とすると、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeeef63-2e88-43c2-bc15-88bacb0bf693",
   "metadata": {},
   "source": [
    "$$\n",
    "Var[X_i u_i] = E[u^2_i X_i X_i^T]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2b936-8fdc-4f0d-b611-b5e6769e2686",
   "metadata": {},
   "source": [
    "## バイアスとバリアンス\n",
    "\n",
    "最小二乗推定量はすべての線形不偏推定量の中で最もバリアンスが小さい（最良である）ことを示すガウス・マルコフの定理というものがある。\n",
    "\n",
    "```{margin} バイアスとバリアンス\n",
    "統計学・機械学習の分野では誤差をバイアス（bias）とバリアンス（variance）に分けて考えることが多い。\n",
    "\n",
    "バイアスは真の値$\\theta$とサンプルを変えて推定を繰り返したときの個々の推定結果の平均$E(\\hat{\\theta})$との差で、\n",
    "バリアンスは推定の分散$V(\\hat{\\theta})$である。\n",
    "\n",
    "$$\n",
    "Bias = \\theta - E(\\hat{\\theta})\\\\\n",
    "Variance = V(\\hat{\\theta})\n",
    "$$\n",
    "```\n",
    "\n",
    "\n",
    "```{note} ガウス・マルコフの定理\n",
    "各$i$について、\n",
    "\n",
    "- $E[\\varepsilon_i] = 0$\n",
    "- $V[\\varepsilon_i]=\\sigma^2 < \\infty$ が共通\n",
    "- $i \\neq j$のとき$E[\\varepsilon_i \\varepsilon_j] = 0$\n",
    "\n",
    "を満たすとき、最小二乗推定量$\\hat{\\beta}_{OLS}$はBLUEになる\n",
    "```\n",
    "\n",
    "\n",
    "#### 不偏性\n",
    "\n",
    "任意のパラメータの線形結合$\\theta=\\boldsymbol{\\alpha}^\\top {\\boldsymbol{\\beta}}$を考える。例えば$f(x_0)=x_0^\\top \\beta$がこの形である。\n",
    "\n",
    "この最小二乗推定値は\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\boldsymbol{\\alpha}^\\top \\hat{\\boldsymbol{\\beta}}\n",
    "= \\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "で、期待値をとると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E[\\hat{\\theta}]\n",
    "&= E[\\boldsymbol{\\alpha}^\\top \\hat{\\boldsymbol{\\beta}}]\\\\\n",
    "&= E[\\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top \\boldsymbol{y}]\\\\\n",
    "% &= \\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top E[\\boldsymbol{y}]\\\\\n",
    "&= E[\\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top (X\\beta + \\varepsilon) }] \\\\\n",
    "&= \\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top X \\beta + \\alpha^\\top (X^\\top X)^{-1} X^\\top} E[ \\varepsilon ] \\\\\n",
    "&= \\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top X \\beta}\\\\\n",
    "&= \\boldsymbol{\\alpha}^\\top \\boldsymbol{\\beta}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "```{margin}\n",
    "※誤差項は仮定により$E[\\boldsymbol{\\varepsilon}]=0$であるため\n",
    "```\n",
    "\n",
    "となり（※）、$\\hat{\\theta}$が不偏推定量である（$E[\\hat{\\theta}] = \\theta$）ことがわかる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f9f1f-7164-4ba5-8b1d-3016e9f7737a",
   "metadata": {},
   "source": [
    "### バリアンス\n",
    "\n",
    "$\\boldsymbol{\\alpha}^\\top \\boldsymbol{\\beta}$に対して不偏のまた別の線形推定量$\\boldsymbol{c}^\\top \\boldsymbol{y}$があるとする。\n",
    "\n",
    "両者の差を\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\alpha}^\\top \\boldsymbol{\\hat{\\beta}} - \\boldsymbol{c}^\\top \\boldsymbol{y}\n",
    "&= [ \\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X} - \\boldsymbol{c}^\\top ] \\boldsymbol{y}\\\\\n",
    "&=: \\boldsymbol{d}^\\top \\boldsymbol{y}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "とおく。このとき、不偏性$E[\\boldsymbol{c}^\\top \\boldsymbol{y}] = \\boldsymbol{\\alpha}^\\top \\boldsymbol{\\beta}$から両者の差の期待値はゼロになるべきであり、\n",
    "\n",
    "$$\n",
    "E[\\boldsymbol{d}^\\top \\boldsymbol{y}]\n",
    "= \\boldsymbol{d}^\\top \\boldsymbol{X} \\boldsymbol{\\beta} = 0\n",
    "$$\n",
    "\n",
    "が任意の$\\boldsymbol{\\beta}$について成り立たなければならないため、\n",
    "\n",
    "$$\n",
    "\\boldsymbol{d}^\\top \\boldsymbol{X} = \\boldsymbol{0}\n",
    "$$\n",
    "\n",
    "が成り立つ。\n",
    "\n",
    "\n",
    "次に、2つの確率変数$X, Y$に対し\n",
    "\n",
    "$$\n",
    "V[X+Y] = V[X] + 2 \\text{Cov}[X, Y] + V[Y]\n",
    "$$\n",
    "\n",
    "が成り立つから、$\\boldsymbol{c}^\\top \\boldsymbol{y}$の分散は\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "V[\\boldsymbol{c^\\top y}] &= V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} - d^\\top y }]\\\\\n",
    "&= V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }]\n",
    "- 2 \\text{Cov} [\\boldsymbol{ \\alpha^\\top (X^\\top X)^{-1} X^\\top y }, \\boldsymbol{ d^\\top y} ]\n",
    "+ V[\\boldsymbol{ d^\\top y}]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "と表すことができる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc4fcc-c557-4529-a6a9-feee7341a1ee",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cov}(A, B) = E[(A - E[A])(B - E[B])^\\top]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df690aac-43ad-4896-8dac-52b5537dac22",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cov}(a^\\top y, b^\\top y)\n",
    "= E[(a^\\top y - E[a^\\top y])(b^\\top y - E[b^\\top y])^\\top]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d273a-5ee8-4840-81b4-f6729deb94b6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cov}(a^\\top y, b^\\top y)\n",
    "= E[(a^\\top y - E[a^\\top y])(b^\\top y - E[b^\\top y])^\\top]\\\\\n",
    "= E[(a^\\top y - \\alpha^\\top \\beta)(b^\\top y - E[b^\\top y])^\\top]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c030c3d-abfe-4376-8f32-4cfa26f6c7bb",
   "metadata": {},
   "source": [
    "次に、2つの確率変数\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a^\\top y} = \\sum a_i y_i,\n",
    "\\hspace{2em}\n",
    "\\boldsymbol{b^\\top y} = \\sum b_i y_i\n",
    "$$\n",
    "\n",
    "の共分散は、誤差項$\\boldsymbol{\\varepsilon}$が無相関・等分散の仮定$V[\\boldsymbol{\\varepsilon}] = \\sigma^2 \\boldsymbol{I}$を満たすとき、\n",
    "\n",
    "$$\n",
    "\\text{Cov}[\\boldsymbol{a^\\top y, b^\\top y}]\n",
    "= \\text{Cov}[\\boldsymbol{a^\\top \\varepsilon, b^\\top \\varepsilon}]\n",
    "= \\sum a_i b_i \\sigma^2\n",
    "= (\\boldsymbol{a^\\top b}) \\sigma^2\n",
    "$$\n",
    "\n",
    "```{margin}\n",
    "TODO: 解説書く\n",
    "```\n",
    "\n",
    "となることから\n",
    "\n",
    "$$\n",
    "\\text{Cov}[\\boldsymbol{ \\alpha^\\top (X^\\top X)^{-1} X^\\top y, d^\\top y }]\n",
    "= \\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top d } \\cdot \\sigma^2\n",
    "$$\n",
    "\n",
    "となり、$\\boldsymbol{d}^\\top \\boldsymbol{X} = \\boldsymbol{0}$よりこれは0となる。\n",
    "\n",
    "よって\n",
    "\n",
    "$$\n",
    "V[\\boldsymbol{ c^\\top y }] = V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }] + V[\\boldsymbol{ d^\\top y }]\n",
    "$$\n",
    "\n",
    "が成り立ち、分散は非負なので\n",
    "\n",
    "$$\n",
    "V[\\boldsymbol{ c^\\top y }] \\geq V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }]\n",
    "$$\n",
    "\n",
    "を意味する。\n",
    "\n",
    "よって$\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }$は最良線形不偏推定量BLUEである。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e651f04-a61a-45a5-955b-fa5459144080",
   "metadata": {},
   "source": [
    "## OLS推定の幾何学的意味\n",
    "\n",
    "OLS推定量\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}} = (X^\\top X)^{-1} X^\\top \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "を$\\hat{\\boldsymbol{y}} = X \\hat{\\boldsymbol{\\beta}}$に代入すると\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{y}} = \\underbrace{ X (X^\\top X)^{-1} X^\\top }_{P} \\boldsymbol{y}\n",
    "= P \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "つまり、ベクトル$\\boldsymbol{y}$を行列$P = X (X^\\top X)^{-1} X^\\top$で射影したものとみなすことができる。\n",
    "\n",
    "この行列$P$は対称行列で、$P^2=P$となる。この2つの性質を満たす行列を射影行列という。\n",
    "\n",
    ":::{card}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P^2 & = PP \\\\\n",
    "& =(X(X^{\\top} X)^{-1} X^{\\top})(X(X^{\\top} X)^{-1} X^{\\top}) \\\\\n",
    "& =X(X^{\\top} X)^{-1}(X^{\\top} X)(X^{\\top} X)^{-1} X^{\\top} \\\\\n",
    "& =X(X^{\\top} X)^{-1} X^{\\top}\n",
    "=P\n",
    "\\end{aligned}\n",
    "$$\n",
    ":::\n",
    "\n",
    "射影行列は、$X$の列空間$\\Im X$にベクトルを正射影するという性質がある。$\\boldsymbol{y}$の$\\Im X$への射影が$\\hat{\\boldsymbol{y}}$で、垂線の足が誤差$\\boldsymbol{u}$となる。\n",
    "\n",
    "よって、最小二乗法は$\\boldsymbol{y}$から$\\Im X$への射影を求める操作であると捉えることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc94496-31f2-405e-9a02-bc435eecb5cd",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- 東京大学出版会『統計学入門』\n",
    "- 東京大学出版会『自然科学の統計学』\n",
    "- Hastie, T., Tibshirani, R., Friedman, J. H., & Friedman, J. H. (2009). The elements of statistical learning: data mining, inference, and prediction (Vol. 2, pp. 1-758). New York: springer.\n",
    "- [西山慶彦, 新谷元嗣, 川口大司, & 奥井亮. (2019). 計量経済学. Yūhikaku.](https://www.yuhikaku.co.jp/books/detail/9784641053854)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
