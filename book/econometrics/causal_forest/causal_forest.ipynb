{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c6d2f0-8084-47ea-9031-4c9cb767de62",
   "metadata": {},
   "source": [
    "# Casual Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3390f92-ae65-4997-a468-c9c0c23d5dfd",
   "metadata": {},
   "source": [
    "Causal Forest（因果フォレスト）とは、ランダムフォレストの枠組みを拡張し、個別化された因果効果（Heterogeneous Treatment Effect: HTE）を推定するための機械学習手法。\n",
    "\n",
    "一般化ランダムフォレスト（Generalized Random Forest: GRF）の一種として提案され、非線形性や高次元の特徴量を持つデータにおいて、因果推論を可能にする。\n",
    "\n",
    "\n",
    "Random Forestをカーネル重み付けとみなす視点に、Robinson (1988)の部分線形モデルを合わせたもの\n",
    "\n",
    "[一般化ランダムフォレストの理論と統計的因果推論への応用 - Speaker Deck](https://speakerdeck.com/tomoshige_n/ban-hua-randamuhuoresutonoli-lun-totong-ji-de-yin-guo-tui-lun-henoying-yong?slide=42)\n",
    "\n",
    "- [ランダムフォレストによる因果推論と最近の展開 - Speaker Deck](https://speakerdeck.com/tomoshige_n/randamuhuoresutoniyoruyin-guo-tui-lun-tozui-jin-nozhan-kai-838c3989-570d-49ca-b630-22044a798589)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea1198-85c3-4281-829a-bb257bdfb05e",
   "metadata": {},
   "source": [
    "### 背景：Random Forestの理論解析の進展\n",
    "\n",
    "- Delgado et al. (2014) はUCIデータセット121に対して様々な手法を適用し、Random Forestが優れた結果を示したと報告\n",
    "    - [Fernández-Delgado, M., Cernadas, E., Barro, S., & Amorim, D. (2014). Do we need hundreds of classifiers to solve real world classification problems?. The journal of machine learning research, 15(1), 3133-3181.](https://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf)\n",
    "    - その後はXGBoostやLightGBMも登場しており現在は違う結果となる可能性も高いが、少ない計算量・シンプルな手法ながら優れた結果ではあった\n",
    "- 漸近正規性が証明される → 信頼区間が得られる\n",
    "    - Wager (2014) は無限の木があるときのRandom Forestの予測値が漸近正規性をもつことを証明\n",
    "        - [Wager, S. (2014). Asymptotic theory for random forests. arXiv preprint arXiv:1405.0352.](https://arxiv.org/abs/1405.0352)\n",
    "    - Mentch & Hooker (2014) は有限の木での漸近正規性を証明\n",
    "        - [Mentch, L., & Hooker, G. (2014). Ensemble trees and clts: Statistical inference for supervised learning. stat, 1050, 25.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=be56bcaad2650c02017fb455808b047befc04c9e)\n",
    "- Scornet (2016) はRandom Forestがカーネル法の一種であることを示した\n",
    "    - [Scornet, E. (2016). Random forests and kernel methods. IEEE Transactions on Information Theory, 62(3), 1485-1500.](https://arxiv.org/abs/1502.03836)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa5eb9-306b-460e-a4ea-658449d0fd45",
   "metadata": {},
   "source": [
    "## 理論"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d610f81-559a-4581-bbf5-927318fec323",
   "metadata": {},
   "source": [
    "[Wager, S., & Athey, S. (2015). Estimation and inference of heterogeneous treatment effects using random forests. arXiv.](https://arxiv.org/abs/1510.04342)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3defa-9d92-4426-bd9d-10a1de0d4e24",
   "metadata": {},
   "source": [
    "### モデルの枠組み\n",
    "\n",
    "因果推論の標準的な設定として、観測データは以下の変数で構成される。\n",
    "\n",
    "- $Y_i$ : アウトカム（結果変数）\n",
    "- $W_i \\in \\{0,1\\}$ : 処置変数（1は処置群、0は対照群）\n",
    "- $X_i$ : 共変量ベクトル\n",
    "\n",
    "潜在アウトカムモデルは次のように表される。\n",
    "\n",
    "$$\n",
    "Y_i(1), \\ Y_i(0) \\quad \\text{（それぞれ処置あり・なしの場合のアウトカム）}\n",
    "$$\n",
    "\n",
    "観測されるアウトカムは\n",
    "\n",
    "$$\n",
    "Y_i = W_i Y_i(1) + (1 - W_i) Y_i(0)\n",
    "$$\n",
    "\n",
    "である。\n",
    "\n",
    "個別処置効果（Conditional Average Treatment Effect: CATE）は\n",
    "\n",
    "$$\n",
    "\\tau(x) = \\mathbb{E}[Y_i(1) - Y_i(0) \\mid X_i = x]\n",
    "$$\n",
    "\n",
    "として定義される。\n",
    "\n",
    "### 推定の流れ\n",
    "\n",
    "Causal Forestは以下のステップで構築される。\n",
    "\n",
    "1. **サンプルスプリット（Honest Splitting）**  \n",
    "   データを分割し、一方で木の分割規則を学習し、もう一方で効果を推定する。これにより過学習を抑制する。\n",
    "\n",
    "2. **分割基準**  \n",
    "   各ノードで、処置効果の異質性を最大化するように分割する。これは通常の回帰木や分類木とは異なり、平均アウトカムではなく効果のばらつきを重視する。\n",
    "\n",
    "3. **効果推定**  \n",
    "   終端ノード（リーフ）ごとに、処置群と対照群の平均アウトカム差を計算し、局所的なCATE推定値とする。\n",
    "\n",
    "4. **アンサンブル化**  \n",
    "   多数の木を構築して平均化し、安定した推定を得る。\n",
    "\n",
    "### 数式的表現\n",
    "\n",
    "各リーフ $L_b(x)$ におけるCATE推定は\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}_b(x) = \\bar{Y}_{1,b} - \\bar{Y}_{0,b}\n",
    "$$\n",
    "\n",
    "ここで、$\\bar{Y}_{1,b}$ はリーフ内の処置群平均、$\\bar{Y}_{0,b}$ はリーフ内の対照群平均である。\n",
    "\n",
    "最終的な推定値は、$B$ 本の木で平均して\n",
    "\n",
    "$$\n",
    "\\hat{\\tau}(x) = \\frac{1}{B} \\sum_{b=1}^B \\hat{\\tau}_b(x)\n",
    "$$\n",
    "\n",
    "とする。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a10ea-1b88-4e18-a72f-c1304947a50f",
   "metadata": {},
   "source": [
    "### 実装例\n",
    "\n",
    "代表的な実装としては、Rパッケージ `grf` や、Python実装の `econml` ライブラリがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ffd9b-b576-43b9-979a-ab813fb97e69",
   "metadata": {},
   "source": [
    "## 応用研究\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ee9f3-e1ea-4bd9-95f7-97dcecc6dd99",
   "metadata": {},
   "source": [
    "\n",
    "### 小売業においてクーポン配布のCATEを推定\n",
    "\n",
    "[How causal machine learning can leverage marketing strategies: Assessing and improving the performance of a coupon campaign | PLOS One](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0278937)\n",
    "\n",
    "- Kaggle公開データを使ってCATEを推定\n",
    "- 配布した5種類のクーポンのうち、ドラッグストア商品券と食品カテゴリ券の2種だけが有意に売上増効果を持つことが分かった。\n",
    "- 他のクーポンは統計的に効果が確認できず、無効な施策だった。\n",
    "- また効果の異質性分析から、「ドラッグストア券は事前購買額の大きい優良顧客に特に効果的」「一般食品券は購買額の少ないライト層に効果的」といったセグメント別の効果差が判明した\n",
    "- 例えば、既存ヘビーユーザーには日用品系クーポンで追加購買を促進でき、ライトユーザーには普段買わない食品クーポンで来店を促すと効果的。\n",
    "- この結果を踏まえ、クーポン配布の対象を効果の高いセグメントに絞る最適施策を導出したところ、全顧客に配布する場合と比べ費用対効果が大幅に向上した（少数配布で売上効果の大半を実現）。因果フォレストを用いることで、マーケティングROIを最大化する配布戦略の策定が可能になることを示した。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8506d-eb72-4eb5-9750-58b4ba594cbd",
   "metadata": {},
   "source": [
    "### Amazonの顧客ターゲティング\n",
    "\n",
    "[[2409.13847] Segment Discovery: Enhancing E-commerce Targeting](https://arxiv.org/abs/2409.13847)\n",
    "\n",
    "方法\n",
    "- Amazon社内の大規模実験データ（オンラインサービス等のABテスト複数）。例：ある定額サービスで解約防止のプロモメッセージを送る実験（数十万人規模）。\n",
    "- まずランダム化比較試験から顧客毎のCATEをCausal Forestやuplift modelで推定。次に企業側の制約（予算・接触可能数）を組み込んだ最適化アルゴリズム（Large-Scale Budget-Constrained Causal Forest）で最大効果のターゲット集合を選定。\n",
    "\n",
    "結果\n",
    "- 従来は、例えば離脱率の高い順に顧客に介入するなど予測モデルに基づくターゲティングが行われていた。しかし実験データを分析したところ、離脱リスクが極端に高い顧客層では、プロモメッセージを送っても効果が無いばかりか逆効果（介入で離脱率が悪化）になる場合があることが判明\n",
    "- 一方、リスクが中程度の層に大きなプラス効果が見られるなど、どの層に介入すべきかは単純な予測スコア順とは一致しないことが示された。\n",
    "- Causal Forestを用いるターゲティングでは、こうした「介入効果の高い層」を的確に抽出できる。実際、**あるサービスの例では従来ルールでは離脱スコア下位39.1%を一律介入対象としていたが、因果モデルに基づき効果の見込める顧客だけを選別したところ、むしろ全体の半数以下の配信で離脱抑止効果の75%以上を達成**できた。\n",
    "- このアプローチにより、顧客体験を損ねる無駄な介入を避けつつ、限られたマーケ予算で最大限の効果を上げることが可能となる。Amazon社の研究では複数のキャンペーンで有効性が検証されており、大規模パーソナライズドマーケティングへの因果機械学習の実用性を示すケースとなっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5efd6b-8281-45e5-b2bd-95b3ca2b783e",
   "metadata": {},
   "source": [
    "### 「少しずつ頻繁に」行う宿題の学習効果 McJames et al. (2024)\n",
    "\n",
    "- [Little and often: Causal inference machine learning demonstrates the benefits of homework for improving achievement in mathematics and science - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0959475224000951?via%3Dihub)\n",
    "- [Study reveals impact of homework on student achievement in math and science](https://phys.org/news/2024-09-reveals-impact-homework-student-math.html)\n",
    "\n",
    "方法：\n",
    "\n",
    "- 国際学力調査TIMSS 2019のデータから、アイルランドの中学2年生4,118人の数学・理科成績と家庭学習時間を分析\n",
    "- Bayesian Causal Forests で、宿題の頻度・長さを疑似介入変数として成績への因果効果を推定\n",
    "\n",
    "結果：\n",
    "- 週あたりの宿題実施回数を増やすことが学力向上に効果的である一方、1回あたりの宿題時間を延ばしても効果は頭打ちになる傾向が示された\n",
    "- 15分程度の短い課題でも長時間の課題と同等の効果があり、頻度を上げて宿題を小分けにする「Little and Often」戦略が有効であることがデータから裏付けられた。\n",
    "- **数学では「毎日少し」の宿題が最も成績を伸ばし** 、理科では週3～4回程度が効果的。\n",
    "- また従来の通説では家庭環境により宿題効果に差が出ると考えられていたが、本解析ではどの社会経済層の生徒も宿題の恩恵を等しく享受しており、一部の層だけが得をするわけではないことが示された。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520dcb09-cda3-46f9-aeba-76a4ff779c69",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [Causal TreeとCausal Forestの理論と実装 - tomtom58’s blog](https://tomtom58.hatenablog.com/entry/2024/07/15/211016)\n",
    "    - フルスクラッチ実装例がある\n",
    "- [計量経済学と 機械学習の交差点入り口 （公開用） | PDF](https://www.slideshare.net/slideshow/ss-67818872/67818872)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419429e-8c89-4e90-aebf-144fe0922354",
   "metadata": {},
   "source": [
    "## Causal Tree-Transformed Outcome\n",
    "\n",
    "[坪井優樹, 阪井優太, 鈴木佐俊, & 後藤正幸. (2023). Causal Tree に基づく選択バイアスを考慮した頑健な条件付き平均処置効果推定手法の提案. 情報処理学会論文誌, 64(9), 1399-1412.](https://www.it.mgmt.waseda.ac.jp/results/papers/IPSJ-JNL6409034.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41266bc-1bd3-4dab-9f21-bb00a280fc48",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419a431-91b0-4e96-8d32-e081f31a70f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
