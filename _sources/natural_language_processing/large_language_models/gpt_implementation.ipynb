{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b57222-b71e-491b-a62d-094e14a64f47",
   "metadata": {},
   "source": [
    "# GPTの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a2f70-9528-47b2-b2d6-8eaafd06bb59",
   "metadata": {
    "tags": []
   },
   "source": [
    "### コード詳細\n",
    "\n",
    "- GPT2のリポジトリ：[openai/gpt-2: Code for the paper \"Language Models are Unsupervised Multitask Learners\"](https://github.com/openai/gpt-2)\n",
    "- minGPT（シンプルにしたGPT）：[karpathy/minGPT: A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training](https://github.com/karpathy/minGPT)\n",
    "- minGPTを実装したブログ：[GPT from Scratch - Jake Tae](https://jaketae.github.io/study/gpt/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969eb46-05da-4b36-b04b-f76fbebe5c99",
   "metadata": {},
   "source": [
    "参考：[Python(PyTorch)で自作して理解するTransformer](https://zenn.dev/yukiyada/articles/59f3b820c52571)（Encoder-Decoder方式のTransformer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4a9d14-48c9-4d17-b50d-f306294be82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684a007b-2cc9-4c26-a90e-0a0ef6fc0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTConfig:\n",
    "    attn_dropout = 0.1\n",
    "    embed_dropout = 0.1\n",
    "    ff_dropout = 0.1\n",
    "    \n",
    "    def __init__(\n",
    "        self, vocab_size, max_len, **kwargs\n",
    "    ):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "class GPT1Config(GPTConfig):\n",
    "    num_heads = 12\n",
    "    num_blocks = 12\n",
    "    embed_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4baddbf7-b89a-43bb-93ca-7a11f5233dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.max_len = config.max_len\n",
    "        # 前処理層（Text & Positional Embedding）\n",
    "        self.tok_embed = nn.Embedding(config.vocab_size, embed_dim)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_len, embed_dim))\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(config.embed_dropout)\n",
    "        # Transformer blocks\n",
    "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.num_blocks)])\n",
    "        # Layer Normalization\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        # Feed Forward Network\n",
    "        self.fc = nn.Linear(embed_dim, config.vocab_size)\n",
    "    \n",
    "    def forward(self, x, target=None):\n",
    "        # batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        assert seq_len <= self.max_len, \"sequence longer than model capacity\"\n",
    "        \n",
    "        tok_embedding = self.tok_embed(x)\n",
    "        # tok_embedding.shape == (batch_size, seq_len, embed_dim)\n",
    "        pos_embedding = self.pos_embed[:, :seq_len, :]\n",
    "        # pos_embedding.shape == (1, seq_len, embed_dim)\n",
    "        x = self.dropout(tok_embedding + pos_embedding)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        x = self.fc(x)\n",
    "        # x.shape == (batch_size, seq_len, vocab_size)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer Block\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiheadAttention(config)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim),\n",
    "            nn.Dropout(config.ff_dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.embed_dim\n",
    "        self.num_heads = config.num_heads\n",
    "        assert embed_dim % self.num_heads == 0, \"invalid heads and embedding dimension configuration\"\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_dropout = nn.Dropout(config.attn_dropout)\n",
    "        self.proj_dropout = nn.Dropout(config.ff_dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\", \n",
    "            torch.tril(torch.ones(config.max_len, config.max_len))\n",
    "            .unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        # x.shape == (batch_size, seq_len, embed_dim)\n",
    "        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, -1).permute(0, 2, 3, 1)\n",
    "        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
    "        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
    "        # shape == (batch_size, num_heads, seq_len, head_dim)\n",
    "        \n",
    "        attn = torch.matmul(q, k_t) / math.sqrt(q.size(-1))\n",
    "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
    "        # マスキング処理\n",
    "        mask = self.mask[:, :, :seq_len, :seq_len]\n",
    "        attn = attn.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        attn = self.attn_dropout(attn)\n",
    "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        y = torch.matmul(attn, v)\n",
    "        # y.shape == (batch_size, num_heads, seq_len, head_dim)\n",
    "        y = y.transpose(1, 2)\n",
    "        # y.shape == (batch_size, seq_len, num_heads, head_dim)\n",
    "        y = y.reshape(batch_size, seq_len, -1)\n",
    "        # y.shape == (batch_size, seq_len, embed_dim)\n",
    "        y = self.proj_dropout(self.proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49381d6-4558-4540-aad8-f5a362cd0635",
   "metadata": {},
   "source": [
    "### Maskについて\n",
    "\n",
    "> Masked Self-Attention：自己回帰生成（順に要素を予測していくタスク）などに用いられる場合、Self-Attentionの各要素が自身より未来の要素を参照できないようにする必要がある。このため、Attention Matrixに三角状のマスクを適用し、各要素が未来の要素にアクセスできないようにすることで、過去と現在の情報のみから未来の情報を予測できるように学習させる。\n",
    ">\n",
    "> [30分で完全理解するTransformerの世界](https://zenn.dev/zenkigen/articles/2023-01-shimizu#%E6%A7%8B%E9%80%A0%E7%9A%84%E3%81%AA%E8%A9%B1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73cba1c9-563f-4040-98b0-3e2c85620715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 5\n",
    "\n",
    "mask = torch.tril(torch.ones(max_len, max_len)).unsqueeze(0).unsqueeze(0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a63620c-bef4-440e-a3bd-3eb089131c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0.],\n",
       "          [1., 1., 0.],\n",
       "          [1., 1., 1.]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 3\n",
    "\n",
    "mask = mask[:, :, :seq_len, :seq_len]\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969bbf3-59ca-4732-856a-6339773e551b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea127c2-e7e1-4cfa-b24f-9a611cfbba06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (tok_embed): Embedding(10, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention(\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "max_len = 12\n",
    "\n",
    "config = GPT1Config(vocab_size, max_len)\n",
    "model = GPT(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f739439-3623-4dc0-9dc5-35d36ca230c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903f301-de72-49cf-b8ad-d7e32231c618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
