{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa456de-1333-4ef0-8ce5-ba4c7caee619",
   "metadata": {},
   "source": [
    "# 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f316fc2b-88db-4120-a04c-4dd3b5b04a1f",
   "metadata": {},
   "source": [
    "## ノンパラメトリック法\n",
    "\n",
    "ノンパラメトリック法ではモデルの想定を弱めて構造の連続性や滑らかさのみを仮定することが多い。\n",
    "\n",
    "ノンパラではモデル想定の間違いによって生じる推定の誤りは少なくなり頑健になるものの、一般に推定精度が低くなる。\n",
    "\n",
    "$n$をサンプルサイズとして、一般にパラメトリック推定量は$n^{-1/2}$のオーダーで収束するが、ノンパラメトリック推定量は$n^{-1/2+\\delta} (\\delta >0)$のオーダーとなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82c311-de8a-486e-801d-51c75b6f010e",
   "metadata": {},
   "source": [
    "## セミパラメトリックモデル\n",
    "\n",
    "セミパラメトリックモデルは有限次元のパラメータとノンパラメトリックな関数の両方を未知パラメータとして含むモデル\n",
    "\n",
    "有限次元パラメータについてはパラメトリック推定量と同じ収束のオーダーになる。\n",
    "\n",
    "モデルを部分的にパラメトリックにできるため、関心のあるパラメータが有限次元である状況とは相性がいいアプローチ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f84ce-a6ff-4be9-8c1d-a4cc9bcd053b",
   "metadata": {},
   "source": [
    "## パラメトリックモデルの特定化を誤るとどうなるか\n",
    "\n",
    "仮定したパラメトリックモデルが誤っているとき、それに基づく推定量は本来意図した量とは異なる量を推定してしまう。\n",
    "\n",
    "### 例：最尤推定法\n",
    "\n",
    "ある密度関数$f_0(x)$から無作為標本$(X_1,\\dots,X_n)$が得られたとする。未知パラメータベクトル$\\theta$を持つパラメトリックモデル$f(x;\\theta), \\theta \\in \\Theta$を想定したとき、最尤推定量は\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} := \\arg \\max _\\theta \\sum_{i=1}^n \\log f\\left(X_i ; \\theta\\right)\n",
    "$$\n",
    "\n",
    "と定義される（$\\Theta$はパラメータがとりうる値の集合で、パラメータ空間という）。\n",
    "\n",
    "「モデルが正しい」とは\n",
    "\n",
    "$$\n",
    "\\exists \\theta_0 \\in \\Theta \\text { s.t. } f_0(x)=f\\left(x ; \\theta_0\\right)\n",
    "$$\n",
    "\n",
    "すなわち、尤度関数の設計に際して仮定した密度関数$f(x; \\theta_0)$が真の密度関数$f_0(x)$に一致する、ということ。このとき一定の正則条件が満たされれば$\\hat\\theta$は一致性、漸近正規性、効率性をもつ。つまり\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\xrightarrow{p} \\theta_0\\\\\n",
    "\\sqrt{n}(\\hat{\\theta}-\\theta) \\xrightarrow{d} N\\left(0, I\\left(\\theta_0\\right)^{-1}\\right)\n",
    "$$ \n",
    "\n",
    "が成り立つ。ただし$I(\\theta)$は情報行列\n",
    "\n",
    "$$\n",
    "I(\\theta)=-\\int \\frac{\\partial^2 \\log f(x ; \\theta)}{\\partial \\theta \\partial \\theta^T} f\\left(x ; \\theta_0\\right) d x\n",
    "$$\n",
    "\n",
    "である。情報行列の逆行列が一定の正則条件のもとでの漸近正規性・一致性を持つ推定量の漸近分散の下限となる。（これは不偏推定量の場合の Cramer-Raoの下限に対応する）\n",
    "\n",
    "### モデルが誤っている場合の最尤推定量\n",
    "\n",
    "もし、仮定したパラメトリックモデルが間違っている、すなわち、どの$\\theta \\in \\Theta$に対しても$f(x;\\theta) \\neq f_0(x)$なら、最尤推定量はカルバック・ライブラー距離を最小にする値\n",
    "\n",
    "$$\n",
    "\\theta_1=\\arg \\min \\int \\log \\frac{f_0(x)}{f(x ; \\theta)} f_0(x) d x\n",
    "$$\n",
    "\n",
    "に収束する（つまり$\\hat{\\theta} \\xrightarrow{p} \\theta_1$）。これを擬似真値という。\n",
    "\n",
    "\n",
    "真の分布が左右対称の単峰の分布ならある程度は真の分布に近い密度推定が得られる。しかし真の分布が二峰の場合は視覚的にも全く異なる推定結果となる。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
