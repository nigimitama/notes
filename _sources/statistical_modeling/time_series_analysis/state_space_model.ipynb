{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a1270d-d59b-437c-9b41-9034a3504c8e",
   "metadata": {},
   "source": [
    "# 状態空間モデル\n",
    "\n",
    "系列から系列への変換器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd76734-aee8-42f9-91ae-d352bdc882cb",
   "metadata": {},
   "source": [
    "## State Space Models\n",
    "\n",
    "SSMsのうち、DeepSSMsの論文で見かける式\n",
    "\n",
    "1次元のinput signal $x(t)$ を N次元のlatent space $h(t)$にしたあとに1次元のoutput signal $y(y)$に射影する。\n",
    "\n",
    "$$\n",
    "h'(t) = A h(t) + B x(t)\\\\\n",
    "y(t) =C h(t) + D x(t)\n",
    "$$\n",
    "\n",
    "ここで$A,B,C,D$はパラメータであり勾配降下法で学習される。$D=0$とおいて$y(t) =C h(t)$とするモデルもある。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4343f-06c0-4a56-810a-4bb29792ca6f",
   "metadata": {},
   "source": [
    "## ディープラーニングベースの状態空間モデル（Deep SSMs）\n",
    "\n",
    "[[2404.09516] State Space Model for New-Generation Network Alternative to Transformers: A Survey](https://arxiv.org/abs/2404.09516)\n",
    "\n",
    "### 構造化状態空間モデル（S4）\n",
    "\n",
    "[[2111.00396] Efficiently Modeling Long Sequences with Structured State Spaces](https://arxiv.org/abs/2111.00396)\n",
    "\n",
    "Structured State Space sequence model で S4と呼ばれる\n",
    "\n",
    "S4は状態空間モデル（SSMs）をRNNとCNNの組み合わせとして扱う\n",
    "\n",
    "\n",
    "### Manbda（S6）\n",
    "\n",
    "\n",
    "- [【Mamba入門】Transformerを凌駕しうるアーキテクチャを解説（独自の学習・推論コード含む） #Python - Qiita](https://qiita.com/peony_snow/items/649ecb307cd3b5c10aa7)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
