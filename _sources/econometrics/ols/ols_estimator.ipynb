{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733cacd3-1521-4c79-8fb3-5d20629fd626",
   "metadata": {},
   "source": [
    "# OLS推定量の性質"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86755f18-49a4-4180-a44e-bb2bcd1a418d",
   "metadata": {},
   "source": [
    "## 重回帰モデル\n",
    "\n",
    "$N$個のサンプルがあり、$i$番目のサンプルについての回帰式を次のように表記する\n",
    "\n",
    "$$\n",
    "Y_i = X_i^T \\beta + u_i, \\hspace{1em} i=1,\\dots, N\n",
    "$$\n",
    "\n",
    "ここで$X_i \\in \\mathbb{R}^D$は説明変数の行列$X\\in \\mathbb{R}^{N\\times D}$を1行取り出したもので、$Y_i, u_i \\in \\mathbb{R}$も1つのサンプルの被説明変数と誤差項である。\n",
    "\n",
    "\n",
    "行列表記にすると\n",
    "\n",
    "$$\n",
    "Y = X \\beta + u\n",
    "$$\n",
    "\n",
    "と表すことができる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e6038-cffb-4344-835e-e82adff6f8cc",
   "metadata": {},
   "source": [
    "### OLS推定量\n",
    "\n",
    "目的関数は残差の二乗和であるため、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\beta) &= u^T u\\\\\n",
    "&= (Y - X \\beta)^T (Y - X \\beta)\\\\\n",
    "&= Y^T Y - Y^T X \\beta - (X\\beta)^T Y + (X \\beta)^T X \\beta\\\\\n",
    "&= Y^T Y - 2 \\beta^T X^T Y + \\beta^T X^T X \\beta\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    ":::{margin} 式展開メモ\n",
    "- $(X \\beta)^T = \\beta^T X^T$ のため\n",
    "- $Y^T X \\beta$と$(X\\beta)^T Y$は同値のスカラーになるので$2 \\beta^T X^T Y$と1つの項にまとめた\n",
    ":::\n",
    "\n",
    "\n",
    "である。これを微分してゼロとおくと\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(\\beta)}\n",
    "{\\partial \\beta}\n",
    "=  - 2 X^T Y + 2 X^T X \\beta\n",
    "= 0\n",
    "$$\n",
    "\n",
    "となり、$\\beta$について解くと\n",
    "\n",
    "$$\n",
    "\\beta\n",
    "= (X^T X)^{-1} X^T Y\n",
    "$$\n",
    "\n",
    ":::{margin} 式展開メモ\n",
    "ベクトル$x$、行列$A$に対し\n",
    "\n",
    "$$\n",
    "\\frac{\\partial A x}{\\partial x^T} = A\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial x^T B x}{\\partial x} = (B + B^T) x\n",
    "$$\n",
    "\n",
    "もしBが対称行列なら$(B + B^T) x = 2Bx$\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3641bfdb-671d-4732-883d-4b58dc646e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 5., 7.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x0 = np.array([1, 1, 1])\n",
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([2, 8, 9])\n",
    "X = np.array([x0, x1, x2]).T\n",
    "beta = np.array([3, 5, 7]) # 真のbeta\n",
    "y = X @ beta\n",
    "\n",
    "# OLS推定量\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "beta_hat.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f89c34-0389-4379-87dc-916356a73a53",
   "metadata": {},
   "source": [
    "## OLS推定量の別表記\n",
    "\n",
    "一致性や不偏性の議論のための準備として、OLS推定量を変形する。\n",
    "\n",
    "重回帰モデル$Y = X\\beta + u$をOLS推定量$\\hat{\\beta} = (X^T X)^{-1} X^T Y$に代入して変形すると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\beta}\n",
    "&= (X^T X)^{-1} X^T Y\\\\\n",
    "&= (X^T X)^{-1} X^T (X\\beta + u)\\\\\n",
    "&= (X^T X)^{-1} X^T X\\beta + (X^T X)^{-1} X^T u\\\\\n",
    "&= \\beta + (X^T X)^{-1} X^T u\\\\\n",
    "&= \\beta + \\left(\\frac{1}{N} X^T X\\right)^{-1} \\frac{1}{N} X^T u\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "単回帰でいうと\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = \\beta + \\frac{Cov(X, u)}{Var(X)}\n",
    "$$\n",
    "\n",
    "である。$X$に内生性がある、すなわち$Cov(X, u) \\neq 0$であると$\\hat{\\beta} \\neq \\beta$となる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46793a7-5246-49ad-ac57-7259c8b51678",
   "metadata": {},
   "source": [
    "### OLS推定量のバリアンス\n",
    "\n",
    "$\\hat{\\beta} = \\beta + (X^T X)^{-1} X^T u$ は $u\\sim N(0, \\sigma^2 I)$の仮定より、$\\hat{\\beta} \\sim N(\\beta, \\sigma^2 (X^\\top X)^{-1})$となる。\n",
    "\n",
    "よって $\\operatorname{Var}[\\hat{\\beta}] = \\sigma^2 (X^\\top X)^{-1}$ となる\n",
    "\n",
    "::::{dropdown} 証明\n",
    "\n",
    "以下の定理を使う\n",
    "\n",
    ":::{card} 定理\n",
    "\n",
    "$u$を確率変数ベクトルとし、$\\mu\\in\\mathbb{R}^n$、$b\\in\\mathbb{R}^p$、$C\\in\\mathbb{R}^{p\\times n}$、$\\operatorname{rank} C = p$とする。\n",
    "\n",
    "$u \\sim N(\\mu, \\Sigma)$ のとき、$Cu + b \\sim N(C\\mu + b, C\\Sigma C^\\top)$\n",
    "\n",
    ":::\n",
    "\n",
    "$C := (X^T X)^{-1} X^T$とおけば\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C^T = [(X^T X)^{-1} X^T]^T\n",
    "&= X [(X^T X)^{-1}]^T \\quad (\\because (AB)^T = B^T A^T) \\\\\n",
    "&= X [(X^T X)^T]^{-1} \\quad (\\because (A^{-1})^T = (A^T)^{-1} ) \\\\\n",
    "&= X (X^T X)^{-1} \\quad (\\because (X^T X)^T=X^T X ) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "であるため、$u\\sim N(0, \\sigma^2 I)$ の仮定が満たされるとき、\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\beta + C u \\sim N(\\beta, \\sigma^2 CC^T)\\\\\n",
    "&= \\beta + (X^T X)^{-1} X^T u \\sim \n",
    "N(\\beta, \\sigma^2 (X^T X)^{-1} X^T X (X^T X)^{-1} )\\\\\n",
    "&= \\beta + (X^T X)^{-1} X^T u \\sim \n",
    "N(\\beta, \\sigma^2 (X^T X)^{-1})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9010c73-3d7d-43ab-9a14-fd2c47baa708",
   "metadata": {},
   "source": [
    ":::{admonition} OLSの仮定\n",
    "1. i.i.d.：$(Y, X)$は独立同一分布に従う\n",
    "2. 外生性：$E[u|X] = 0$\n",
    "3. 異常値がない：$X, u$は4次までのモーメントを持つ\n",
    "4. 多重共線性がない：任意の$\\sum_{j=0}^k a_j^2 = 1$となる$a_0,\\dots,a_k$について$E[(a_0 + a_1 X_1 + \\cdots + a_k X_k)^2]>0$が成り立つ\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a69a88-bb97-4173-b6f1-07fc0abbd9f2",
   "metadata": {},
   "source": [
    "## 不偏性\n",
    "\n",
    "### 外生性\n",
    "\n",
    "単回帰モデル$Y = \\alpha + \\beta X + u$を例にとる。\n",
    "\n",
    ":::{admonition} 外生性\n",
    "\n",
    "説明変数$X$と誤差項$u$が\n",
    "\n",
    "$$\n",
    "E(u | X) = 0\n",
    "$$\n",
    "\n",
    "を満たすとき、$X$は外生変数であるという。\n",
    ":::\n",
    "\n",
    "また、外生性の条件は別の表現もできる\n",
    "\n",
    ":::{admonition} $X$と$u$の直交\n",
    "説明変数$X$が外生変数ならば、\n",
    "\n",
    "$$\n",
    "E(u) = 0, E(X, u) = 0\n",
    "$$\n",
    ":::\n",
    "\n",
    ":::{dropdown} 証明\n",
    "$$\n",
    "E(X u) = E_{X}[ E(X u | X) ] = E_{X}[ X \\underbrace{ E(u|X) }_{ =0 } ] = E_{X}(X\\cdot 0) = 0\n",
    "\\\\\n",
    "E(u) = E_{X}[ \\underbrace{ E(u|X) }_{ =0 } ] = 0\n",
    "$$\n",
    ":::\n",
    "\n",
    "さらに、共分散との関係も導出できる\n",
    "\n",
    ":::{admonition} $X$と$u$の無相関\n",
    "説明変数$X$が外生変数ならば、\n",
    "\n",
    "$$\n",
    "Cov(X, u) = 0\n",
    "$$\n",
    ":::\n",
    "\n",
    ":::{dropdown} 証明\n",
    "\n",
    "$$\n",
    "Cov(X, u) = \\underbrace{ E(X u) }_{ =0 }\n",
    "- E(X) \\underbrace{ E(u) }_{ =0 }\n",
    "= 0\n",
    "$$\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a9806-69da-4279-b236-4f31e1c2c2e3",
   "metadata": {},
   "source": [
    "### OLS推定量の不偏性\n",
    "\n",
    "単回帰モデル$Y = \\alpha + \\beta X + u$のOLS推定量$\\beta$の確率極限は\n",
    "\n",
    "$$\n",
    "\\DeclareMathOperator{\\cov}{\\text{Cov}}\n",
    "\\DeclareMathOperator{\\var}{\\text{Var}}\n",
    "\\DeclareMathOperator{\\plim}{\\text{plim}}\n",
    "\\plim \\beta = \\beta + \\frac{\\cov(X, u)}{\\var(X)}\n",
    "$$\n",
    "\n",
    "となる。外生性が満たされるとき$\\cov(X, u) = 0$であるため、$\\plim \\beta = \\beta$となり、OLS推定量は母回帰係数の不偏推定量となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a168ea-a916-4588-a32e-22e6e150e002",
   "metadata": {},
   "source": [
    "::::{dropdown} 証明\n",
    "$$\n",
    "\\DeclareMathOperator{\\cov}{\\text{Cov}}\n",
    "\\DeclareMathOperator{\\var}{\\text{Var}}\n",
    "\\DeclareMathOperator{\\plim}{\\text{plim}}\n",
    "\\begin{align}\n",
    "\\plim \\beta\n",
    "&= \\frac{\\cov(X, Y)}{\\var(X)}\\\\\n",
    "&= \\frac{\\cov(X, \\alpha + \\beta X + u)}{\\var(X)}\\\\\n",
    "&= \\frac{\\cov(X, \\alpha) + \\cov(X, \\beta X) + \\cov(X, u) }{\\var(X)}\\\\\n",
    "&= \\frac{\\beta \\var(X) + \\cov(X, u) }{\\var(X)}\\\\\n",
    "&= \\beta + \\frac{\\cov(X, u)}{\\var(X)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    ":::{admonition}（参考）和の共分散\n",
    "標本値、確率変数の和は、加える前の個々の共分散の和になる。すなわち、共分散においては分配法則が成り立つ。\n",
    "\n",
    "$$\n",
    "\\cov(X + Z, Y) = \\cov(X, Y) + \\cov(Z, Y)\n",
    "$$\n",
    "\n",
    "参考：[確率統計 – 分散と共分散 – TauStation](http://taustation.com/statistics-variance-and-covariance/)\n",
    ":::\n",
    "\n",
    ":::{admonition} （参考）共分散と定数\n",
    "\n",
    "$\\alpha, \\beta$は定数と考えると、\n",
    "\n",
    "$$\n",
    "\\cov(X, \\alpha)\n",
    "= E(X \\alpha) - E(X) E(\\alpha)\\\\\n",
    "= \\alpha E(X) - \\alpha E(X)\\\\\n",
    "= 0\n",
    "$$\n",
    "\n",
    "であり\n",
    "\n",
    "$$\n",
    "\\cov(X, \\beta X)\n",
    "= E(X \\beta X) - E(X) E(\\beta X)\\\\\n",
    "= \\beta E(X^2) - \\beta E(X)^2\\\\\n",
    "= \\beta \\var(X)\n",
    "$$\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4badf0a0-6349-4919-86d0-98114ed85a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 一致性\n",
    "\n",
    "異常値がない（$X, u$は4次までのモーメントを持つ）という仮定と大数の法則により以下が成立する\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{N} X^T X\n",
    "    &= \\frac{1}{N} \\sum^N_{i=1} X_i X_i^T\n",
    "    \\overset{p}{\\longrightarrow}\n",
    "    E(X_i X_i^T)\n",
    "\\\\\n",
    "\\frac{1}{N} X^T u\n",
    "    &= \\frac{1}{N} \\sum^N_{i=1} X_i u_i\n",
    "    \\overset{p}{\\longrightarrow}\n",
    "    E(X_i u_i)\n",
    "    = 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "多重共線性がないという仮定により$(E(X_i X_i^T))^{-1}$が存在する\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "    \\frac{1}{N} X^T X\n",
    "\\right)^{-1}\n",
    "\\frac{1}{N} X^T u\n",
    "\\overset{p}{\\longrightarrow}\n",
    "0\n",
    "$$\n",
    "\n",
    "よって\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}\n",
    "\\overset{p}{\\longrightarrow}\n",
    "\\beta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c58162-4089-44f5-9f82-c2103de6531f",
   "metadata": {},
   "source": [
    "## 漸近正規性\n",
    "\n",
    "OLS推定量\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}\n",
    "= \\beta + \\left(\\frac{1}{N} X^T X\\right)^{-1} \\frac{1}{N} X^T u\n",
    "$$\n",
    "\n",
    "を整理して以下の形にする\n",
    "\n",
    "$$\n",
    "\\sqrt{N} (\\hat{\\beta} - \\beta)\n",
    "=\n",
    "\\left(\n",
    "    \\frac{1}{N} X^T X\n",
    "\\right)^{-1}\n",
    "\\frac{1}{\\sqrt{N}} X^T u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27326747-3dcd-46e8-8604-5c64e8c83636",
   "metadata": {},
   "source": [
    "$\\frac{1}{\\sqrt{N}} X^T u$は$\\frac{1}{\\sqrt{N}} \\sum^N_{i=1} X_i u_i$と書くことができる。OLSの仮定より\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(X_i u_i) &= 0\\\\\n",
    "Var(X_i u_i) &= E(u^2 X_i X^T_i)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "なので、中心極限定理により\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{N}} X^T u\n",
    "= \\frac{1}{\\sqrt{N}} \\sum^N_{i=1} X_i u_i\n",
    " \\overset{d}{\\longrightarrow} N\\left( 0, E(u_i^2 X_i X_i^T) \\right)\n",
    "$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711625a6-398c-4c0c-9a4b-d733d0e0e08b",
   "metadata": {},
   "source": [
    "一致性のときに導出した\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} X^T X\n",
    "\\overset{p}{\\longrightarrow} E(X_i X_i^T)\n",
    "$$\n",
    "\n",
    "を使うと、スルツキーの定理を用いて\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sqrt{N} (\\hat{\\beta} - \\beta)\n",
    "&=\n",
    "\\left(\n",
    "    \\frac{1}{N} X^T X\n",
    "\\right)^{-1}\n",
    "\\frac{1}{\\sqrt{N}} X^T u\n",
    "\\overset{d}{\\longrightarrow} \\left( E(X_i X_i^T)  \\right)^{-1} \\times N\\left( 0, E(u_i^2 X_i X_i^T) \\right)\\\\\n",
    "&= N\\left( 0,\n",
    "    \\left( E(X_i X_i^T)  \\right)^{-1}  E(u_i^2 X_i X_i^T)  \\left( E(X_i X_i^T)  \\right)^{-1}\n",
    "\\right)\\\\\n",
    "&= N(0, V)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcd205-d812-4675-8532-9f3d4996bd3a",
   "metadata": {},
   "source": [
    ":::{dropdown} スルツキーの定理\n",
    "\n",
    "確率変数の行列$Y_N, Y, X_N, X \\in \\mathbb{R}^{N\\times N}$、正則行列$C \\in \\mathbb{R}^{N\\times N}$があるとする。\n",
    "\n",
    "$N\\to \\infty$のとき\n",
    "\n",
    "$$\n",
    "X_N \\xrightarrow{d} X\\\\\n",
    "Y_N \\xrightarrow{d} C\\\\\n",
    "$$\n",
    "\n",
    "とする。\n",
    "\n",
    "このとき、以下の結果が成り立ち、これを **スルツキーの定理** という\n",
    "\n",
    "1. $X_N + Y_N \\xrightarrow{d} X + C$\n",
    "2. $Y_N X_N \\xrightarrow{d} C X$\n",
    "3. $Y_N^{-1}X_N \\xrightarrow{d} C^{-1} X$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253aef1e-2ac7-49a1-9c50-96e4bb187633",
   "metadata": {},
   "source": [
    "$V$は以下のように一致推定できる\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{V} & =\\left[\\frac{1}{N} \\sum_{i=1}^N X_i X_i^T\\right]^{-1} \\frac{1}{N} \\sum_{i=1}^N \\hat{u}_i^2 X_i X_i^T\\left[\\frac{1}{N} \\sum_{i=1}^N X_i X_i^T\\right]^{-1} \\\\\n",
    "& =\\left(\\frac{1}{N} X^T X\\right)^{-1} \\frac{1}{N} X^T \\hat{U} X\\left(\\frac{1}{N} X^T X\\right)^{-1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ただし、$\\hat{U}$は対角要素に$\\hat{u}_1^2, \\dots, \\hat{u}_N^2$を並べた対角行列である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2b936-8fdc-4f0d-b611-b5e6769e2686",
   "metadata": {},
   "source": [
    "## バイアスとバリアンス\n",
    "\n",
    "最小二乗推定量はすべての線形不偏推定量の中で最もバリアンスが小さい（最良である）ことを示すガウス・マルコフの定理というものがある。\n",
    "\n",
    "```{margin} バイアスとバリアンス\n",
    "統計学・機械学習の分野では誤差をバイアス（bias）とバリアンス（variance）に分けて考えることが多い。\n",
    "\n",
    "バイアスは真の値$\\theta$とサンプルを変えて推定を繰り返したときの個々の推定結果の平均$E(\\hat{\\theta})$との差で、\n",
    "バリアンスは推定の分散$V(\\hat{\\theta})$である。\n",
    "\n",
    "$$\n",
    "Bias = \\theta - E(\\hat{\\theta})\\\\\n",
    "Variance = V(\\hat{\\theta})\n",
    "$$\n",
    "```\n",
    "\n",
    "\n",
    "```{note} ガウス・マルコフの定理\n",
    "各$i$について、\n",
    "\n",
    "- $E[\\varepsilon_i] = 0$\n",
    "- $V[\\varepsilon_i]=\\sigma^2 < \\infty$ が共通\n",
    "- $i \\neq j$のとき$E[\\varepsilon_i \\varepsilon_j] = 0$\n",
    "\n",
    "を満たすとき、最小二乗推定量$\\hat{\\beta}_{OLS}$はBLUEになる\n",
    "```\n",
    "\n",
    "\n",
    "#### 不偏性\n",
    "\n",
    "任意のパラメータの線形結合$\\theta=\\boldsymbol{\\alpha}^\\top {\\boldsymbol{\\beta}}$を考える。例えば$f(x_0)=x_0^\\top \\beta$がこの形である。\n",
    "\n",
    "この最小二乗推定値は\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\boldsymbol{\\alpha}^\\top \\hat{\\boldsymbol{\\beta}}\n",
    "= \\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "で、期待値をとると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E[\\hat{\\theta}]\n",
    "&= E[\\boldsymbol{\\alpha}^\\top \\hat{\\boldsymbol{\\beta}}]\\\\\n",
    "&= E[\\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top \\boldsymbol{y}]\\\\\n",
    "% &= \\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X}^\\top E[\\boldsymbol{y}]\\\\\n",
    "&= E[\\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top (X\\beta + \\varepsilon) }] \\\\\n",
    "&= \\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top X \\beta + \\alpha^\\top (X^\\top X)^{-1} X^\\top} E[ \\varepsilon ] \\\\\n",
    "&= \\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top X \\beta}\\\\\n",
    "&= \\boldsymbol{\\alpha}^\\top \\boldsymbol{\\beta}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "```{margin}\n",
    "※誤差項は仮定により$E[\\boldsymbol{\\varepsilon}]=0$であるため\n",
    "```\n",
    "\n",
    "となり（※）、$\\hat{\\theta}$が不偏推定量である（$E[\\hat{\\theta}] = \\theta$）ことがわかる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f9f1f-7164-4ba5-8b1d-3016e9f7737a",
   "metadata": {},
   "source": [
    "### バリアンス\n",
    "\n",
    "$\\boldsymbol{\\alpha}^\\top \\boldsymbol{\\beta}$に対して不偏のまた別の線形推定量$\\boldsymbol{c}^\\top \\boldsymbol{y}$があるとする。\n",
    "\n",
    "両者の差を\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\boldsymbol{\\alpha}^\\top \\boldsymbol{\\hat{\\beta}} - \\boldsymbol{c}^\\top \\boldsymbol{y}\n",
    "&= [ \\boldsymbol{\\alpha}^\\top (\\boldsymbol{X}^\\top \\boldsymbol{X})^{-1} \\boldsymbol{X} - \\boldsymbol{c}^\\top ] \\boldsymbol{y}\\\\\n",
    "&=: \\boldsymbol{d}^\\top \\boldsymbol{y}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "とおく。このとき、不偏性$E[\\boldsymbol{c}^\\top \\boldsymbol{y}] = \\boldsymbol{\\alpha}^\\top \\boldsymbol{\\beta}$から両者の差の期待値はゼロになるべきであり、\n",
    "\n",
    "$$\n",
    "E[\\boldsymbol{d}^\\top \\boldsymbol{y}]\n",
    "= \\boldsymbol{d}^\\top \\boldsymbol{X} \\boldsymbol{\\beta} = 0\n",
    "$$\n",
    "\n",
    "が任意の$\\boldsymbol{\\beta}$について成り立たなければならないため、\n",
    "\n",
    "$$\n",
    "\\boldsymbol{d}^\\top \\boldsymbol{X} = \\boldsymbol{0}\n",
    "$$\n",
    "\n",
    "が成り立つ。\n",
    "\n",
    "\n",
    "次に、2つの確率変数$X, Y$に対し\n",
    "\n",
    "$$\n",
    "V[X+Y] = V[X] + 2 \\text{Cov}[X, Y] + V[Y]\n",
    "$$\n",
    "\n",
    "が成り立つから、$\\boldsymbol{c}^\\top \\boldsymbol{y}$の分散は\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "V[\\boldsymbol{c^\\top y}] &= V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} - d^\\top y }]\\\\\n",
    "&= V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }]\n",
    "- 2 \\text{Cov} [\\boldsymbol{ \\alpha^\\top (X^\\top X)^{-1} X^\\top y }, \\boldsymbol{ d^\\top y} ]\n",
    "+ V[\\boldsymbol{ d^\\top y}]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "と表すことができる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc4fcc-c557-4529-a6a9-feee7341a1ee",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cov}(A, B) = E[(A - E[A])(B - E[B])^\\top]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df690aac-43ad-4896-8dac-52b5537dac22",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cov}(a^\\top y, b^\\top y)\n",
    "= E[(a^\\top y - E[a^\\top y])(b^\\top y - E[b^\\top y])^\\top]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d273a-5ee8-4840-81b4-f6729deb94b6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Cov}(a^\\top y, b^\\top y)\n",
    "= E[(a^\\top y - E[a^\\top y])(b^\\top y - E[b^\\top y])^\\top]\\\\\n",
    "= E[(a^\\top y - \\alpha^\\top \\beta)(b^\\top y - E[b^\\top y])^\\top]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c030c3d-abfe-4376-8f32-4cfa26f6c7bb",
   "metadata": {},
   "source": [
    "次に、2つの確率変数\n",
    "\n",
    "$$\n",
    "\\boldsymbol{a^\\top y} = \\sum a_i y_i,\n",
    "\\hspace{2em}\n",
    "\\boldsymbol{b^\\top y} = \\sum b_i y_i\n",
    "$$\n",
    "\n",
    "の共分散は、誤差項$\\boldsymbol{\\varepsilon}$が無相関・等分散の仮定$V[\\boldsymbol{\\varepsilon}] = \\sigma^2 \\boldsymbol{I}$を満たすとき、\n",
    "\n",
    "$$\n",
    "\\text{Cov}[\\boldsymbol{a^\\top y, b^\\top y}]\n",
    "= \\text{Cov}[\\boldsymbol{a^\\top \\varepsilon, b^\\top \\varepsilon}]\n",
    "= \\sum a_i b_i \\sigma^2\n",
    "= (\\boldsymbol{a^\\top b}) \\sigma^2\n",
    "$$\n",
    "\n",
    "```{margin}\n",
    "TODO: 解説書く\n",
    "```\n",
    "\n",
    "となることから\n",
    "\n",
    "$$\n",
    "\\text{Cov}[\\boldsymbol{ \\alpha^\\top (X^\\top X)^{-1} X^\\top y, d^\\top y }]\n",
    "= \\boldsymbol{\\alpha^\\top (X^\\top X)^{-1} X^\\top d } \\cdot \\sigma^2\n",
    "$$\n",
    "\n",
    "となり、$\\boldsymbol{d}^\\top \\boldsymbol{X} = \\boldsymbol{0}$よりこれは0となる。\n",
    "\n",
    "よって\n",
    "\n",
    "$$\n",
    "V[\\boldsymbol{ c^\\top y }] = V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }] + V[\\boldsymbol{ d^\\top y }]\n",
    "$$\n",
    "\n",
    "が成り立ち、分散は非負なので\n",
    "\n",
    "$$\n",
    "V[\\boldsymbol{ c^\\top y }] \\geq V[\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }]\n",
    "$$\n",
    "\n",
    "を意味する。\n",
    "\n",
    "よって$\\boldsymbol{ \\alpha^\\top \\hat{\\beta} }$は最良線形不偏推定量BLUEである。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e651f04-a61a-45a5-955b-fa5459144080",
   "metadata": {},
   "source": [
    "## OLS推定の幾何学的意味\n",
    "\n",
    "OLS推定量\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}} = (X^\\top X)^{-1} X^\\top \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "を$\\hat{\\boldsymbol{y}} = X \\hat{\\boldsymbol{\\beta}}$に代入すると\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{y}} = \\underbrace{ X (X^\\top X)^{-1} X^\\top }_{P} \\boldsymbol{y}\n",
    "= P \\boldsymbol{y}\n",
    "$$\n",
    "\n",
    "つまり、ベクトル$\\boldsymbol{y}$を行列$P = X (X^\\top X)^{-1} X^\\top$で射影したものとみなすことができる。\n",
    "\n",
    "この行列$P$は対称行列で、$P^2=P$となる。この2つの性質を満たす行列を射影行列という。\n",
    "\n",
    ":::{card}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P^2 & = PP \\\\\n",
    "& =(X(X^{\\top} X)^{-1} X^{\\top})(X(X^{\\top} X)^{-1} X^{\\top}) \\\\\n",
    "& =X(X^{\\top} X)^{-1}(X^{\\top} X)(X^{\\top} X)^{-1} X^{\\top} \\\\\n",
    "& =X(X^{\\top} X)^{-1} X^{\\top}\n",
    "=P\n",
    "\\end{aligned}\n",
    "$$\n",
    ":::\n",
    "\n",
    "射影行列は、$X$の列空間$\\Im X$にベクトルを正射影するという性質がある。$\\boldsymbol{y}$の$\\Im X$への射影が$\\hat{\\boldsymbol{y}}$で、垂線の足が誤差$\\boldsymbol{u}$となる。\n",
    "\n",
    "よって、最小二乗法は$\\boldsymbol{y}$から$\\Im X$への射影を求める操作であると捉えることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64100a1-e4b0-4694-8d29-ca9032a765b4",
   "metadata": {},
   "source": [
    "## OLSとBLUE / BUE\n",
    "\n",
    ":::{card} OLSはBLUEかBUEか？\n",
    "\n",
    "行列$A$によって$b = Ay$のような線形結合で表現される推定量$b$は線形推定量という。OLSも$A=(X^\\top X)^{-1} X^\\top$とおけば同じ形になっていることがわかる。\n",
    "\n",
    "OLSはガウス・マルコフの定理でBLUE（線形不偏推定量のなかで最良）だと示された。\n",
    "\n",
    "[Hansen (2022)](https://doi.org/10.3982/ECTA19255) は線形制約は不要で、線形と非線形の両方のすべての不偏推定量の中で最良（BUE）だと主張した。\n",
    "一方で [Pötscher & Preinerstorfer (2022)](https://doi.org/10.48550/arXiv.2203.01425) はHansen (2022)に対する批判を展開した。\n",
    "[Portnoy (2022)](https://doi.org/10.1080/00031305.2022.2076743) は「一般線形モデルの場合、十分に広い分布族内のすべての分布に対して、不偏な推定量は線形でなければならない」と述べている。\n",
    "\n",
    "Hansen(2022) の「OLSが最良の不偏推定量（BUE）」が正しいとしても、Portnoy (2022)によれば「一般線形モデルの不偏推定量は線形推定量」なので結局BLUE=BUEになり、いずれの主張も間違っていないことになる。\n",
    "\n",
    "\n",
    "参考：\n",
    "\n",
    "- 元ネタ：[Is OLS BLUE or BUE? | Statistical Horizons](https://statisticalhorizons.com/is-ols-blue-or-bue/)\n",
    "- [Hansen, B. E. (2022). A Modern Gauss–Markov Theorem. Econometrica, 90(3), 1283-1294.](https://doi.org/10.3982/ECTA19255)\n",
    "- [Portnoy, S. (2022). Linearity of unbiased linear model estimators. The American Statistician, (just-accepted), 1-10.](https://doi.org/10.1080/00031305.2022.2076743)\n",
    "- [Pötscher, B. M., & Preinerstorfer, D. (2022). A Modern Gauss-Markov Theorem? Really?. arXiv preprint arXiv:2203.01425.](https://doi.org/10.48550/arXiv.2203.01425)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc94496-31f2-405e-9a02-bc435eecb5cd",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- 東京大学出版会『統計学入門』\n",
    "- 東京大学出版会『自然科学の統計学』\n",
    "- Hastie, T., Tibshirani, R., Friedman, J. H., & Friedman, J. H. (2009). The elements of statistical learning: data mining, inference, and prediction (Vol. 2, pp. 1-758). New York: springer.\n",
    "- [西山慶彦, 新谷元嗣, 川口大司, & 奥井亮. (2019). 計量経済学. Yūhikaku.](https://www.yuhikaku.co.jp/books/detail/9784641053854)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
