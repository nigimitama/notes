{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c6d2f0-8084-47ea-9031-4c9cb767de62",
   "metadata": {},
   "source": [
    "# Casual Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3390f92-ae65-4997-a468-c9c0c23d5dfd",
   "metadata": {},
   "source": [
    "Random Forestをカーネル重み付けとみなす視点に、Robinson (1988)の部分線形モデルを合わせたもの\n",
    "\n",
    "[一般化ランダムフォレストの理論と統計的因果推論への応用 - Speaker Deck](https://speakerdeck.com/tomoshige_n/ban-hua-randamuhuoresutonoli-lun-totong-ji-de-yin-guo-tui-lun-henoying-yong?slide=42)\n",
    "\n",
    "- [ランダムフォレストによる因果推論と最近の展開 - Speaker Deck](https://speakerdeck.com/tomoshige_n/randamuhuoresutoniyoruyin-guo-tui-lun-tozui-jin-nozhan-kai-838c3989-570d-49ca-b630-22044a798589)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108e441-b47a-461a-8d4a-8153a828b996",
   "metadata": {},
   "source": [
    "## Causal Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea1198-85c3-4281-829a-bb257bdfb05e",
   "metadata": {},
   "source": [
    "### 背景：Random Forestの理論解析の進展\n",
    "\n",
    "- Delgado et al. (2014) はUCIデータセット121に対して様々な手法を適用し、Random Forestが優れた結果を示したと報告\n",
    "    - [Fernández-Delgado, M., Cernadas, E., Barro, S., & Amorim, D. (2014). Do we need hundreds of classifiers to solve real world classification problems?. The journal of machine learning research, 15(1), 3133-3181.](https://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf)\n",
    "    - その後はXGBoostやLightGBMも登場しており現在は違う結果となる可能性も高いが、少ない計算量・シンプルな手法ながら優れた結果ではあった\n",
    "- 漸近正規性が証明される → 信頼区間が得られる\n",
    "    - Wager (2014) は無限の木があるときのRandom Forestの予測値が漸近正規性をもつことを証明\n",
    "        - [Wager, S. (2014). Asymptotic theory for random forests. arXiv preprint arXiv:1405.0352.](https://arxiv.org/abs/1405.0352)\n",
    "    - Mentch & Hooker (2014) は有限の木での漸近正規性を証明\n",
    "        - [Mentch, L., & Hooker, G. (2014). Ensemble trees and clts: Statistical inference for supervised learning. stat, 1050, 25.](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=be56bcaad2650c02017fb455808b047befc04c9e)\n",
    "- Scornet (2016) はRandom Forestがカーネル法の一種であることを示した\n",
    "    - [Scornet, E. (2016). Random forests and kernel methods. IEEE Transactions on Information Theory, 62(3), 1485-1500.](https://arxiv.org/abs/1502.03836)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd7583-b46f-47d4-8217-142867023288",
   "metadata": {},
   "source": [
    "### 因果推論についての前提\n",
    "\n",
    ":::{card} Potential outcome framework\n",
    "\n",
    "- $Y_{a=1}, Y_{a=0} \\in \\mathbb{R}$ ：潜在結果変数\n",
    "- $X_j$： $p$次元の pre-treatment 共変量（ $j=1:p$ ）\n",
    "- $A=\\{0,1\\}$ ：処置変数\n",
    "- $\\pi(x)=\\operatorname{Pr}(A=1 \\mid X=x)$ ：傾向スコア\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{card} Assumption: Consistency\n",
    "\n",
    "$$\n",
    "Y=A Y_{a=1}+(1-A) Y_{a=0}\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card} Assumption : Unconfoundedness\n",
    "\n",
    "$$\n",
    "A \\perp Y_a \\mid X \\text { for } a=0,1\n",
    "$$\n",
    ":::\n",
    "\n",
    ":::{card} Assumption : Posititvity\n",
    "\n",
    "$$\n",
    "0<\\pi(x)<1\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card} Definition: Average Treatment Effect (ATE)\n",
    "\n",
    "$$\n",
    "\\theta^{A T E}=\\mathrm{E}\\left[Y_{a=1}-Y_{a=0}\\right]\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card} Definition: Heterogeneous Treatment Effect (HTE)\n",
    "\n",
    "$$\n",
    "\\theta^{H T E}(x)=\\mathrm{E}\\left[Y_{a=1}-Y_{a=0} \\mid X=x\\right]\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc6a37-191c-455d-abb2-6dd27ef31f5a",
   "metadata": {},
   "source": [
    "### Honest\n",
    "\n",
    "- Causal Treesはrecursive partitioningを用いてHeterogeneous Treatment Effectを推定する手法。\n",
    "- honest性という概念がcausal forestsやGeneralized Random Forestの証明において重要な役割を果たす。\n",
    "- またhonest性を満たすTreeはCARTと比較して過学習を起こしにくいという性質もある。\n",
    "\n",
    ":::{card} honest\n",
    "\n",
    "**「木の分割（partitioning）をするために用いるサンプル」と「TreeのLeafごとの推定量の計算に用いるサンプル」に別々のサンプルを用いることで、partition $\\Pi$ と 推定量$\\hat{\\mu}$ が独立になったTree を honest なTreeであるという**\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7956b0c-03d2-43c3-99ba-5764c1639562",
   "metadata": {},
   "source": [
    "#### honestな木はCARTと異なる目的関数をもつ\n",
    "\n",
    "honestな木はpartition $\\Pi$のもとで estimation sample $\\mathcal{S}^{e s t}$ を用いて推定された条件付き平均$\\hat{\\mu}\\left(X_i ; \\mathcal{S}^{e s t}, \\Pi\\right)$とテストデータ$\\mathcal{S}^{t e}$の平均二乗誤差\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}\\left(\\mathcal{S}^{t e}, \\mathcal{S}^{e s t}, \\Pi\\right)=\\frac{1}{\\#\\left(\\mathcal{S}^{t e}\\right)} \n",
    "\\sum_{i \\in \\mathcal{S}^{t e}}\n",
    "\\left\\{\\left(Y_i-\\hat{\\mu}\\left(X_i ; \\mathcal{S}^{e s t}, \\Pi\\right)\\right)^2-Y_i^2\\right\\}\n",
    "$$\n",
    "\n",
    "の期待値をとったものを最小化する。\n",
    "\n",
    "\n",
    "$$\n",
    "\\Pi^{\\text{honest}}=\n",
    "\\arg\\min_\\Pi \\mathrm{E}_{\\mathcal{S}^{\\text{te}}, \\mathcal{S}^{\\text{est}}, \\mathcal{S}^{\\text{tr}}}\n",
    "\\left[\\operatorname{MSE}(\\mathcal{S}^{\\text{te}}, \\mathcal{S}^{\\text{est}}, \\Pi(\\mathcal{S}^{\\text{tr}})\\right]\n",
    "$$\n",
    "\n",
    "一方で一般的なCARTでは、訓練サンプル $\\mathcal{S}^{\\text{te}}$ を使ってpartition $\\Pi$と推定量$\\hat{\\mu}$を作って誤差を最小化する\n",
    "\n",
    "$$\n",
    "\\Pi^{\\text{CART}}=\n",
    "\\arg\\min_\\Pi \\mathrm{E}_{\\mathcal{S}^{\\text{te}}, \\mathcal{S}^{\\text{tr}}}\n",
    "\\left[\\operatorname{MSE}(\\mathcal{S}^{\\text{te}}, \\mathcal{S}^{\\text{tr}}, \\Pi(\\mathcal{S}^{\\text{tr}})\\right]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f758c94-fb07-4160-8b22-c5d82a2fc41c",
   "metadata": {},
   "source": [
    "#### honestな木は過学習しにくい\n",
    "\n",
    "MSEの期待値を取ったものをEMSE\n",
    "\n",
    "$$\n",
    "\\operatorname{EMSE}(\\Pi) := \\mathrm{E}_{\\mathcal{S}^{t e}, \\mathcal{S}^{\\text {est }}}\\left[\\operatorname{MSE}\\left(\\mathcal{S}^{t e}, \\mathcal{S}^{\\text {est }}, \\Pi\\right)\\right]\n",
    "$$\n",
    "\n",
    "とする。honestな木はこれを目的関数とする。\n",
    "\n",
    "負のEMSEを展開すると\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "-\\operatorname{EMSE}(\\Pi) & =-\\mathrm{E}_{\\left(Y_i, X_j\\right), \\mathcal{S}^{\\operatorname{est}}}\\left[\\left(Y_i-\\mu\\left(X_i ; \\Pi\\right)^2-Y_i\\right]\\right. \\\\\n",
    "& -\\mathrm{E}_{X_i, \\mathcal{S}^{\\text {est }}}\\left[\\left(\\hat{\\mu}\\left(X_i ; \\mathcal{S}^{\\text {est }} ; \\Pi\\right)-\\mu\\left(X_i ; \\Pi\\right)\\right)^2\\right] \\\\\n",
    "& =\\mathrm{E}_{X_i}\\left[\\mu^2\\left(X_i ; \\Pi\\right)\\right]-\\mathrm{E}_{\\mathcal{S}^{\\text {est }}, X_i}\\left[\\operatorname{Var}\\left(\\hat{\\mu}\\left(X_i ; \\mathcal{S}^{\\text {est }} ; \\Pi\\right)\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "となる。\n",
    "\n",
    "これに対して訓練サンプル$\\mathcal{S}^{t r}$から不偏推定量を構成すると\n",
    "\n",
    "$$\n",
    "\\widehat{\\operatorname{EMSE}}\\left(\\mathcal{S}^{t r}, \\Pi\\right)\n",
    "=\\frac{1}{N^{t r}} \\sum_{i \\in \\mathcal{S}^{t r}} \\hat{\\mu}^2\\left(X_i ; \\mathcal{S}^{t r}, \\Pi\\right)\n",
    "-\\underbrace{ \\frac{2}{N^{t r}} \\cdot \\sum_{\\ell \\in \\Pi} S_{\\mathcal{S}^{t r}}^2(\\ell) }_{penalty}\n",
    "$$\n",
    "\n",
    "となる。ここで$S_{\\mathcal{S}^{t r}}^2(\\ell)$は$\\ell \\in \\Pi$におけるleaf内分散を意味する。\n",
    "\n",
    "一方で、CARTにおいてはpenalty項がなく、分割を行えば行うほど$-\\operatorname{MSE}$が改善するため、枝刈りが必要になる。\n",
    "\n",
    "$$\n",
    "-\\operatorname{MSE}\\left(\\mathcal{S}^{t r}, \\mathcal{S}^{t r}, \\Pi\\right)=\\frac{1}{N^{t r}} \\sum_{i \\in \\mathcal{S}^{t r}} \\hat{\\mu}^2\\left(X_i ; \\mathcal{S}^{t r}, \\Pi\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "leaf内分散はleaf内のサンプル数が多いうちは小さい（=CARTとhonest treeは似た挙動になる）が、leaf内サンプルが小さくなると高くなりやすい（分割を停止する方向に動く）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd99fc78-cc95-48af-905e-c8ebe32bd6ba",
   "metadata": {},
   "source": [
    "#### HTEの推定\n",
    "\n",
    "問題：データ $\\left(Y_i, X_i, W_i\\right) \\in \\mathbb{R} \\times \\mathbb{R}^\\rho \\times\\{0,1\\}$ が観測されたもとで、 $\\theta^{H T E}(x)=\\mathrm{E}\\left[Y_{a=1}-Y_{a=0} \\mid X=x\\right]$ を推定する問題\n",
    "\n",
    "\n",
    "$$\n",
    "\\tau(x ; \\Pi) \\equiv \\mathrm{E}\\left[Y_{a=1}-Y_{a=0} \\mid X \\in \\ell(x ; \\Pi)\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu(a, x ; \\Pi) \\equiv \\mathrm{E}\\left[Y_a \\mid X \\in \\ell(x ; \\Pi)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa5eb9-306b-460e-a4ea-658449d0fd45",
   "metadata": {},
   "source": [
    "## Causal Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3defa-9d92-4426-bd9d-10a1de0d4e24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "244ffd9b-b576-43b9-979a-ab813fb97e69",
   "metadata": {},
   "source": [
    "## 応用研究\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ee9f3-e1ea-4bd9-95f7-97dcecc6dd99",
   "metadata": {},
   "source": [
    "\n",
    "### 小売業においてクーポン配布のCATEを推定\n",
    "\n",
    "[How causal machine learning can leverage marketing strategies: Assessing and improving the performance of a coupon campaign | PLOS One](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0278937)\n",
    "\n",
    "- Kaggle公開データを使ってCATEを推定\n",
    "- 配布した5種類のクーポンのうち、ドラッグストア商品券と食品カテゴリ券の2種だけが有意に売上増効果を持つことが分かった。\n",
    "- 他のクーポンは統計的に効果が確認できず、無効な施策だった。\n",
    "- また効果の異質性分析から、「ドラッグストア券は事前購買額の大きい優良顧客に特に効果的」「一般食品券は購買額の少ないライト層に効果的」といったセグメント別の効果差が判明した\n",
    "- 例えば、既存ヘビーユーザーには日用品系クーポンで追加購買を促進でき、ライトユーザーには普段買わない食品クーポンで来店を促すと効果的。\n",
    "- この結果を踏まえ、クーポン配布の対象を効果の高いセグメントに絞る最適施策を導出したところ、全顧客に配布する場合と比べ費用対効果が大幅に向上した（少数配布で売上効果の大半を実現）。因果フォレストを用いることで、マーケティングROIを最大化する配布戦略の策定が可能になることを示した。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8506d-eb72-4eb5-9750-58b4ba594cbd",
   "metadata": {},
   "source": [
    "### Amazonの顧客ターゲティング\n",
    "\n",
    "[[2409.13847] Segment Discovery: Enhancing E-commerce Targeting](https://arxiv.org/abs/2409.13847)\n",
    "\n",
    "方法\n",
    "- Amazon社内の大規模実験データ（オンラインサービス等のABテスト複数）。例：ある定額サービスで解約防止のプロモメッセージを送る実験（数十万人規模）。\n",
    "- まずランダム化比較試験から顧客毎のCATEをCausal Forestやuplift modelで推定。次に企業側の制約（予算・接触可能数）を組み込んだ最適化アルゴリズム（Large-Scale Budget-Constrained Causal Forest）で最大効果のターゲット集合を選定。\n",
    "\n",
    "結果\n",
    "- 従来は、例えば離脱率の高い順に顧客に介入するなど予測モデルに基づくターゲティングが行われていた。しかし実験データを分析したところ、離脱リスクが極端に高い顧客層では、プロモメッセージを送っても効果が無いばかりか逆効果（介入で離脱率が悪化）になる場合があることが判明\n",
    "- 一方、リスクが中程度の層に大きなプラス効果が見られるなど、どの層に介入すべきかは単純な予測スコア順とは一致しないことが示された。\n",
    "- Causal Forestを用いるターゲティングでは、こうした「介入効果の高い層」を的確に抽出できる。実際、**あるサービスの例では従来ルールでは離脱スコア下位39.1%を一律介入対象としていたが、因果モデルに基づき効果の見込める顧客だけを選別したところ、むしろ全体の半数以下の配信で離脱抑止効果の75%以上を達成**できた。\n",
    "- このアプローチにより、顧客体験を損ねる無駄な介入を避けつつ、限られたマーケ予算で最大限の効果を上げることが可能となる。Amazon社の研究では複数のキャンペーンで有効性が検証されており、大規模パーソナライズドマーケティングへの因果機械学習の実用性を示すケースとなっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5efd6b-8281-45e5-b2bd-95b3ca2b783e",
   "metadata": {},
   "source": [
    "### 「少しずつ頻繁に」行う宿題の学習効果 McJames et al. (2024)\n",
    "\n",
    "- [Little and often: Causal inference machine learning demonstrates the benefits of homework for improving achievement in mathematics and science - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0959475224000951?via%3Dihub)\n",
    "- [Study reveals impact of homework on student achievement in math and science](https://phys.org/news/2024-09-reveals-impact-homework-student-math.html)\n",
    "\n",
    "方法：\n",
    "\n",
    "- 国際学力調査TIMSS 2019のデータから、アイルランドの中学2年生4,118人の数学・理科成績と家庭学習時間を分析\n",
    "- Bayesian Causal Forests で、宿題の頻度・長さを疑似介入変数として成績への因果効果を推定\n",
    "\n",
    "結果：\n",
    "- 週あたりの宿題実施回数を増やすことが学力向上に効果的である一方、1回あたりの宿題時間を延ばしても効果は頭打ちになる傾向が示された\n",
    "- 15分程度の短い課題でも長時間の課題と同等の効果があり、頻度を上げて宿題を小分けにする「Little and Often」戦略が有効であることがデータから裏付けられた。\n",
    "- **数学では「毎日少し」の宿題が最も成績を伸ばし** 、理科では週3～4回程度が効果的。\n",
    "- また従来の通説では家庭環境により宿題効果に差が出ると考えられていたが、本解析ではどの社会経済層の生徒も宿題の恩恵を等しく享受しており、一部の層だけが得をするわけではないことが示された。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520dcb09-cda3-46f9-aeba-76a4ff779c69",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [Causal TreeとCausal Forestの理論と実装 - tomtom58’s blog](https://tomtom58.hatenablog.com/entry/2024/07/15/211016)\n",
    "    - フルスクラッチ実装例がある\n",
    "- [計量経済学と 機械学習の交差点入り口 （公開用） | PDF](https://www.slideshare.net/slideshow/ss-67818872/67818872)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419a431-91b0-4e96-8d32-e081f31a70f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
