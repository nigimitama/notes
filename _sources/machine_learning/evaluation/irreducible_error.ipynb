{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd7b490-9ce5-485d-be58-54c113d8cd0d",
   "metadata": {},
   "source": [
    "# 削減不能な誤差の推定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46e932-0009-4db5-93a0-68d3539512c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## バイアス‐バリアンス分解\n",
    "\n",
    ":::{admonition} 定理\n",
    "\n",
    "目的変数$Y$が回帰関数$f(X)$と誤差$\\varepsilon$によって分解できる、すなわち$Y=f(X)+\\varepsilon$であるとする。ここで$\\mathrm{E}(\\varepsilon)=0, \\ \\mathrm{Var}(\\varepsilon) = \\sigma^2_{\\varepsilon}$である。\n",
    "\n",
    "入力点$X=x_0$における学習した回帰関数$\\hat{f}(X)$の二乗誤差の期待値は、 **削減不能な誤差 (irreducible error)** 、 **バイアス（Bias）** の二乗、 **バリアンス（Variance）** に分解できる。\n",
    "\n",
    ":::\n",
    "\n",
    ":::{card} 証明\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Err}\\left(x_0\\right)\n",
    "&= \\mathrm{E} \\left[\\left(Y-\\hat{f}\\left(x_0\\right)\\right)^2 \\mid X=x_0\\right] \\\\\n",
    "& =\\sigma_{\\varepsilon}^2+\\left[\\mathrm{E} \\hat{f}\\left(x_0\\right)-f\\left(x_0\\right)\\right]^2+E\\left[\\hat{f}\\left(x_0\\right)-\\mathrm{E} \\hat{f}\\left(x_0\\right)\\right]^2 \\\\\n",
    "& =\\sigma_{\\varepsilon}^2+\\operatorname{Bias}^2\\left(\\hat{f}\\left(x_0\\right)\\right)+\\operatorname{Var}\\left(\\hat{f}\\left(x_0\\right)\\right) \\\\\n",
    "& =\\text { Irreducible Error }+\\operatorname{Bias}^2+\\text { Variance. }\n",
    "\\end{aligned}\n",
    "$$\n",
    ":::\n",
    "\n",
    "もし、現状のデータとモデルではそれ以上誤差を削減させられないなら、モデルのフィッティングを頑張るよりも特徴量を増やす努力をしたほうがよいかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e9767-4149-4e91-9e47-4db61cf8d7f6",
   "metadata": {},
   "source": [
    "## 削減不能な誤差の推定\n",
    "\n",
    "削減不能な誤差をどう推定するか？\n",
    "\n",
    "- [Liitiäinen, E., Corona, F., & Lendasse, A. (2008). On nonparametric residual variance estimation. Neural Processing Letters, 28, 155-167.](https://research.cs.aalto.fi/aml/Publications/Publication132.pdf)\n",
    "- [Devroye, L., Györfi, L., Lugosi, G., & Walk, H. (2018). A nearest neighbor estimate of the residual variance. Electronic Journal of Statistics, 12, 1752-1778.](https://www.semanticscholar.org/reader/c683bc0adb168900e3d74e5bb49d3db7ac6cc7c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9e0b8-4f8f-4891-96e3-98bb4f11fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
