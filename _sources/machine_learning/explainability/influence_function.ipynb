{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ed8ea6-77e9-4e82-b261-6827b46200f8",
   "metadata": {},
   "source": [
    "# 影響関数（influence function）\n",
    "\n",
    "データ点$z_{test}$の予測において訓練データ点$z$が与えた影響の大きさを評価する関数$\\mathcal{I}(z, z_{test})$を推定する技術\n",
    "\n",
    "- [Koh & Liang (2017)](https://arxiv.org/pdf/1703.04730.pdf)が提案\n",
    "- [Hara et al. (2019)](https://proceedings.neurips.cc/paper/2019/file/5f14615696649541a025d3d0f8e0447f-Paper.pdf)はconvexでない損失関数にも使えるよう拡張\n",
    "- [Guo et al. (2020)](https://arxiv.org/pdf/2012.15781.pdf)はFastIFを提案：k-最近傍のデータに探索範囲を絞るなどして最大80倍の高速化\n",
    "- [Sharchilev et al. (2018)](https://arxiv.org/abs/1802.06640)は勾配ブースティング決定木に向けたinfluence functionを提案\n",
    "  - Influence Functionはモデルのパラメータ$\\theta$の微分によって近似推定するため、決定木ベースのアルゴリズムなど微分不可能なアルゴリズムでは計算できないため\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c97447-bb52-4956-8260-6d9bcaa7e2a2",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "- データ点$z=(x, y)$\n",
    "- 誤差関数$L(z, \\theta)$\n",
    "  - 経験リスク：$R = \\frac{1}{N} \\sum^N_{i=1} L(z_i, \\theta)$\n",
    "- $N$訓練データ点が訓練集合$\\mathcal{Z}$に含まれるとする\n",
    "- 標準的な経験リスク最小化：$\\hat{\\theta} = \\arg \\min_{\\theta} \\frac{1}{N} \\sum^N_{i=1} L(z_i, \\theta)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189238f-e4a6-4ed7-acec-8bbed212af80",
   "metadata": {},
   "source": [
    "## Leave-One-Out\n",
    "\n",
    "1つのインスタンスを抜いた状態で訓練した場合にどれだけ予測値が変わるかを考える\n",
    "\n",
    "$n$回学習し直す必要があるので現実的ではない\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{-z} - \\hat{\\theta}\\\\\n",
    "\\hat{\\theta}_{-z} := \\arg \\min_{\\theta \\in \\Theta} \\sum_{z_i \\neq z} L(z_i, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49db0f-ab8f-49ed-bbd8-5ed428039c43",
   "metadata": {},
   "source": [
    "## Influence Function\n",
    "\n",
    "- 論文：[Koh & Liang (2017)](https://arxiv.org/pdf/1703.04730.pdf) [[ar5iv](https://ar5iv.labs.arxiv.org/html/1703.04730)]\n",
    "- 実装：[kohpangwei/influence-release](https://github.com/kohpangwei/influence-release)\n",
    "\n",
    "### アイデア\n",
    "\n",
    "LOOを近似し、再学習を不要にしたい\n",
    "\n",
    "訓練データ全部を使った経験リスクに、データ点$z$についての誤差$L(z, \\theta)$を重み付きで足したリスク関数で訓練したパラメータ$\\hat{\\theta}_{\\epsilon,z}$を考える\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{\\epsilon,z}\n",
    ":= \\arg \\min_{\\theta} \\frac{1}{N} \\sum^N_{i=1} L(z_i, \\theta) + \\epsilon L(z, \\theta)\n",
    "$$\n",
    "\n",
    "$z$を入れることによる変化分がとれるので、これの$\\epsilon$での微分の$\\epsilon = 0$のときの値をパラメータについての上側のinfluence functionとする\n",
    "\n",
    "$$\n",
    "\\mathcal{I}_{up, params}(z) := \\left . \\frac{d \\hat{\\theta}_{\\epsilon,z} }{ d \\epsilon } \\right | _{\\epsilon = 0}\n",
    "= -H^{-1}_{\\hat{\\theta}} \\nabla_{\\theta} L(z, \\hat{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a231a-1d36-43ad-ba47-b2e2e127fa45",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "$$\n",
    "\\left. \\frac{dy}{dx} \\right|_{x=a}\n",
    "$$\n",
    "\n",
    "は「$\\frac{dy}{dx}$に$x=a$を代入した値」あるいは「$x=a$のときの$\\frac{dy}{dx}$」という意味らしい\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53b7ce-eb8d-41b2-a3c0-53a178b9b40f",
   "metadata": {},
   "source": [
    ":::{dropdown} 導出\n",
    "（[Koh & Liang (2017)](https://arxiv.org/pdf/1703.04730.pdf)のAppendixより）\n",
    "\n",
    "up-weightedされた経験リスクのもとでの推定量は\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{\\epsilon, z} = \\arg \\min_{\\theta \\in \\Theta}\n",
    "\\big \\{\n",
    "    R(\\theta) + \\epsilon L(z, \\theta)\n",
    "\\big \\}\n",
    "$$\n",
    "\n",
    "これともとの推定量の差を$\\Delta_{\\epsilon}$とする\n",
    "\n",
    "$$\n",
    "\\Delta_{\\epsilon} = \\hat{\\theta}_{\\epsilon, z} - \\hat{\\theta}\n",
    "$$\n",
    "\n",
    "第二項は$\\epsilon$と関係無いので、$\\epsilon$で微分すると消える\n",
    "\n",
    "$$\n",
    "\\frac{d \\Delta_{\\epsilon} }{d \\epsilon}\n",
    "= \\frac{d \\hat{\\theta}_{\\epsilon, z} }{d \\epsilon}\n",
    "$$\n",
    "\n",
    "$\\hat{\\theta}_{\\epsilon, z}$ は arg minの解なので最適性条件を満たす、つまりup-weightedされた経験リスクを微分してゼロとなるポイント\n",
    "\n",
    "$$\n",
    "0 = \\nabla R(\\hat{\\theta}_{\\epsilon, z}) + \\epsilon \\nabla L(z, \\hat{\\theta}_{\\epsilon, z})\n",
    "$$\n",
    "\n",
    "$\\epsilon \\to 0$とすると$\\hat{\\theta}_{\\epsilon, z} \\to \\hat{\\theta}$なので、テイラー展開$f(x) = f(a) + f(a) (x - a) + \\cdots$を用いると\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "0 &= \\big[ \\nabla R(\\hat{\\theta}) + \\epsilon \\nabla L(z, \\hat{\\theta}) \\big]\n",
    "    + \\big[ \\nabla^2 R(\\hat{\\theta}) + \\epsilon \\nabla^2 L(z, \\hat{\\theta}) \\big] \\Delta_{\\epsilon}\n",
    "    + o(\\| \\Delta_{\\epsilon} \\|) \\\\\n",
    "  &\\approx \\big[ \\nabla R(\\hat{\\theta}) + \\epsilon \\nabla L(z, \\hat{\\theta}) \\big]\n",
    "    + \\big[ \\nabla^2 R(\\hat{\\theta}) + \\epsilon \\nabla^2 L(z, \\hat{\\theta}) \\big] \\Delta_{\\epsilon}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "となる。整理すると\n",
    "\n",
    "$$\n",
    "\\Delta_{\\epsilon} \\approx \n",
    "- \\big[ \\nabla^2 R(\\hat{\\theta}) + \\epsilon \\nabla^2 L(z, \\hat{\\theta}) \\big]^{-1}\n",
    "\\big[ \\nabla R(\\hat{\\theta}_{\\epsilon, z}) + \\epsilon \\nabla L(z, \\hat{\\theta}) \\big]\n",
    "$$\n",
    "\n",
    "であり、$\\hat{\\theta}$は$R(\\hat{\\theta})$を最小化して$\\nabla R(\\hat{\\theta})=0$になると考え、$o(\\epsilon)$の（$\\epsilon$に比例する）項を消すと\n",
    "\n",
    "$$\n",
    "\\Delta_{\\epsilon} \\approx \n",
    "- \\big[ \\nabla^2 R(\\hat{\\theta}) + \\epsilon \\nabla^2 L(z, \\hat{\\theta}) \\big]^{-1}\n",
    "\\big[\n",
    "    \\underbrace{ \\nabla R(\\hat{\\theta}_{\\epsilon, z}) }_{=0}\n",
    "    + \\epsilon \\nabla L(z, \\hat{\\theta})\n",
    "\\big]\n",
    "$$\n",
    "\n",
    "より\n",
    "\n",
    "$$\n",
    "\\Delta_{\\epsilon}\n",
    "\\approx - \\nabla^2 R(\\hat{\\theta})^{-1} \\nabla L(z, \\hat{\\theta}) \\epsilon \\\\\n",
    "= - H_{\\hat{\\theta}}^{-1} \\nabla L(z, \\hat{\\theta}) \\epsilon\n",
    "$$\n",
    "\n",
    "（$\\epsilon \\nabla L(z, \\hat{\\theta})$は残るのはなぜ？？？？）\n",
    "\n",
    "よって\n",
    "\n",
    "$$\n",
    "\\left . \\frac{d \\hat{\\theta}_{\\epsilon,z} }{ d \\epsilon } \\right | _{\\epsilon = 0}\n",
    "= -H^{-1}_{\\hat{\\theta}} \\nabla_{\\theta} L(z, \\hat{\\theta})\n",
    "$$\n",
    "\n",
    "（$\\epsilon = 0$のときなので掛かっていた$\\epsilon$が消えている？？しかしゼロを掛けたら他のも消えないのか）\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb902a7-e6a0-4d3a-b99f-111aa1b980a0",
   "metadata": {},
   "source": [
    "### LOOの近似\n",
    "\n",
    "もし$\\epsilon = -\\frac{1}{N}$なら\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{\\epsilon,z}\n",
    "= \\arg \\min_{\\theta} \\frac{1}{N} \\sum^N_{i=1} L(z_i, \\theta) - \\frac{1}{N} L(z, \\theta)\n",
    "$$\n",
    "\n",
    "もし$z$が訓練データに含まれるなら、訓練データから$z$を除去した場合と同様なので、LOOの考え方を近似できる\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{-z} - \\hat{\\theta}\n",
    "\\approx -\\frac{1}{n} \\mathcal{I}_{up, params}(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461796fd-bd54-404a-8ad2-351b017104d7",
   "metadata": {},
   "source": [
    "### 損失へのupweighting\n",
    "\n",
    "データ点$z_{test}$におけるinfluenceを計算するため、微分の連鎖律を使う\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{I}_{up, loss}(z, z_{test})\n",
    ":&= \\left . \\frac{d L(z_{test}, \\hat{\\theta}_{\\epsilon, z}) }{ d \\epsilon } \\right | _{\\epsilon = 0} \\\\\n",
    "&= \\nabla_{\\theta} L(z_{test}, \\hat{\\theta})^\\top\n",
    "    \\left . \\frac{d \\hat{\\theta}_{\\epsilon, z} }{ d \\epsilon } \\right | _{\\epsilon = 0} \\\\\n",
    "&= - \\nabla_{\\theta} L(z_{test}, \\hat{\\theta})^\\top H^{-1}_{\\hat{\\theta}} \\nabla_{\\theta} L(z, \\hat{\\theta})\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e103ac-1ee1-4455-9501-e4fdb3618bb0",
   "metadata": {},
   "source": [
    "## FastFI\n",
    "\n",
    "[Guo, H., Rajani, N. F., Hase, P., Bansal, M., & Xiong, C. (2020). Fastif: Scalable influence functions for efficient model interpretation and debugging. arXiv preprint arXiv:2012.15781.](https://arxiv.org/pdf/2012.15781.pdf)\n",
    "\n",
    "Influence Functionは計算が重い\n",
    "\n",
    "1. データ点の評価は$O(n)$\n",
    "2. モデルパラメータのinverse Hessianの計算コストが高い\n",
    "3. 上記の計算は並列可能であるが、先行研究のアルゴリズムでは直列\n",
    "\n",
    "FastIfのアイデア\n",
    "\n",
    "1. 全データを探索するのではなく、fast nearest neighbor search（Johnson et al., 2017）で探索範囲を狭め、桁違いに計算量を抑える\n",
    "2. Hessianの推定において、品質を保ちつつ時間を半分以下にするハイパーパラメータ集合を識別\n",
    "3. シンプルに並列計算へ拡張し、さらに2倍高速化\n",
    "\n",
    "実験においてほとんどのケースで全体で2桁程度の高速化が確認された\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0170f-dfa1-48db-9b0a-6048d9fd3a21",
   "metadata": {},
   "source": [
    "## LeafInfluence\n",
    "\n",
    "- Paper: [[1802.06640] Finding Influential Training Samples for Gradient Boosted Decision Trees](https://arxiv.org/abs/1802.06640)\n",
    "- Code: [bsharchilev/influence_boosting](https://github.com/bsharchilev/influence_boosting)\n",
    "- 実装は [Brophy et al. (2023)](https://jmlr.org/papers/v24/22-0449.html)のリポジトリ[jjbrophy47/tree_influence](https://github.com/jjbrophy47/tree_influence) のほうがいいかも\n",
    "  - [Brophy et al. (2023)](https://jmlr.org/papers/v24/22-0449.html)はDataShapelyなど色々な事例型説明の手法を適用・比較しており、GBDTにおける事例型説明についてまとまっている\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb9a38-07e1-435d-a095-681c8b22d155",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "- [Influence Functionでインスタンスの重要度を解釈する - Dropout](https://dropout009.hatenablog.com/entry/2021/07/19/223929)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34aece-3a09-4aa8-8615-19f6c1aaf661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
