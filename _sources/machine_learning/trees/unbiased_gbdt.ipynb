{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59e5ae8-4ada-4557-9fe1-78ccf9aba0f2",
   "metadata": {},
   "source": [
    "# UnbiasedGBM\n",
    "\n",
    ":::{card} Unbiased gradient boosting decision tree with unbiased feature importance. (IJCAI2023)\n",
    "\n",
    "- page: [Zhang, Z., Zhang, T., & Li, J. (2023, August). Unbiased gradient boosting decision tree with unbiased feature importance. In Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (pp. 4629-4637).](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/515)\n",
    "- pdf: [arxiv.org/pdf/2305.10696v1](https://arxiv.org/pdf/2305.10696v1)\n",
    "\n",
    ":::\n",
    "\n",
    "## 概要\n",
    "\n",
    "GBDTの分割（split）を決めるアルゴリズムには次のような バイアス（偏り） が存在することが問題になっている：\n",
    "\n",
    "1. 特徴量の 分割候補の数（例えば連続値やカテゴリ数が多い特徴は多くの分割点を持てる）に依存して、有利になりやすい。\n",
    "2. 分割の「改善度」（gain）を推定する際に、訓練データだけを使って評価するため、過学習や誤った重要度評価につながる。\n",
    "\n",
    "この偏りにより、以下のような問題が起きる：\n",
    "\n",
    "1. 解釈性（interpretability）が低くなる：実際には無関係な特徴量が高く評価されてしまう可能性。 \n",
    "2. 過学習（overfitting）の原因となる：訓練データ上でよくなる分割を選びがちで、それが一般化性能を損なうことがある。 \n",
    "\n",
    "これらの問題に対処するために、Unbiased GBMを提唱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd3321-6362-4e93-8f9d-fbc11b78018f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48209b9-a159-41bc-b30c-5271cff9606c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
