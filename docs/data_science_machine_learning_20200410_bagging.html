<!DOCTYPE html>
<html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GXSWJY51EG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GXSWJY51EG');
  </script>

  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

  <script src="https://kit.fontawesome.com/95678975f3.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Frank+Ruhl+Libre|Roboto" rel="stylesheet">
  <link href="modules/progress-nav/normalize.css" rel="stylesheet" type="text/css" />
  <link href="modules/progress-nav/style.css" rel="stylesheet" type="text/css" />

    <meta name="dcterms.date" content="2020-04-10">
  <title>盆暗の勉強メモ – なぜbaggingは予測精度を上げるのか</title>
  <style type="text/css">code{white-space: pre;}</style>



  <link rel="stylesheet" href="modules/style.css">

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>


</head>
<body>
<header>
    <div class="logo-area p-4">
        <a href="index.html">盆暗の勉強メモ</a>
    </div>

    <nav class="navbar px-4 py-1 navbar-expand-lg navbar-light bg-light">
        <ul class="navbar-nav">
            <li class="nav-item"><a class="nav-link" href="data_science.html"><i class="fas fa-chart-bar"></i> Data Science</a></li>
            <li class="nav-item"><a class="nav-link" href="engineering.html"><i class="fas fa-file-code"></i> Software Engineering</a></li>
            <li class="nav-item"><a class="nav-link" href="mathematics.html"><i class="fas fa-square-root-alt"></i> Mathematics</a></li>
        </ul>
    </nav>
</header>  <main class="py-2">
  <!-- table of contents -->
      <nav class="toc" id="TOC">
    <ul>
    <li><a href="#予備知識">予備知識</a><ul>
    <li><a href="#バギングとは">バギングとは</a></li>
    <li><a href="#バイアスとバリアンス">バイアスとバリアンス</a></li>
    </ul></li>
    <li><a href="#バギングによるバリアンスの低減">バギングによるバリアンスの低減</a></li>
    <li><a href="#バギングの効果">バギングの効果</a></li>
    <li><a href="#バギングと相関">バギングと相関</a></li>
    <li><a href="#参考">参考</a></li>
    </ul>
      <!-- svg for progress-nav -->
      <svg class="toc-marker" width="200" height="200" xmlns="http://www.w3.org/2000/svg">
        <path stroke="dimgray" stroke-width="3" fill="transparent" stroke-dasharray="0, 0, 0, 1000" stroke-linecap="round" stroke-linejoin="round" transform="translate(-0.5, -0.5)" />
      </svg>
    </nav>
    
  <!-- main contents -->
    
    <!-- contents header -->
        <div>
      <h1 class="title">なぜbaggingは予測精度を上げるのか</h1>
                        <p class="date">2020-04-10</p>
          </div>
    
    <!-- contents body -->
    <article class="contents">
<p>機械学習の分野では、バギング（bagging）というアンサンブル学習の方法があります。</p>
<p><strong>なぜバギングで予測精度が上がるのか？</strong>という点について少し学んだのでメモしておきます。</p>
<h1 id="予備知識">予備知識</h1>
<h2 id="バギングとは">バギングとは</h2>
<p>バギング（bagging, “<strong>b</strong>ootstrap <strong>agg</strong>regat<strong>ing</strong>”の略）とは、多様性をもった複数の決定木を作り、その平均（回帰の場合）や多数決を行った結果（分類の場合）を最終的な予測値とする学習法です。</p>
<p>アルゴリズムは以下のようになります：</p>
<ol style="list-style-type: decimal">
<li>元のデータを<span class="math inline">\(\mathcal D=(\boldsymbol{x}, y)\)</span>とする。<span class="math inline">\(\mathcal D\)</span>からサンプルサイズ<span class="math inline">\(N\)</span>のデータを復元抽出する作業を<span class="math inline">\(B\)</span>回繰り返し、新しいデータセット（ブートストラップ標本 bootstrap sample）を<span class="math inline">\(B\)</span>個作る。</li>
<li>各ブートストラップ標本<span class="math inline">\(\{\mathcal D_b\}(b=1,2,...,B)\)</span>について、それぞれ予測器<span class="math inline">\(\{f^b(\boldsymbol{x})\}_{b=1}^B\)</span>を学習させる。</li>
<li>ある入力点<span class="math inline">\(\boldsymbol{x}_0\)</span>における予測値を算出するときは、<span class="math inline">\(B\)</span>個の予測値<span class="math inline">\(\{f^b(\boldsymbol{x_0})\}_{b=1}^B\)</span>の平均（回帰問題の場合）あるいは多数決（分類問題の場合）を行い、それを最終的な予測値とする。</li>
</ol>
<h2 id="バイアスとバリアンス">バイアスとバリアンス</h2>
<p>誤差はバイアスとバリアンスという構成要因に分解できます。</p>
<p>データがモデル<span class="math inline">\(Y=f(X) + \varepsilon\)</span>から生成されたとし、<span class="math inline">\(\text{E}(\varepsilon)=0,\ \text{Var}(\varepsilon)=\sigma^2_{\varepsilon}\)</span>とします。議論を簡潔にするため、データにおける<span class="math inline">\(x_i\)</span>の値は決定論的に決められているとします。そのとき、<span class="math inline">\(X=x_0\)</span>における期待予測誤差、もしくは汎化誤差と呼ばれるものは <span class="math display">\[
\begin{align}\text{EPE}(x_0)&amp;=\text{E}_{\mathcal D}[(Y-\hat{f}(x_0))^2|X=x_0]\\&amp;= \sigma^2_{\varepsilon} + (\text{E}_{\mathcal D}[\hat{f}(x_0)] - f(x_0))^2+ \text{E}_{\mathcal D}[(\hat{f}(x_0) - \text{E}_{\mathcal D}[\hat{f}(x_0)])^2]\\&amp;= \sigma^2_{\varepsilon} + \text{Bias}(\hat{f}(x_0))^2 + \text{Var}_{\mathcal D}(\hat{f}(x_0))\\&amp;= \text{削減不能な誤差} + \text{バイアス}^2 + \text{バリアンス（分散）} \end{align}
\]</span> と分解できます。ただし、<span class="math inline">\(\text{E}_{\mathcal D}\)</span>はいろいろな訓練サンプル集合<span class="math inline">\(\mathcal D\)</span>についてとった平均です。各用語の意味は以下の通り：</p>
<ul>
<li><strong>削減不能な誤差</strong>（irreducible error）：<span class="math inline">\(\text{Var}_{\mathcal D}[Y|X=x_0]=\text{Var}_{\mathcal D}[\varepsilon]=\sigma^2_{\varepsilon}\)</span> データの測定誤差などに由来する、目的変数の分散でありノイズの分散</li>
<li><strong>バイアス</strong>（Bias）：<span class="math inline">\(\text{E}_{\mathcal D}[\hat{f}(x_0)] - f(x_0)\)</span> 平均的な予測値と真の値との差</li>
<li><strong>バリアンス</strong>（Variance）：<span class="math inline">\(\text{E}_{\mathcal D}[\hat{f}(x_0) - \text{E}_{\mathcal D}[\hat{f}(x_0)]]^2\)</span> 予測値の分散</li>
</ul>
<h1 id="バギングによるバリアンスの低減">バギングによるバリアンスの低減</h1>
<p>解析のため、真の分布<span class="math inline">\(\mathcal P\)</span>から無限に学習データセットが得られるとし、その下で構成される理想的な平均化推定量（aggregated estimator）<span class="math inline">\(\bar{f}(x) = \text{E}_{\mathcal P} [\hat{f}(x)]\)</span>があったとします。</p>
<p>ここで<span class="math inline">\(\hat{f}(x)\)</span>は分布<span class="math inline">\(\mathcal{P}\)</span>から独立に取り出した学習データ<span class="math inline">\(\{x_i, y_i\}_{i=1}^N\)</span>で学習した予測器の、入力点<span class="math inline">\(x\)</span>における予測値です。</p>
<p>固定された入力点<span class="math inline">\(x\)</span>の下での平均2乗誤差（MSE）を分解すると <span class="math display">\[
\begin{align}\text{E}_{\mathcal P} [(Y - \hat{f}(x))^2]&amp;= \text{E}_{\mathcal P} [(Y - \bar{f}(x) + \bar{f}(x) -\hat{f}(x))^2]\\
&amp;=  \text{E}_{\mathcal P} [(Y - \bar{f}(x))^2]
+ \underbrace{\text{E}_{\mathcal P} [(\hat{f}(x) - \bar{f}(x))^2]}_{Variance}\\
&amp;\geq \text{E}_{\mathcal P} [(Y - \bar{f}(x))^2]\end{align}
\]</span> 2行目の第2項<span class="math inline">\(\text{E}_{\mathcal P} [(\hat{f}(x) - \bar{f}(x))^2]\)</span>は平均<span class="math inline">\(\bar{f}(x)\)</span>のまわりでの<span class="math inline">\(\hat{f}(x)\)</span>の分散（バリアンス）です。</p>
<p>上の式は、<span class="math inline">\(Y\)</span>と平均化推定量<span class="math inline">\(\bar{f}(x)\)</span>の平均2乗誤差<span class="math inline">\(\text{E}_{\mathcal P} [(Y - \bar{f}(x))^2]\)</span>は、<span class="math inline">\(Y\)</span>と推定量<span class="math inline">\(\hat{f}(x)\)</span>の平均2乗誤差<span class="math inline">\(\text{E}_{\mathcal P} [(Y - \hat{f}(x))^2]\)</span>よりもバリアンスの分だけ小さいことを示しています。</p>
<p>一般的に、バイアスとバリアンスの間にはトレードオフ関係があり、バリアンスを下げるとバイアスが増える傾向がありますが、<strong>バギングを使うことで、バイアスを増やさずにバリアンスをゼロにすることができる</strong>わけです。</p>
<p>上の議論は真の分布<span class="math inline">\(\mathcal P\)</span>から無限にデータセットが得られる場合で、現実にはありえません。Breiman (1996)が提案したバギングでは、この無限のデータセットをブートストラップサンプルで近似したものになります。ブートストラップによる現実のバギングでも、多くの場合はこのようにバリアンスを下げてくれます。</p>
<p>ただし、回帰においてバギングは平均2乗誤差を増加させず減少させますが、分類の場合は多数決になるので、一定以上の精度がないと逆に悪化させる可能性があります。</p>
<h1 id="バギングの効果">バギングの効果</h1>
<p>Breiman（1999）が行った実験結果をまとめたのが以下の表です。</p>
<div class="figure">
<img src="20200410_bagging.assets/image-20200427012403568.png" />

</div>
<p>Data Setはデータセット名、Noiseはデータセットのノイズ、Unpruned CARTは、枝刈りを行わなかった単体の決定木で、Baggingは枝刈りしていない50本の決定木で構成されたBaggingです。</p>
<p>理論解析の結論とほぼ合致していて、<strong>Baggingが単体の決定木と同程度のBiasを保ったままVarianceを大幅に削減している</strong>ことがわかります。</p>
<p>理論解析と違ってVarianceがゼロにならないのは、</p>
<ol style="list-style-type: decimal">
<li>データセットがブートストラップサンプルによる近似であること</li>
<li>決定木同士の相関がある</li>
</ol>
<p>という理由が考えられます。</p>
<h1 id="バギングと相関">バギングと相関</h1>
<p>分散<span class="math inline">\(\sigma^2\)</span>の<span class="math inline">\(B\)</span>個の独立な確率変数<span class="math inline">\(X\)</span>の平均<span class="math inline">\(\bar{X}\)</span>の分散は <span class="math display">\[
\text{Var}[\bar{X}] = \frac{\sigma^2}{B}
\]</span> になりますが、確率変数間に正の相関<span class="math inline">\(\rho\)</span>がある場合は <span class="math display">\[
\text{Var}[\bar{X}] = \frac{1-\rho}{B} \sigma^2 + \rho \sigma^2
\]</span> となります。</p>
<p>ブートストラップ標本の数<span class="math inline">\(B\)</span>を増やすと第1項は減りますが、第2項は残ります。</p>
<p>単純なバギングで決定木を作っただけでは<span class="math inline">\(\rho \sigma^2\)</span>が残ってしまい、分散の低減効果が少なくなります。</p>
<p>そこでランダムフォレスト（Breiman 2001）では、複数の決定木を作っていくフェーズで、あらかじめ決めた数の特徴量をランダムに選び出して決定木を作ることで決定木間の相関を大幅に減らすように工夫されています。</p>
<h1 id="参考">参考</h1>
<p><a href="https://link.springer.com/content/pdf/10.1023/A:1018054314350.pdf">Breiman, L. (1996). Bagging predictors. <em>Machine learning</em>, <em>24</em>(2), 123-140.</a></p>
<p><a href="https://www.stat.berkeley.edu/users/breiman/adaptbag99.pdf">Breiman, L. (1999). Using adaptive bagging to debias regressions (p. 16). Technical Report 547, Statistics Dept. UCB.</a></p>
<p><a href="https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf">Breiman, L. (2001). Random forests. <em>Machine learning</em>, <em>45</em>(1), 5-32.</a></p> <!-- NOTE: ここにインデントをつけるとcode部のインデントが壊れる -->
    </article>
    
      </main>

  <script src="modules/progress-nav/script.js"></script>
</body>
</html>