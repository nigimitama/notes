<!DOCTYPE html>
<html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GXSWJY51EG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GXSWJY51EG');
  </script>

  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

  <script src="https://kit.fontawesome.com/95678975f3.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Frank+Ruhl+Libre|Roboto" rel="stylesheet">
  <link href="modules/progress-nav/normalize.css" rel="stylesheet" type="text/css" />
  <link href="modules/progress-nav/style.css" rel="stylesheet" type="text/css" />

    <meta name="dcterms.date" content="2018-11-23">
  <title>盆暗の勉強メモ – 「統計的に有意」だけでは足りないワケ：推定量のバイアス-バリアンス分解</title>
  <style type="text/css">code{white-space: pre;}</style>



  <link rel="stylesheet" href="modules/style.css">

<script src="/usr/share/javascript/mathjax/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>


</head>
<body>
<header>
    <div class="logo-area p-4">
        <a href="index.html">盆暗の勉強メモ</a>
    </div>

    <nav class="navbar px-4 py-1 navbar-expand-lg navbar-light bg-light">
        <ul class="navbar-nav">
            <li class="nav-item"><a class="nav-link" href="data_science.html"><i class="fas fa-chart-bar"></i> Data Science</a></li>
            <li class="nav-item"><a class="nav-link" href="engineering.html"><i class="fas fa-file-code"></i> Software Engineering</a></li>
            <li class="nav-item"><a class="nav-link" href="mathematics.html"><i class="fas fa-square-root-alt"></i> Mathematics</a></li>
        </ul>
    </nav>
</header>  <main class="py-2">
  <!-- table of contents -->
      <nav class="toc" id="TOC">
    <ul>
    <li><a href="#バイアスbiasとバリアンスvariance">バイアス（bias）とバリアンス（variance）</a><ul>
    <li><a href="#mseの展開">MSEの展開</a></li>
    <li><a href="#つまり">つまり？</a></li>
    <li><a href="#イメージ図">イメージ図</a></li>
    </ul></li>
    <li><a href="#バリアンスを下げるには">バリアンスを下げるには</a><ul>
    <li><a href="#標準誤差">標準誤差</a></li>
    <li><a href="#バリアンスを下げるには-1">バリアンスを下げるには</a></li>
    </ul></li>
    <li><a href="#バイアスを下げるには">バイアスを下げるには</a><ul>
    <li><a href="#バイアスの種類と原因">バイアスの種類と原因</a><ul>
    <li><a href="#欠落変数バイアス除外変数バイアス">１．欠落変数バイアス（除外変数バイアス）</a></li>
    <li><a href="#同時決定バイアス">２．同時決定バイアス</a></li>
    <li><a href="#内生性バイアス逆の因果性">３．内生性バイアス（逆の因果性）</a></li>
    </ul></li>
    <li><a href="#バックドア基準">バックドア基準</a></li>
    </ul></li>
    <li><a href="#今回の話から導かれる推定の３つの方向性">今回の話から導かれる推定の３つの方向性</a><ul>
    <li><a href="#実験ランダム化比較試験abテスト">１．実験（ランダム化比較試験・A/Bテスト）</a></li>
    <li><a href="#準実験擬似実験">２．準実験・擬似実験</a></li>
    <li><a href="#統計モデリング">３．統計モデリング</a></li>
    </ul></li>
    <li><a href="#まとめ">まとめ</a></li>
    <li><a href="#参考">参考</a><ul>
    <li><a href="#参考サイト">参考サイト</a></li>
    <li><a href="#参考mseの展開">（参考）MSEの展開</a></li>
    </ul></li>
    </ul>
      <!-- svg for progress-nav -->
      <svg class="toc-marker" width="200" height="200" xmlns="http://www.w3.org/2000/svg">
        <path stroke="dimgray" stroke-width="3" fill="transparent" stroke-dasharray="0, 0, 0, 1000" stroke-linecap="round" stroke-linejoin="round" transform="translate(-0.5, -0.5)" />
      </svg>
    </nav>
    
  <!-- main contents -->
    
    <!-- contents header -->
        <div>
      <h1 class="title">「統計的に有意」だけでは足りないワケ：推定量のバイアス-バリアンス分解</h1>
                        <p class="date">2018-11-23</p>
          </div>
    
    <!-- contents body -->
    <article class="contents">
<p>機械学習の教科書には，序盤などに「バイアスとバリアンス」とか「バイアス－バリアンス分解」といった項目があります。「誤差にはバイアスとバリアンスの２種類があるよ」という話です。正直私はそれを読んでも「ふーん。まぁ，そうだよね」と思うくらいで特に重要なトピックとも思っていませんでした。</p>
<p>ところが，統計学にも「バイアスとバリアンス」の話があって，そちらは個人的に「なるほど！！」となったのでここにメモしておきます。</p>
<h1 id="バイアスbiasとバリアンスvariance">バイアス（bias）とバリアンス（variance）</h1>
<h3 id="mseの展開">MSEの展開</h3>
<p>推定したい真のパラメータ<span class="math inline">\(\theta\)</span>とその推定量<span class="math inline">\(\hat{\theta}\)</span>の平均二乗誤差（Mean Squared Error：MSE）<span class="math inline">\(E[(\hat{\theta} - \theta)^2]\)</span>を分解（展開）すると，以下のようになります。 <span class="math display">\[
\begin{align}
MSE(\hat{\theta}, \theta)
&amp;= E[(\hat{\theta} - \theta)^2] \\
&amp;= E[(\hat{\theta} - E[\hat{\theta}] + E[\hat{\theta}]-\theta)^2] \\
&amp;= E[(\hat{\theta} - E[\hat{\theta}])^2] + [E[\hat{\theta}]-\theta]^2\\
&amp;= Var(\hat{\theta}) + Bias(\hat{\theta},\theta)^2
\end{align}
\]</span></p>
<p>ここで<span class="math inline">\(Var(\hat{\theta})\)</span>は<strong>バリアンス</strong>（variance，普通に分散のこと），<span class="math inline">\(Bias(\hat{\theta},\theta)\)</span>は<strong>バイアス</strong>（bias）で，それぞれ <span class="math display">\[
\begin{align}
Var(\hat{\theta}) &amp;= E[(\hat{\theta} - E[\hat{\theta}])^2] \\
Bias(\hat{\theta},\theta) &amp;= E[\hat{\theta}]-\theta
\end{align}
\]</span> と定義されます。<strong>「パラメータの推定量と真の値との平均二乗誤差はバリアンスとバイアスの二乗の和である」</strong>ということです。</p>
<h3 id="つまり">つまり？</h3>
<p>「統計的に有意」かどうかの判断で使われる標準誤差（推定量の標準偏差）<span class="math inline">\(SE(\hat{\theta})\)</span>は分散<span class="math inline">\(Var(\hat{\theta})\)</span>の平方根なので、ここに関わってきます。</p>
<p>上の分解は「パラメータの推定を誤る原因は，標準誤差とバイアスの2つに分けられる」ということであり，言い換えると，「<strong>『統計的に有意（分散が低い）』であっても推定が正しいとは限らない</strong>（バイアスが存在するかもしれない）」ということになります。これは非常に興味深いトピックです。</p>
<p>（ただし，標本平均のように<strong>不偏推定量</strong>（unbiased estimator）と呼ばれるタイプの推定量はバイアスがゼロなのでこの心配はありません。一方，回帰分析の最小二乗推定量などは不偏性を得るための前提が満たされにくいので問題になります。）</p>
<h3 id="イメージ図">イメージ図</h3>
<p>射的に例えてイメージ図を描くなら，以下のような感じでしょうか。的の中心が真の値<span class="math inline">\(\theta\)</span>で，着弾点が推定量<span class="math inline">\(\hat{\theta}\)</span>です。</p>
<p><strong>「バリアンスが低い（統計的に有意である）」ことが必ずしも「真の値をよく推定できている」と言えるとは限らない</strong>ことがわかるかなと思います（右上の図）。</p>
<p><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/n/nigimitama/20181124/20181124054245.png" /></p>
<h1 id="バリアンスを下げるには">バリアンスを下げるには</h1>
<p>「バリアンスを下げるにはどうしたらいいのか」を考えるために，まず，「標準誤差」ってなんだっけ，「統計的に有意」ってなんだっけ，というところの用語の確認から行っていきます。回帰分析での推定を例に考えていきます。</p>
<h3 id="標準誤差">標準誤差</h3>
<p>標準誤差（standard error）はパラメータの推定量と真の値とのばらつき（標準偏差）のことです。</p>
<p>回帰分析の場合，誤差項<span class="math inline">\(\varepsilon_i\)</span>の分布について <span class="math display">\[
\varepsilon_i \sim N(0, \sigma^2)
\]</span></p>
<p>という仮定をおくと，傾き係数<span class="math inline">\(\hat{\beta_1}\)</span>の分布は <span class="math display">\[
\hat{\beta_1} \sim ~ N\left(\beta_1, \frac{\sigma^2}{\sum^n_{i=1}(X_i-\bar{X})^2}\right)
\]</span> となることが知られています。</p>
<p>誤差項<span class="math inline">\(\varepsilon_i\)</span>の分散<span class="math inline">\(\sigma^2\)</span>の不偏推定量<span class="math inline">\(\hat{\sigma}^2\)</span>は，回帰分析の残差<span class="math inline">\(\hat{u}_i = Y_i - (\hat{\beta}_0+\hat{\beta}_1X_i)\)</span>から得られることが知られていて，以下のようになります。 <span class="math display">\[
\hat{\sigma}^2 = \frac{\sum_{i=1}^n\hat{u}_i}{n-2}
\]</span> これを用いると，推定量<span class="math inline">\(\hat{\beta}_1\)</span>の標準誤差は <span class="math display">\[
SE(\hat{\beta}_1) = \sqrt{\frac{\hat{\sigma}^2}{\sum^n_{i=1}(X_i-\bar{X})^2}}
\]</span> となります。</p>
<p>「統計的に有意」かどうかは，<span class="math inline">\(t\)</span>検定の場合，推定量（と帰無仮説で想定する真の値の差）を標準誤差で割って得る<span class="math inline">\(t\)</span>値（推定量のばらつきに対する推定量の大きさ）から判断します。</p>
<h3 id="バリアンスを下げるには-1">バリアンスを下げるには</h3>
<p>バリアンスを下げるには，どうすればよいのでしょうか。</p>
<p>標準誤差<span class="math inline">\(SE(\hat{\beta}_1)\)</span>は，言い換えれば <span class="math display">\[
SE(\hat{\beta}_1) = \sqrt{\frac{\hat{\sigma}^2}{\sum^n_{i=1}(X_i-\bar{X})^2}} = \sqrt{\frac{\text{誤差項のばらつき}}{\text{データのばらつき}}}
\]</span> で，「誤差項のばらつき」<span class="math inline">\(\hat{\sigma}^2\)</span>は <span class="math display">\[
\hat{\sigma}^2 = \frac{\sum_{i=1}^n\hat{u}_i}{n-2} = \frac{\text{予測精度の低さ}}{\text{サンプルサイズの大きさ}}
\]</span> になります。つまり，バリアンスを下げるには，</p>
<ul>
<li>サンプルサイズを上げて<span class="math inline">\(\hat{\sigma}^2\)</span>を下げる</li>
<li>予測精度を上げて残差<span class="math inline">\(\hat{u}_i\)</span>を下げる</li>
</ul>
<p>という方法が考えられます。</p>
<p>例えば手元にモデルに入れていない変数がある場合に投入してみて残差を減らしてみたり，とかです。</p>
<h1 id="バイアスを下げるには">バイアスを下げるには</h1>
<p>「バイアスを回避するにはどうしたらよいのか」，あるいは「そもそもどういうときにバイアスが発生するのか」といったことについて考えてみます。</p>
<h2 id="バイアスの種類と原因">バイアスの種類と原因</h2>
<h3 id="欠落変数バイアス除外変数バイアス">１．欠落変数バイアス（除外変数バイアス）</h3>
<p>本来なら説明変数としてモデルに含まれるべき変数が欠落しているために誤差項と説明変数が独立でなくなり生じるバイアスを<strong>欠落変数バイアス</strong>（omitted variable bias）と呼びます。</p>
<p>例えば<span class="math inline">\(X\to Y\)</span>への因果関係を見たいとき，<span class="math inline">\(X,Y\)</span>の両方に影響を与える変数があるとき，これを<strong>交絡変数</strong>（confounding variable）と呼びます（<strong>交絡因子</strong>とも呼ばれます）。交絡変数があるときは，モデルに含めないと欠落変数バイアスが生じます。</p>
<figure>
<img src="20181123_bias_and_variance.assets/1543009165138.png" alt="1543009165138" /><figcaption>1543009165138</figcaption>
</figure>
<h3 id="同時決定バイアス">２．同時決定バイアス</h3>
<p>被説明変数と説明変数が相互に影響を与え合っている（因果関係がループしている）関係にあるときもまた誤差項と説明変数が独立でなくなり，バイアスを生みます。</p>
<figure>
<img src="20181123_bias_and_variance.assets/1543009186279.png" alt="1543009186279" /><figcaption>1543009186279</figcaption>
</figure>
<h3 id="内生性バイアス逆の因果性">３．内生性バイアス（逆の因果性）</h3>
<p>説明変数に使用している変数が内生変数（想定しているモデルの中で内生的に決定される変数で，被説明変数に該当する）である場合も誤差項と説明変数が独立でなくなり，バイアスを生じます。</p>
<figure>
<img src="20181123_bias_and_variance.assets/1543009201244.png" alt="1543009201244" /><figcaption>1543009201244</figcaption>
</figure>
<h2 id="バックドア基準">バックドア基準</h2>
<p>バイアスを避けるには，データが生成されている構造をしっかりと捉えて，上記のバイアスを生むことがないように統計モデルを構築する必要があります。その際に参考になる変数選択基準がバックドア基準というものです。</p>
<p><strong>バックドア基準</strong></p>
<p>原因をX，結果をYと表すとき， 1. 追加した説明変数はXの子孫（下流側）ではない 2. （Xから出る矢印を除いたときの因果構造において） 追加した説明変数によってXとYの交絡因子からの流れをすべて遮断できている</p>
<p>バックドア基準については林岳彦先生のスライドや岩波データサイエンスVol.3での記事がわかりやすいのでおすすめです（岩波の記事はこのスライドと中身ほぼ一緒です）。</p>
<p><a href="https://www.slideshare.net/takehikoihayashi/ss-73059140">『バックドア基準の入門』＠統数研研究集会 - SlideShare</a></p>
<h1 id="今回の話から導かれる推定の３つの方向性">今回の話から導かれる推定の３つの方向性</h1>
<p>（※この先の記述は他に明示している文書を見たことがないので私の推測です）</p>
<p>「『統計的に有意』であればその推定が正しいわけではない」という点から生まれる「<strong>ではどう推定していくべきか</strong>」についての考え方は，私が知る範囲では３つあります。</p>
<h3 id="実験ランダム化比較試験abテスト">１．実験（ランダム化比較試験・A/Bテスト）</h3>
<p>実験（ランダム化比較試験：効果を測定したい処置を行うグループへの被験者の割付をランダムに行う）によってデータの生成構造をコントロールし，バイアスを回避するアプローチです。</p>
<h3 id="準実験擬似実験">２．準実験・擬似実験</h3>
<p>計量経済学では「実験（ランダム化比較試験）を行いたいが，分野の都合上，実験は難しい」という分野の特性に合わせて，観測データから「実験に似た状況（ランダム割付が発生している状況）を探し出し，実験したとみなす」ような手法をとることもあります。</p>
<p>実験と見なせる状況は観測されたデータのうちごく一部になってしまうので，局所的（一部の主体への）平均因果効果の推定になってしまうことも多いですが，「ランダム化されているのでバイアスは除去できている」という点は分析上強い武器になります。</p>
<h3 id="統計モデリング">３．統計モデリング</h3>
<p>現実のデータ生成構造をうまく模すことができない統計モデルを組んで推定を行うと，パラメータにバイアスが含まれます。なので，データを良く見て正しい統計モデリングを行おうという話です。</p>
<p>計量経済学では実験的なアプローチが導入される前のパラダイムではこの方向性が主流でした。しかし，例えばバイアスを生む原因となる要因が観測不可能なものである場合に対処がきわめて難しくなるなど，限界はあります（例えばその人の「知性」や「健康への関心の高さ」という明示的にデータにできないものが交絡因子であると考えられるときにどう統計モデルに組み込むか）。</p>
<h1 id="まとめ">まとめ</h1>
<ul>
<li>パラメータの真の値と推定量の誤差（MSE）は，バイアスとバリアンスに分けられる</li>
<li>「バリアンスが小さい（統計的に有意）」かつ「バイアスがない」推定量が良い推定量</li>
<li>バイアスの回避のためには，いろいろアプローチがあり，できれば実験が望ましい</li>
</ul>
<h1 id="参考">参考</h1>
<h3 id="参考サイト">参考サイト</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator#Bias,_variance_and_mean_squared_error">Bias_of_an_estimator - Wikipedia</a></li>
<li><a href="http://www.statisticalengineering.com/Weibull/precision-bias.html">Precision and Bias - Statistical Engineering</a></li>
</ul>
<h3 id="参考mseの展開">（参考）MSEの展開</h3>
<p>自分用にMSEのバイアスーバリアンス分解の式展開を超丁寧にメモ <span class="math display">\[
MSE = E[(\hat{\theta} - \theta)^2]
\]</span> まず，同じ数を足して引いても全体の結果に影響を与えないので定数<span class="math inline">\(E[\hat{\theta}]\)</span>を足して引いて <span class="math display">\[
E[(\hat{\theta} - E[\hat{\theta}] + E[\hat{\theta}]-\theta)^2]
\]</span> つぎに<span class="math inline">\(\hat{\theta} - E[\hat{\theta}]=a, \ E[\hat{\theta}]-\theta = b\)</span>とおいて（ひとかたまりに考えて）やれば，<span class="math inline">\((a+b)^2=a^2+2ab+b^2\)</span>なので <span class="math display">\[
\begin{align}
&amp; E[(\hat{\theta} - E[\hat{\theta}])^2 + 2(\hat{\theta} - E[\hat{\theta}])(E[\hat{\theta}]-\theta) + (E[\hat{\theta}] - \theta)^2]
\\
=&amp; E[(\hat{\theta} - E[\hat{\theta}])^2] 
+ E[2(\hat{\theta} - E[\hat{\theta}])(E[\hat{\theta}]-\theta)] + E[(E[\hat{\theta}] - \theta)^2]
\end{align}
\]</span> <span class="math inline">\(\ E[\hat{\theta}]-\theta\)</span>は定数なので，期待値の括弧からはずしても問題ない（<span class="math inline">\(E[X]=X\)</span>）ため，括弧から出してやって <span class="math display">\[
\begin{align}
E[(\hat{\theta} - E[\hat{\theta}])^2] + 2(E[\hat{\theta}]-\theta) E[(\hat{\theta} - E[\hat{\theta}])] + (E[\hat{\theta}] - \theta)^2
\end{align}
\]</span> <span class="math inline">\(E[\hat{\theta}]\)</span>は定数であり，確率変数に定数を足し（引い）たものの期待値は期待値に定数を足し（引い）たものと等しい（<span class="math inline">\(E[X-C]=E[X]-C\)</span>）ので，第2項の<span class="math inline">\(E[(\hat{\theta} - E[\hat{\theta}])]\)</span>は<span class="math inline">\((E[\hat{\theta}] - E[\hat{\theta}])]\)</span>となり，ゼロになるので消えて <span class="math display">\[
E[(\hat{\theta} - E[\hat{\theta}])^2] + (E[\hat{\theta}] - \theta)^2
\]</span> 定義上，分散（variance）は<span class="math inline">\(Var(X) = E[(X - \bar{X})^2]=E[(X-E[X])^2]\)</span>，バイアス（bias）は<span class="math inline">\(E[\hat{\theta}]-\theta\)</span>だったので <span class="math display">\[
MSE = E[(\hat{\theta} - E[\hat{\theta}])^2] + (E[\hat{\theta}] - \theta)^2 = Var(\hat{\theta})+Bias(\hat{\theta},\theta)^2
\]</span></p>
<h4 id="参考サイト-1">参考サイト</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Mean_squared_error">Mean squared error - Wikipedia</a></li>
<li><a href="https://bellcurve.jp/statistics/course/6714.html">期待値の性質 | 統計学の時間 | 統計WEB</a></li>
</ul> <!-- NOTE: ここにインデントをつけるとcode部のインデントが壊れる -->
    </article>
    
      </main>

  <script src="modules/progress-nav/script.js"></script>
</body>
</html>